{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ccd0eb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77b4aaf4",
   "metadata": {},
   "source": [
    "# Generate triplets from cross encoder\n",
    "\n",
    "Generate triplets using the cross encoder from 222\n",
    "- get all pairs from tree-record-attachments and existing standard buckets\n",
    "- add easy-negs from most-frequent 10000 tree pref names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2525d3d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "from datetime import datetime\n",
    "import random\n",
    "import re\n",
    "\n",
    "import pandas as pd\n",
    "from sentence_transformers.cross_encoder import CrossEncoder\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "\n",
    "from src.data.utils import read_csv, load_dataset_v2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd5420dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "given_surname = 'given'\n",
    "\n",
    "num_training_examples = 10_000_000\n",
    "run = ''\n",
    "# if common, write triplets from common names\n",
    "# else write triplet from train and include num_easy_negs easy negatives\n",
    "num_easy_negs = 'common'  \n",
    "\n",
    "allow_dups = False\n",
    "\n",
    "num_common_names = 10_000\n",
    "\n",
    "tokenizer_max_length = 32\n",
    "pref_path = f\"s3://familysearch-names/processed/tree-preferred-{given_surname}-aggr.csv.gz\"\n",
    "train_path = f\"s3://familysearch-names/processed/tree-hr-{given_surname}-train-v2.csv.gz\"\n",
    "common_non_negatives_path = f\"../data/processed/common_{given_surname}_non_negatives-augmented.csv\"\n",
    "\n",
    "std_path = f\"../references/std_{given_surname}.txt\"\n",
    "cross_encoder_dir = f\"../data/models/cross-encoder-{given_surname}-10m-265-same-all\"\n",
    "\n",
    "triplets_path=f\"../data/processed/cross-encoder-triplets-{given_surname}-{num_easy_negs}{'-dups' if allow_dups else ''}{run}.csv\"\n",
    "triplets_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da1ac45b",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()\n",
    "print(torch.cuda.is_available())\n",
    "print(\"cuda total\", torch.cuda.get_device_properties(0).total_memory)\n",
    "print(\"cuda reserved\", torch.cuda.memory_reserved(0))\n",
    "print(\"cuda allocated\", torch.cuda.memory_allocated(0))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7fe2f0a",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b762546",
   "metadata": {},
   "source": [
    "### load common names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c098c254",
   "metadata": {},
   "outputs": [],
   "source": [
    "pref_df = read_csv(pref_path)\n",
    "common_names = [name for name in pref_df['name'][:num_common_names].tolist() \\\n",
    "                if len(name) > 1 and re.fullmatch(r'[a-z]+', name)]\n",
    "pref_df = None\n",
    "len(common_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c23b436",
   "metadata": {},
   "source": [
    "### load common non-negatives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8888319c",
   "metadata": {},
   "outputs": [],
   "source": [
    "name_pairs = set()\n",
    "\n",
    "common_non_negatives_df = read_csv(common_non_negatives_path)\n",
    "for name1, name2 in common_non_negatives_df.values.tolist():\n",
    "    if name1 != name2:\n",
    "        name_pairs.add((name1, name2))\n",
    "len(name_pairs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c43e65e",
   "metadata": {},
   "source": [
    "### load training dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cf4f1f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "tree_names_train, attached_names_train, record_names_train = \\\n",
    "    load_dataset_v2(train_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e580ce04",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"tree_names_train\", len(tree_names_train))\n",
    "print(\"attached_names_train\", sum(len(attachments) for attachments in attached_names_train))\n",
    "print(\"total pairs\", sum(freq for attachments in attached_names_train for _, freq in attachments))\n",
    "print(\"record_names_train\", len(record_names_train))\n",
    "print(\"total names\", len(set(tree_names_train).union(set(record_names_train))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdffb457",
   "metadata": {},
   "outputs": [],
   "source": [
    "buckets = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "947d2e04",
   "metadata": {},
   "outputs": [],
   "source": [
    "for tree_name, attachments in zip(tree_names_train, attached_names_train):\n",
    "    names = [tree_name]\n",
    "    for name, _ in attachments:\n",
    "        if name not in names:\n",
    "            names.append(name)\n",
    "    if len(names) < 2:\n",
    "        continue\n",
    "    buckets.append(names)\n",
    "    for name1 in names:\n",
    "        for name2 in names:\n",
    "            if name1 != name2:\n",
    "                name_pairs.add((name1, name2))\n",
    "print(len(buckets), sum(len(bucket) for bucket in buckets))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cd03786",
   "metadata": {},
   "source": [
    "### load std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e66101a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(std_path) as f:\n",
    "    for line in f.readlines():\n",
    "        line = line.strip()\n",
    "        head_names, tail_names = line.split(':')\n",
    "        head_names = head_names.strip()\n",
    "        tail_names = tail_names.strip()\n",
    "        names = []\n",
    "        for name in head_names.split(' '):\n",
    "            if len(name) > 0 and name not in names:\n",
    "                names.append(name)\n",
    "        for name in tail_names.split(' '):\n",
    "            if len(name) > 0 and name not in names:\n",
    "                names.append(name)\n",
    "        if len(names) < 2:\n",
    "            continue\n",
    "        buckets.append(names)\n",
    "        for name1 in names:\n",
    "            for name2 in names:\n",
    "                if name1 != name2:\n",
    "                    name_pairs.add((name1, name2))\n",
    "print(len(buckets), sum(len(bucket) for bucket in buckets))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bfa446d",
   "metadata": {},
   "outputs": [],
   "source": [
    "len([bucket for bucket in buckets if len(bucket) == 2])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5916949",
   "metadata": {},
   "source": [
    "### name pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0938a3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "name_pairs = list(name_pairs)\n",
    "len(name_pairs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f9eb85d",
   "metadata": {},
   "source": [
    "## Generate and write triplets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4182baa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = CrossEncoder(cross_encoder_dir, max_length=tokenizer_max_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d8e1aef",
   "metadata": {},
   "outputs": [],
   "source": [
    "def harmonic_mean(x,y):\n",
    "    return 2 / (1/x+1/y)\n",
    "\n",
    "def choose3(names):\n",
    "    while True:\n",
    "        anchor = random.randrange(len(names))\n",
    "        pos = random.randrange(len(names))\n",
    "        neg = random.randrange(len(names))\n",
    "        if anchor != neg and pos != neg and (anchor != pos or len(names) == 2):\n",
    "            if names[pos] < names[neg]:  # always return pos >= neg\n",
    "                neg, pos = pos, neg\n",
    "            return names[anchor], names[pos], names[neg]\n",
    "        \n",
    "def choose_pair(pair):\n",
    "    if random.random() < 0.5:\n",
    "        return pair[0], pair[1]\n",
    "    else:\n",
    "        return pair[1], pair[0]\n",
    "\n",
    "def clamp(score):\n",
    "    return max(0.0, min(1.0, score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01ee14b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "triplets_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a1717f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_triple(writer, triple):\n",
    "    anchor, pos, neg = triple\n",
    "    anchor_pos1, anchor_pos2, anchor_neg1, anchor_neg2 = \\\n",
    "        model.predict([[anchor, pos], [pos, anchor], [anchor, neg], [neg, anchor]])\n",
    "    anchor_pos = harmonic_mean(anchor_pos1, anchor_pos2)\n",
    "    anchor_neg = harmonic_mean(anchor_neg1, anchor_neg2)\n",
    "    if anchor == pos:\n",
    "        anchor_pos = 1.0\n",
    "    if anchor == neg:\n",
    "        anchor_neg = 1.0\n",
    "    anchor_pos = clamp(anchor_pos)\n",
    "    anchor_neg = clamp(anchor_neg)\n",
    "    if anchor_pos < anchor_neg:\n",
    "        pos, neg = neg, pos\n",
    "        anchor_pos, anchor_neg = anchor_neg, anchor_pos\n",
    "    writer.writerow({\n",
    "        'anchor': anchor, \n",
    "        'positive': pos, \n",
    "        'positive_score': anchor_pos, \n",
    "        'negative': neg, \n",
    "        'negative_score': anchor_neg,\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e4699d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# open each path, get names, write triplets\n",
    "cnt = 0\n",
    "seen_triples = set()\n",
    "seen_cnt = 0\n",
    "with open(triplets_path, 'w', newline='') as f:\n",
    "    # Create a CSV writer object\n",
    "    writer = csv.DictWriter(f, fieldnames=['anchor','positive','positive_score','negative','negative_score'])\n",
    "\n",
    "    # Write the column headers\n",
    "    writer.writeheader()\n",
    "\n",
    "    while cnt < num_training_examples:\n",
    "        # write triples from common names\n",
    "        if num_easy_negs == 'common':\n",
    "            anchor = random.choice(common_names)\n",
    "            pos = random.choice(common_names)\n",
    "            neg = random.choice(common_names)\n",
    "            if anchor == pos or anchor == neg or pos == neg:\n",
    "                continue\n",
    "            if pos < neg:\n",
    "                pos, neg = neg, pos\n",
    "            triple = (anchor, pos, neg)\n",
    "            if triple in seen_triples:\n",
    "                seen_cnt += 1\n",
    "                continue\n",
    "            seen_triples.add(triple)\n",
    "            write_triple(writer, triple)\n",
    "            cnt += 1\n",
    "            if cnt % 10_000 == 0:\n",
    "                print(cnt, seen_cnt, datetime.now())\n",
    "        else:\n",
    "            ix = random.randrange(len(buckets))\n",
    "            if not allow_dups and len(buckets[ix]) < 3:\n",
    "                continue\n",
    "            triple = choose3(buckets[ix])\n",
    "            if triple in seen_triples:\n",
    "                seen_cnt += 1\n",
    "                continue\n",
    "            seen_triples.add(triple)\n",
    "            write_triple(writer, triple)\n",
    "            cnt += 1\n",
    "            if cnt % 10_000 == 0:\n",
    "                print(cnt, seen_cnt, datetime.now())\n",
    "\n",
    "            easy_neg_cnt = 0\n",
    "            while easy_neg_cnt < num_easy_negs:\n",
    "                ix = random.randrange(len(name_pairs))\n",
    "                anchor, pos = choose_pair(name_pairs[ix])\n",
    "                easy_neg = random.choice(common_names)\n",
    "                triple = (anchor, pos, easy_neg)\n",
    "                if triple in seen_triples:\n",
    "                    seen_cnt += 1\n",
    "                    continue\n",
    "                seen_triples.add(triple)\n",
    "                write_triple(writer, triple)\n",
    "                easy_neg_cnt += 1\n",
    "                cnt += 1\n",
    "                if cnt % 10_000 == 0:\n",
    "                    print(cnt, seen_cnt, datetime.now())\n",
    "cnt"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nama",
   "language": "python",
   "name": "nama"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "896a97b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad2e0f1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import namedtuple\n",
    "import math\n",
    "\n",
    "import jellyfish\n",
    "import joblib\n",
    "import matplotlib.pyplot as plt\n",
    "from mpire import WorkerPool\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import auc, PrecisionRecallDisplay, precision_recall_curve\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "import wandb\n",
    "\n",
    "from src.data.filesystem import fopen\n",
    "from src.data.utils import load_dataset\n",
    "from src.eval.utils import similars_to_ndarray\n",
    "from src.models.ensemble import featurize\n",
    "from src.models.swivel import SwivelModel, get_best_swivel_matches\n",
    "from src.models.utils import add_padding, remove_padding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dfe0578",
   "metadata": {},
   "outputs": [],
   "source": [
    "# config\n",
    "\n",
    "given_surname = \"given\"\n",
    "vocab_size = 610000 if given_surname == \"given\" else 2100000\n",
    "sample_size = 100000\n",
    "embed_dim = 50  # 100\n",
    "encoder_layers = 2\n",
    "num_matches = 5000\n",
    "batch_size = 256\n",
    "swivel_threshold = 0.45\n",
    "lev_threshold = 0.55\n",
    "Config = namedtuple(\"Config\", [\n",
    "    \"train_path\",\n",
    "    \"freq_path\",\n",
    "    \"embed_dim\",\n",
    "    \"swivel_vocab_path\",\n",
    "    \"swivel_model_path\",\n",
    "    \"ensemble_model_path\",\n",
    "])\n",
    "config = Config(\n",
    "    train_path=f\"s3://familysearch-names/processed/tree-hr-{given_surname}-train.csv.gz\",\n",
    "    freq_path=f\"s3://familysearch-names/processed/tree-preferred-{given_surname}-aggr.csv.gz\",\n",
    "    embed_dim=embed_dim,\n",
    "    swivel_vocab_path=f\"s3://nama-data/data/models/fs-{given_surname}-swivel-vocab-{vocab_size}-augmented.csv\",\n",
    "    swivel_model_path=f\"s3://nama-data/data/models/fs-{given_surname}-swivel-model-{vocab_size}-{embed_dim}-augmented.pth\",\n",
    "    ensemble_model_path=f\"s3://nama-data/data/models/fs-{given_surname}-ensemble-model-{vocab_size}-{embed_dim}-augmented.pth\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c13e7bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# wandb.init(\n",
    "#     project=\"nama\",\n",
    "#     entity=\"nama\",\n",
    "#     name=\"65_ensemble\",\n",
    "#     group=given_surname,\n",
    "#     notes=\"\",\n",
    "#     config=config._asdict(),\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e17e3d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)\n",
    "print(\"cuda total\", torch.cuda.get_device_properties(0).total_memory)\n",
    "print(\"cuda reserved\", torch.cuda.memory_reserved(0))\n",
    "print(\"cuda allocated\", torch.cuda.memory_allocated(0))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c349c2ee",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "390f4a78",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_names_train, weighted_actual_names_train, candidate_names_train = load_dataset(config.train_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43f55084",
   "metadata": {},
   "outputs": [],
   "source": [
    "freq_df = pd.read_csv(config.freq_path, na_filter=False)\n",
    "name_freq = {add_padding(name): freq for name, freq in zip(freq_df[\"name\"], freq_df[\"frequency\"])}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21d68bea",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(name_freq.get(\"<john>\", 0))\n",
    "print(name_freq.get(\"<dallan>\", 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e269e938",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_df = pd.read_csv(fopen(config.swivel_vocab_path, \"rb\"))\n",
    "swivel_vocab = {name: _id for name, _id in zip(vocab_df[\"name\"], vocab_df[\"index\"])}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25b3e296",
   "metadata": {},
   "outputs": [],
   "source": [
    "swivel_model = SwivelModel(len(swivel_vocab), config.embed_dim)\n",
    "swivel_model.load_state_dict(torch.load(fopen(config.swivel_model_path, \"rb\"), map_location=torch.device(device)))\n",
    "swivel_model.to(device)\n",
    "swivel_model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6d4b732",
   "metadata": {},
   "outputs": [],
   "source": [
    "_, input_names_train_sample, _, weighted_actual_names_train_sample = \\\n",
    "    train_test_split(input_names_train, weighted_actual_names_train, test_size=sample_size)\n",
    "candidate_names_train_sample = candidate_names_train"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "412d2b45",
   "metadata": {},
   "source": [
    "### Generate training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "721651a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_similarity_to(name):\n",
    "    name = remove_padding(name)\n",
    "\n",
    "    def calc_similarity(row):\n",
    "        cand_name = remove_padding(row[0])\n",
    "        dist = jellyfish.levenshtein_distance(name, cand_name)\n",
    "        return 1 - (dist / max(len(name), len(cand_name)))\n",
    "\n",
    "    return calc_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cc40b08",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_similars_for_name(name, candidate_names):\n",
    "    scores = np.apply_along_axis(calc_similarity_to(name), 1, candidate_names[:, None])\n",
    "\n",
    "    sorted_scores_idx = np.argsort(scores)[::-1]\n",
    "    candidate_names = candidate_names[sorted_scores_idx]\n",
    "    candidate_scores = scores[sorted_scores_idx]\n",
    "\n",
    "    return list(zip(candidate_names, candidate_scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02386fd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "swivel_names_scores = get_best_swivel_matches(model=swivel_model, \n",
    "                                              vocab=swivel_vocab, \n",
    "                                              input_names=input_names_train_sample,\n",
    "                                              candidate_names=candidate_names_train_sample,\n",
    "                                              encoder_model=None,\n",
    "                                              k=num_matches, \n",
    "                                              batch_size=batch_size,\n",
    "                                              add_context=True,\n",
    "                                              n_jobs=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a28f2fc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(sum(len(names_scores) for names_scores in swivel_names_scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d0666f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate training data\n",
    "features = []\n",
    "labels = []\n",
    "all_candidate_names = set(candidate_names_train_sample)\n",
    "for input_name, wans, swivels in tqdm(zip(input_names_train_sample, \n",
    "                                          weighted_actual_names_train_sample, \n",
    "                                          swivel_names_scores)):\n",
    "    # actuals - ensure names are in all_candidate_names\n",
    "    actual_names = set(name for name, _, _ in wans if name in all_candidate_names)\n",
    "    # swivel\n",
    "    swivel_scores = {name: score for name, score in swivels \\\n",
    "                     if score >= swivel_threshold}\n",
    "    swivel_names = set(swivel_scores.keys())\n",
    "    # levenshtein\n",
    "    lev_scores = {name: score for name, score in \\\n",
    "                  get_similars_for_name(input_name, np.array(list(swivel_names))) \\\n",
    "                  if score >= lev_threshold}\n",
    "    lev_names = set(lev_scores.keys())\n",
    "\n",
    "    # generate features from swivel and levenshtein scores and frequency\n",
    "    input_name_freq = name_freq.get(input_name, 0)\n",
    "    candidate_names = swivel_names.intersection(lev_names)\n",
    "    for candidate_name in candidate_names:\n",
    "        swivel_score = swivel_scores[candidate_name]\n",
    "        lev_score = lev_scores[candidate_name]\n",
    "        candidate_name_freq = name_freq.get(candidate_name, 0)\n",
    "        feature = featurize(swivel_score, lev_score, input_name_freq, candidate_name_freq)\n",
    "        label = 1 if candidate_name in actual_names else 0\n",
    "#         if label == 1:\n",
    "#             print(input_name, input_name_freq, candidate_name, candidate_name_freq, feature, label)\n",
    "        features.append(feature)\n",
    "        labels.append(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d786826f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(features))\n",
    "print(len(labels))\n",
    "print(sum(labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd0284af",
   "metadata": {},
   "source": [
    "#### Downsample negatives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4363e0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "neg_sample_rate = 1.0\n",
    "features_sample = []\n",
    "labels_sample = []\n",
    "for feature, label in zip(features, labels):\n",
    "    if label == 1 or random.random() <= neg_sample_rate:\n",
    "        features_sample.append(feature)\n",
    "        labels_sample.append(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5594a231",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(features_sample))\n",
    "print(len(labels_sample))\n",
    "print(sum(labels_sample))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb04aaca",
   "metadata": {},
   "source": [
    "### Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94421275",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = LogisticRegression()\n",
    "clf.fit(features_sample, labels_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee5049b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(clf.coef_)\n",
    "print(clf.intercept_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "690d9c3d",
   "metadata": {},
   "source": [
    "### Eval model on itself"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e259f249",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = clf.predict_proba(features)[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff141738",
   "metadata": {},
   "outputs": [],
   "source": [
    "precisions, recalls, thresholds = precision_recall_curve(labels, predictions)\n",
    "disp = PrecisionRecallDisplay(precision=precisions, recall=recalls)\n",
    "disp.plot()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c4e7c55",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(auc(recalls, precisions))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76ad0602",
   "metadata": {},
   "source": [
    "### Save ensemble model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1805e51b",
   "metadata": {},
   "outputs": [],
   "source": [
    "joblib.dump(clf, fopen(config.ensemble_model_path, mode='wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d75f603",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = joblib.load(fopen(config.ensemble_model_path, mode='rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "565a33a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(clf.coef_)\n",
    "print(clf.intercept_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f2dd057",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nama",
   "language": "python",
   "name": "nama"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

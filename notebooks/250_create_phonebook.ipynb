{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2907945b",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b2dac44",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Create a phonebook\n",
    "\n",
    "A phonebook maps clusters to partitions under the following constraints.\n",
    "\n",
    "1. All clusters in the same bucket MUST go in the same partition.\n",
    "2. A partition CANNOT contain clusters totalling more than N records.\n",
    "3. Clusters that are similar to each other SHOULD go in the same partition.\n",
    "\n",
    "## Aproach\n",
    "\n",
    "1. Choose a maximum number of partitions and a maximum number of records per partition.\n",
    "2. Compute the top N most-similar clusters to each cluster.\n",
    "3. Start by putting the clusters for each bucket in their own partition.\n",
    "4. Some buckets because of their size will span multiple partitions. Split those buckets up-front.\n",
    "5. While there are more than the maximum number of partitions, merge partitions containing the most-similar (to least-similar) clusters so long as the combined partition doesn't exceed the maximum partition size.\n",
    "6. If you end up with too many partitions, or many partitions that have significantly fewer number of records than the maximum, consider repeating the steps with a lower maximum number of records per partition."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d131857",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import re\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "from src.data.utils import read_csv\n",
    "from src.models.utils import top_similar_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b54bdec3",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# configure\n",
    "given_surname = \"given\"\n",
    "\n",
    "n_partitions = 720\n",
    "max_partition_size = 2_100_000\n",
    "min_threshold = 0.6\n",
    "\n",
    "linkage = \"average\"\n",
    "similarity_threshold = 0.1\n",
    "scorer = \"ce\"\n",
    "cluster_freq_normalizer = \"none\"\n",
    "clusters_path = f\"../data/processed/clusters_{given_surname}-{scorer}-{linkage}-{similarity_threshold}-{cluster_freq_normalizer}-augmented.json\"\n",
    "super_clusters_path = f\"../data/processed/super_clusters_{given_surname}-{scorer}-{linkage}-{similarity_threshold}-{cluster_freq_normalizer}.json\"\n",
    "pref_path = f\"s3://familysearch-names/processed/tree-preferred-{given_surname}-aggr.csv.gz\"\n",
    "\n",
    "phonebook_path = f\"s3://familysearch-names/processed/phonebook.csv\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4190d2c0",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cec1c31c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dict of name -> freq\n",
    "pref_df = read_csv(pref_path)\n",
    "name_freq = {name: freq for name, freq in zip(pref_df['name'], pref_df['frequency']) \\\n",
    "                if len(name) > 1 and re.fullmatch(r'[a-z]+', name)}\n",
    "pref_df = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b403f61",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(sum(list(name_freq.values())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f7ae378",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load clusters and super-clusters\n",
    "name_cluster = {}       # name -> cluster position\n",
    "cluster_centroids = []  # centroid for each cluster\n",
    "cluster_labels = []     # label for each cluster\n",
    "cluster_indexes = {}    # cluster label -> index\n",
    "cluster_sizes = []      # number of records for each cluster\n",
    "\n",
    "with open(clusters_path, 'r') as f:\n",
    "    clusters = json.load(f)  # cluster label -> names, centroid\n",
    "\n",
    "with open(super_clusters_path, 'r') as f:\n",
    "    super_clusters = json.load(f)  # super_cluster label -> cluster labels\n",
    "\n",
    "for label, cluster in clusters.items():\n",
    "    n_records = 0\n",
    "    for name in cluster['names']:\n",
    "        name_cluster[name] = len(cluster_labels)\n",
    "        n_records += name_freq.get(name, 0)\n",
    "    cluster_indexes[label] = len(cluster_labels)\n",
    "    cluster_labels.append(label)\n",
    "    cluster_sizes.append(n_records)\n",
    "    cluster_centroids.append(np.array(cluster['centroid']))\n",
    "cluster_labels = np.array(cluster_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00eb0732",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('number of names', len(name_cluster))\n",
    "print('number of clusters', len(cluster_labels))\n",
    "print('number of super-clusters', len(super_clusters))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b11e6b78",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('size of all clusters', sum(cluster_sizes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "525c4ae4",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('perfect cluster size', sum(cluster_sizes) / n_partitions)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4af34309",
   "metadata": {},
   "source": [
    "## Compute nearby clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "445d281e",
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_similarity_scores = []  # [(ix1, ix2, similarity)]\n",
    "top_n = 1000\n",
    "for ix, centroid in tqdm(enumerate(cluster_centroids), mininterval=2.0):\n",
    "    nearby_clusters, similarities = top_similar_names(centroid, cluster_centroids, cluster_labels,\n",
    "                                                      threshold=min_threshold, top_n=top_n)\n",
    "    for nearby_cluster, similarity in zip(nearby_clusters, similarities):\n",
    "        nearby_ix = cluster_indexes[nearby_cluster]\n",
    "        if ix >= nearby_ix:\n",
    "            continue\n",
    "        cluster_similarity_scores.append((ix, nearby_ix, similarity))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2524b583",
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_similarity_scores = sorted(cluster_similarity_scores, key=lambda x: x[2], reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89e27718",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(cluster_similarity_scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d3d1200",
   "metadata": {},
   "source": [
    "## Create phonebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5914850f",
   "metadata": {},
   "outputs": [],
   "source": [
    "partition_ix = 0\n",
    "partition_clusters = {}  # partition -> [cluster ix]\n",
    "partition_size = {}      # partition -> size\n",
    "cluster_partition = {}   # cluster -> partition ix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5067c26",
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_partitions(ix1, ix2):\n",
    "    global partition_ix, partition_clusters, partition_size, cluster_partition\n",
    "    \n",
    "    partition_clusters[partition_ix] = partition_clusters[ix1] + partition_clusters[ix2]\n",
    "    del partition_clusters[ix1]\n",
    "    del partition_clusters[ix2]\n",
    "    partition_size[partition_ix] = partition_size[ix1] + partition_size[ix2]\n",
    "    del partition_size[ix1]\n",
    "    del partition_size[ix2]\n",
    "    for cluster in partition_clusters[partition_ix]:\n",
    "        cluster_partition[cluster] = partition_ix\n",
    "    partition_ix += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58f4d564",
   "metadata": {},
   "source": [
    "### Start by creating a partition for each cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae6f96c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "for ix in range(len(cluster_labels)):\n",
    "    partition_clusters[partition_ix] = [ix]\n",
    "    partition_size[partition_ix] = cluster_sizes[ix]\n",
    "    cluster_partition[ix] = partition_ix\n",
    "    partition_ix += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0923b1c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "partition_ix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95eb95ee",
   "metadata": {},
   "source": [
    "### Merge clusters for the same super-cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0b5f27e",
   "metadata": {},
   "outputs": [],
   "source": [
    "for super_cluster in super_clusters.values():\n",
    "    first_cluster_label = super_cluster[0]\n",
    "    for cluster_label in super_cluster[1:]:\n",
    "        ix1 = cluster_partition[cluster_indexes[first_cluster_label]]\n",
    "        ix2 = cluster_partition[cluster_indexes[cluster_label]]\n",
    "        if ix1 != ix2:\n",
    "            merge_partitions(ix1, ix2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1efc3905",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(partition_clusters)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f18f0537",
   "metadata": {},
   "source": [
    "### Count partitions that are > max size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4734fb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_extra_partitions = 0\n",
    "remaining_total = 0\n",
    "for ix, size in partition_size.items():\n",
    "    while size > max_partition_size:\n",
    "        print(size, \",\".join(cluster_labels[cix] for cix in partition_clusters[ix]))\n",
    "        n_extra_partitions += 1\n",
    "        size -= max_partition_size\n",
    "    remaining_total += size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b21c47ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('extra', n_extra_partitions, \n",
    "      'remaining', n_partitions - n_extra_partitions, \n",
    "      'remaining size', remaining_total, \n",
    "      'remaining/partition', remaining_total / (n_partitions - n_extra_partitions))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52e775aa",
   "metadata": {},
   "source": [
    "### Merge partitions containing most-similar clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac22785e",
   "metadata": {},
   "outputs": [],
   "source": [
    "for cix1, cix2, _ in tqdm(cluster_similarity_scores, mininterval=2.0):\n",
    "    if len(partition_clusters) <= (n_partitions - n_extra_partitions):\n",
    "        break\n",
    "    pix1 = cluster_partition[cix1]\n",
    "    pix2 = cluster_partition[cix2]\n",
    "    if pix1 != pix2 and partition_size[pix1] + partition_size[pix2] <= max_partition_size:\n",
    "        merge_partitions(pix1, pix2)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32c01c0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(partition_clusters)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "909d187b",
   "metadata": {},
   "source": [
    "### Merge other partitions using first-fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "faa218b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "while len(partition_clusters) > (n_partitions - n_extra_partitions):\n",
    "    # find the smallest partition\n",
    "    small_ix = min(partition_size, key=partition_size.get)\n",
    "    # find the largest partition it will fit into\n",
    "    large_ix = None\n",
    "    for pix, size in partition_size.items():\n",
    "        if pix == small_ix or partition_size[small_ix] + size > max_partition_size:\n",
    "            continue\n",
    "        if large_ix is None or size > partition_size[large_ix]:\n",
    "            large_ix = pix\n",
    "    if large_ix is None:\n",
    "        break\n",
    "    # merge them\n",
    "    merge_partitions(small_ix, large_ix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b9e24c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(partition_clusters)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a12e3acb",
   "metadata": {},
   "source": [
    "### Check partition sizes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a891bcfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "if len(partition_clusters) > (n_partitions - n_extra_partitions):\n",
    "    print('We have a problem!')\n",
    "len(partition_clusters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ae36611",
   "metadata": {},
   "outputs": [],
   "source": [
    "# count number of partitions that are less than 90% full, 75% full, half full\n",
    "for threshold in [0.90, 0.75, 0.5]:\n",
    "    print(threshold, len([size for size in partition_size.values() if size < max_partition_size * threshold]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42a484aa",
   "metadata": {},
   "source": [
    "## Plot partition sizes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcc1cae3",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 6))\n",
    "plt.hist([size for size in partition_size.values() if size <= max_partition_size], bins=100)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c52b99f",
   "metadata": {},
   "source": [
    "## Plot scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89d6f13a",
   "metadata": {},
   "outputs": [],
   "source": [
    "same_partition_scores = []\n",
    "diff_partition_scores = []\n",
    "for cix1, cix2, score in cluster_similarity_scores:\n",
    "    if cix1 == cix2:\n",
    "        continue\n",
    "    pix1 = cluster_partition[cix1]\n",
    "    pix2 = cluster_partition[cix2]\n",
    "    if pix1 == pix2:\n",
    "        same_partition_scores.append(score)\n",
    "    else:\n",
    "        diff_partition_scores.append(score)\n",
    "print(len(same_partition_scores))\n",
    "print(len(diff_partition_scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0af18be4",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 6))\n",
    "plt.hist(same_partition_scores, bins=100, alpha=0.5, label=\"same\", color='green')\n",
    "plt.hist(diff_partition_scores, bins=100, alpha=0.5, label=\"diff\", color='red')\n",
    "plt.legend(loc='upper right')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d7712ac",
   "metadata": {},
   "source": [
    "## Save phonebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a23bbe02",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nama",
   "language": "python",
   "name": "nama"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

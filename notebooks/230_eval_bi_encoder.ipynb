{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "139bee68",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "028823c5",
   "metadata": {},
   "source": [
    "# Evaluate a bi-encoder model\n",
    "\n",
    "Load a bi-encoder (either one trained directly or one trained from the output of a cross-encoder)\n",
    "and evaluate it.\n",
    "\n",
    "Note that a bi-encoder trained directly has a small advantage here because it's being evaluated on its training data.\n",
    "\n",
    "| type | notes  | high-random | low-non-negative  | differences  | pos-neg               |\n",
    "| ---- | ------ | ----------- | ----------------- | ------------ | --------------------- |\n",
    "| orig |        | 496483 129 2| 88259 65071 36343 | 200002 38914 | 115358 7485 5680 1805 |\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0364890",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import torch\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "from src.models.biencoder import BiEncoder\n",
    "from src.models.tokenizer import get_tokenize_function_and_vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "774de195",
   "metadata": {},
   "outputs": [],
   "source": [
    "given_surname = \"given\"\n",
    "num_common_names = 10000\n",
    "bi_encoder_type = 'orig'\n",
    "\n",
    "max_tokens = 10\n",
    "\n",
    "pref_path = f\"s3://familysearch-names/processed/tree-preferred-{given_surname}-aggr.csv.gz\"\n",
    "test_triplets_path=f\"../data/processed/tree-hr-{given_surname}-triplets-v2-1000.csv.gz\"\n",
    "subwords_path=f\"../data/models/fs-{given_surname}-subword-tokenizer-2000f.json\"\n",
    "model_path = f\"../data/models/bi_encoder-{given_surname}-{bi_encoder_type}.pth\"\n",
    "\n",
    "common_non_negatives_path = f\"../references/common_{given_surname}_non_negatives.csv\"\n",
    "name_variants_path = f\"../references/{given_surname}_variants.csv\"\n",
    "given_nicknames_path = \"../references/givenname_nicknames.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34474d97",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()\n",
    "print(torch.cuda.is_available())\n",
    "print(\"cuda total\", torch.cuda.get_device_properties(0).total_memory)\n",
    "print(\"cuda reserved\", torch.cuda.memory_reserved(0))\n",
    "print(\"cuda allocated\", torch.cuda.memory_allocated(0))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7c030b7",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a60fb5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read triplets\n",
    "triplets_df = pd.read_csv(test_triplets_path, na_filter=False)\n",
    "print(len(triplets_df))\n",
    "triplets_df.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d0d0d78",
   "metadata": {},
   "source": [
    "### read common names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ee56867",
   "metadata": {},
   "outputs": [],
   "source": [
    "pref_df = pd.read_csv(pref_path, na_filter=False)\n",
    "common_names = [name for name in pref_df['name'][:num_common_names].tolist() \\\n",
    "                if len(name) > 1 and re.fullmatch(r'[a-z]+', name)]\n",
    "pref_df = None\n",
    "len(common_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c82c0653",
   "metadata": {},
   "source": [
    "### read common non-negatives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b77c3484",
   "metadata": {},
   "outputs": [],
   "source": [
    "common_non_negatives = set()\n",
    "\n",
    "def add_common_non_negative(name1, name2):\n",
    "    if name1 > name2:\n",
    "        name1, name2 = name2, name1\n",
    "    common_non_negatives.add(f\"{name1}:{name2}\")\n",
    "\n",
    "def is_common_non_negative(name1, name2):\n",
    "    if name1 > name2:\n",
    "        name1, name2 = name2, name1\n",
    "    return f\"{name1}:{name2}\" in common_non_negatives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a1d0064",
   "metadata": {},
   "outputs": [],
   "source": [
    "common_non_negatives_df = pd.read_csv(common_non_negatives_path, na_filter=False)\n",
    "for name1, name2 in common_non_negatives_df.values.tolist():\n",
    "    add_common_non_negative(name1, name2)\n",
    "len(common_non_negatives)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd2388db",
   "metadata": {},
   "outputs": [],
   "source": [
    "name_variants_df = pd.read_csv(name_variants_path, na_filter=False)\n",
    "for name1, name2 in name_variants_df.values.tolist():\n",
    "    add_common_non_negative(name1, name2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca125b1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "if given_surname == \"given\":\n",
    "    with open(given_nicknames_path, \"rt\") as f:\n",
    "        for line in f.readlines():\n",
    "            names = line.split(',')\n",
    "            for name1 in names:\n",
    "                for name2 in names:\n",
    "                    if name1 > name2:\n",
    "                        add_common_non_negative(name1, name2)\n",
    "len(common_non_negatives)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47871b51",
   "metadata": {},
   "source": [
    "### load tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c28eaab",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenize, tokenizer_vocab = get_tokenize_function_and_vocab(\n",
    "    max_tokens=max_tokens,\n",
    "    subwords_path=subwords_path,\n",
    ")\n",
    "len(tokenizer_vocab)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "994f1589",
   "metadata": {},
   "source": [
    "### load bi-encoder model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f8d9649",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = torch.load(model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae53f9a5",
   "metadata": {},
   "source": [
    "## Evaluate bi-encoder"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7cb2cf9",
   "metadata": {},
   "source": [
    "### how many random pairs score highly?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e9e72dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "total = 0\n",
    "cnt = 0\n",
    "bad_cnt = 0\n",
    "n_names = 1000\n",
    "pos_threshold = 0.5\n",
    "bad_threshold = 0.7\n",
    "common_negative_scores = []\n",
    "for ix, pos in enumerate(common_names[:n_names]):\n",
    "    pos_tokens = tokenize(pos)\n",
    "    for neg in common_names[ix+1:n_names]:\n",
    "        if is_common_non_negative(pos, neg):\n",
    "            continue\n",
    "        neg_tokens = tokenize(neg)\n",
    "        sim = model.predict(pos_tokens, neg_tokens)\n",
    "        common_negative_scores.append(sim)\n",
    "        if sim > pos_threshold:\n",
    "            print(pos, neg, sim, '***' if sim > bad_threshold else '')\n",
    "            cnt += 1\n",
    "            bad_cnt += 1 if sim > bad_threshold else 0\n",
    "        total += 1\n",
    "print(total, cnt, bad_cnt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11cff598",
   "metadata": {},
   "source": [
    "### how many common non-negatives score low?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebd811f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "neg_threshold = 0.4\n",
    "bad_threshold = 0.2\n",
    "total = 0\n",
    "cnt = 0\n",
    "bad_cnt = 0\n",
    "for pair in tqdm(common_non_negatives):\n",
    "    name1, name2 = pair.split(':')\n",
    "    sim = model.predict(tokenize(name1), tokenize(name2))\n",
    "    if sim < neg_threshold:\n",
    "        if cnt < 50:\n",
    "            print(name1, name2, sim, '***' if sim < bad_threshold else '')\n",
    "        cnt += 1\n",
    "        bad_cnt += 1 if sim < bad_threshold else 0\n",
    "    total += 1\n",
    "print(total, cnt, bad_cnt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23c9977c",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(common_non_negatives)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5656960b",
   "metadata": {},
   "source": [
    "### how many pairs score significantly differently than their label?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eeabd4be",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "threshold = 0.25\n",
    "total = 0\n",
    "cnt = 0\n",
    "for ix, (anchor, pos, pos_score, neg, neg_score) in tqdm(enumerate(zip(\n",
    "    triplets_df['anchor'], \n",
    "    triplets_df['positive'], \n",
    "    triplets_df['positive_score'], \n",
    "    triplets_df['negative'],\n",
    "    triplets_df['negative_score'],\n",
    "))):\n",
    "    if ix > 100000:\n",
    "        break\n",
    "    anchor_toks = tokenize(anchor)\n",
    "    pos_toks = tokenize(pos)\n",
    "    neg_toks = tokenize(neg)\n",
    "    pos_pred = model.predict(anchor_toks, pos_toks)\n",
    "    neg_pred = model.predict(anchor_toks, neg_toks)\n",
    "    if abs(pos_score - pos_pred) > threshold:\n",
    "        if cnt < 50:\n",
    "            print(anchor, pos, pos_pred, pos_score)\n",
    "        cnt += 1\n",
    "    if abs(neg_score - neg_pred) > threshold:\n",
    "        if cnt < 50:\n",
    "            print(anchor, neg, neg_pred, neg_score)\n",
    "        cnt += 1\n",
    "    total += 2\n",
    "print(total, cnt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98dfdcd2",
   "metadata": {},
   "source": [
    "### how many positive pairs score negatively, and how many negative pairs score positively?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b09b31d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "threshold = 0.1\n",
    "total = 0\n",
    "cnt = 0\n",
    "pos_neg_cnt = 0\n",
    "neg_pos_cnt = 0\n",
    "for ix, (anchor, pos, pos_score, neg, neg_score) in tqdm(enumerate(zip(\n",
    "    triplets_df['anchor'], \n",
    "    triplets_df['positive'], \n",
    "    triplets_df['positive_score'], \n",
    "    triplets_df['negative'],\n",
    "    triplets_df['negative_score'],\n",
    "))):\n",
    "    if ix > 100000:\n",
    "        break\n",
    "    anchor_toks = tokenize(anchor)\n",
    "    pos_toks = tokenize(pos)\n",
    "    neg_toks = tokenize(neg)\n",
    "    pos_pred = model.predict(anchor_toks, pos_toks)\n",
    "    neg_pred = model.predict(anchor_toks, neg_toks)\n",
    "    if pos_score >= 0.5+threshold or pos_score < 0.5-threshold:\n",
    "        if (pos_score >= 0.5+threshold and pos_pred < 0.5-threshold) or (pos_score < 0.5-threshold and pos_pred >= 0.5+threshold):\n",
    "            if pos_score >= 0.5+threshold and pos_pred < 0.5:\n",
    "                pos_neg_cnt += 1\n",
    "                pos_neg = True\n",
    "            else:\n",
    "                neg_pos_cnt += 1\n",
    "                pos_neg = False\n",
    "            if cnt < 50:\n",
    "                print(anchor, pos, pos_pred, pos_score, '***' if pos_neg else '')\n",
    "            cnt += 1\n",
    "        total += 1\n",
    "    if neg_score >= 0.5+threshold or neg_score < 0.5-threshold:\n",
    "        if (neg_score >= 0.5+threshold and neg_pred < 0.5-threshold) or (neg_score < 0.5-threshold and neg_pred >= 0.5+threshold):\n",
    "            if neg_score >= 0.5+threshold and neg_pred < 0.5:\n",
    "                pos_neg_cnt += 1\n",
    "                pos_neg = True\n",
    "            else:\n",
    "                neg_pos_cnt += 1\n",
    "                pos_neg = False\n",
    "            if cnt < 50:\n",
    "                print(anchor, neg, neg_pred, neg_score, '***' if pos_neg else '')\n",
    "            cnt += 1\n",
    "        total += 1\n",
    "print(total, cnt, pos_neg_cnt, neg_pos_cnt)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78ddfc8b",
   "metadata": {},
   "source": [
    "### graph results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cbc6219",
   "metadata": {},
   "outputs": [],
   "source": [
    "lower_threshold = 0.1\n",
    "non_negative_scores = []\n",
    "cnt = 0\n",
    "for pair in tqdm(common_non_negatives):\n",
    "    name1, name2 = pair.split(':')\n",
    "    sim = model.predict(tokenize(name1), tokenize(name2))\n",
    "    non_negative_scores.append(sim)\n",
    "    if sim < lower_threshold:\n",
    "        print(name1, name2, sim)\n",
    "        cnt += 1\n",
    "print(cnt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "322c50bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(non_negative_scores), len(common_negative_scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "982797b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 6))\n",
    "plt.hist(non_negative_scores, bins=30, alpha=0.5, label=\"Non negatives\", color='green')\n",
    "plt.hist(common_negative_scores, bins=30, alpha=0.5, label=\"Common negatives\", color='red')\n",
    "plt.title('Overlapping Histogram')\n",
    "plt.xlabel('Value')\n",
    "plt.ylabel('Frequency')\n",
    "plt.legend(loc='upper right')\n",
    "\n",
    "# Show the plot\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd31da69",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nama",
   "language": "python",
   "name": "nama"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

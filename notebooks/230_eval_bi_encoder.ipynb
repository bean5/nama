{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "139bee68",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "028823c5",
   "metadata": {},
   "source": [
    "# Evaluate a bi-encoder model\n",
    "\n",
    "Load a bi-encoder (either one trained directly or one trained from the output of a cross-encoder)\n",
    "and evaluate it.\n",
    "\n",
    "Note that a bi-encoder trained directly has an advantage here because it's being evaluated on its training data.\n",
    "\n",
    "| type          | high-random    | low-non-negative  | differences| pos-neg|test (high low)|rps-above nns-below|\n",
    "| ------------- | -------------- | ----------------- | ---------- | --------- | -------- | -------------------- |\n",
    "| orig-old      | 495902 2051 121|674868 313972 76494|200002 38914| 156783 13212 | 1215 16786 | 13088 150760 |\n",
    "| orig          | 495902 3444 196|674868 100534 14828|200002 9700 | 156783 599|1938 4081 |0.008 0.47 7390 56782 |\n",
    "| ce-3          |495902 14295 598|674868 46658 4128  |200002 26806| 156783 68 |1892 5294 |0.13 0.56 7610 67924  |   \n",
    "| ce-5          |495902 13768 638|674868 48352 5040  |200002 25367| 156783 73 |1871 5661 | 0.13 0.55 7693 68824 |\n",
    "|ce-1@1        |495902 218716 3081|674868 13274   80 |200002 48979| 200002  0 |1693 8387 | 0.29 0.63 6962 84512 |\n",
    "|ce-2@1        |495902 226092 2622|674868 13178   28 |200002 48680| 200002  0 |1669 8572 | 0.30 0.63 5991 90902 |\n",
    "|\n",
    "| aug38         | 495902 2783 147|674868 116760 17228|200002 7717 | 156783 670|1937 3946 | 0.005 0.45 6447 60470|\n",
    "| aug33         | 495902 2281 131|674868 174158 24706|200002 8601 |156783 1564|1742 5070 | 0.002 0.42 6902 76200|\n",
    "| aug40         | 495902 3140 175|674868  98194 15300|200002 7561 |200002 1586|2018 3594 | 0.007 0.47 6406 55454|\n",
    "|aug40a         | 495902 2785 151|674868 114850 17370|200002 7840 |200002 2066|1952 3868 | 0.005 0.45 6438 59338|\n",
    "| unaug         |495902 13578 616|674868 157320 24086|200002 17360|200002 5961|1351 14113|0.042 0.42 35167 89842|\n",
    "| ce100         |495902 1592 554|674868 473534 404346|200002 152081|200002 140401|471 113326|0.001 0.16 92970 381612|\n",
    "|ce100@3-aug40@6| 495902 3145 153|674868 101122 15260|200002  7593|200002 1724|2011 3396 | 0.007 0.47 6489 56714|\n",
    "|aug40@6-ce0@1 |495902 34316 1661| 674868 32488  8754|200002 47882|200002   18|1844 5690 |0.061 0.62 21415 41730|\n",
    "|aug40@6-ce0@6 |495902 33970 1646| 674868 34092  9010|200002 47085|200002   25|1831 5869 |0.060 0.61 21731 42944|\n",
    "|aug40@6        | 495902 3057 151| 674868 98958 15140|200002 7595 |200002 1612|2018 3493 |0.007 0.47  6449 55490|\n",
    "|aug40+ce0@3    | 495902 5239 243| 674868 49410  8228|200002 14994|200002  278|2207 2817 |0.030 0.54  6265 44058|\n",
    "\n",
    "* aug40a has 0 smoothing in notebook 200_generate_triplets; the others have 20 smoothing\n",
    "\n",
    "Compare\n",
    "-\n",
    "- CE?@1 + aug40@1\n",
    "- CE?@1 + aug40@6\n",
    "- CE100@6\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0364890",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from scipy.stats import ttest_ind, mannwhitneyu\n",
    "import torch\n",
    "\n",
    "from src.data.utils import read_csv\n",
    "from src.models.biencoder import BiEncoder\n",
    "from src.models.tokenizer import get_tokenize_function_and_vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "774de195",
   "metadata": {},
   "outputs": [],
   "source": [
    "given_surname = \"given\"\n",
    "num_common_names = 10000\n",
    "model_type = 'aug40+ce0'\n",
    "\n",
    "model_path = f\"../data/models/bi_encoder-{given_surname}-{model_type}.pth\"\n",
    "test_triplets_path=f\"../data/processed/tree-hr-{given_surname}-triplets-v2-1000.csv.gz\"\n",
    "\n",
    "max_tokens = 10\n",
    "subwords_path=f\"../data/models/fs-{given_surname}-subword-tokenizer-2000f.json\"\n",
    "\n",
    "pref_path = f\"s3://familysearch-names/processed/tree-preferred-{given_surname}-aggr.csv.gz\"\n",
    "common_non_negatives_path = f\"../data/processed/common_{given_surname}_non_negatives-augmented.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34474d97",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()\n",
    "print(torch.cuda.is_available())\n",
    "print(\"cuda total\", torch.cuda.get_device_properties(0).total_memory)\n",
    "print(\"cuda reserved\", torch.cuda.memory_reserved(0))\n",
    "print(\"cuda allocated\", torch.cuda.memory_allocated(0))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7c030b7",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a60fb5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read triplets\n",
    "triplets_df = read_csv(test_triplets_path)\n",
    "print(len(triplets_df))\n",
    "triplets_df.head(30)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d0d0d78",
   "metadata": {},
   "source": [
    "### read common names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ee56867",
   "metadata": {},
   "outputs": [],
   "source": [
    "pref_df = read_csv(pref_path)\n",
    "common_names = [name for name in pref_df['name'][:num_common_names].tolist() \\\n",
    "                if len(name) > 1 and re.fullmatch(r'[a-z]+', name)]\n",
    "pref_df = None\n",
    "len(common_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c82c0653",
   "metadata": {},
   "source": [
    "### read common non-negatives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a1d0064",
   "metadata": {},
   "outputs": [],
   "source": [
    "common_non_negatives = set()\n",
    "\n",
    "common_non_negatives_df = read_csv(common_non_negatives_path)\n",
    "for name1, name2 in common_non_negatives_df.values.tolist():\n",
    "    common_non_negatives.add((name1, name2))\n",
    "len(common_non_negatives)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47871b51",
   "metadata": {},
   "source": [
    "### load tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c28eaab",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenize, tokenizer_vocab = get_tokenize_function_and_vocab(\n",
    "    max_tokens=max_tokens,\n",
    "    subwords_path=subwords_path,\n",
    ")\n",
    "len(tokenizer_vocab)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c133362b",
   "metadata": {},
   "source": [
    "### load bi-encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f906a8e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = torch.load(model_path)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae53f9a5",
   "metadata": {},
   "source": [
    "## Evaluate bi-encoder"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7cb2cf9",
   "metadata": {},
   "source": [
    "### how many random pairs score high?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e9e72dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "total = 0\n",
    "cnt = 0\n",
    "bad_cnt = 0\n",
    "n_names = 1000\n",
    "pos_threshold = 0.3\n",
    "bad_threshold = 0.5\n",
    "random_pair_scores = []\n",
    "for ix, pos in enumerate(common_names[:n_names]):\n",
    "    pos_tokens = tokenize(pos)\n",
    "    for neg in common_names[ix+1:n_names]:\n",
    "        if (pos, neg) in common_non_negatives:\n",
    "            continue\n",
    "        neg_tokens = tokenize(neg)\n",
    "        sim = model.predict(pos_tokens, neg_tokens)\n",
    "        random_pair_scores.append(sim)\n",
    "        if sim > pos_threshold:\n",
    "            print(pos, neg, sim, '***' if sim > bad_threshold else '')\n",
    "            cnt += 1\n",
    "            bad_cnt += 1 if sim > bad_threshold else 0\n",
    "        total += 1\n",
    "print(total, cnt, bad_cnt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11cff598",
   "metadata": {},
   "source": [
    "### how many common non-negatives score low?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebd811f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "neg_threshold = 0.3\n",
    "bad_threshold = 0.1\n",
    "total = 0\n",
    "cnt = 0\n",
    "bad_cnt = 0\n",
    "non_negative_scores = []\n",
    "for name1, name2 in common_non_negatives:\n",
    "    sim = model.predict(tokenize(name1), tokenize(name2))\n",
    "    non_negative_scores.append(sim)\n",
    "    if sim < neg_threshold:\n",
    "        if cnt < 50:\n",
    "            print(name1, name2, sim, '***' if sim < bad_threshold else '')\n",
    "        cnt += 1\n",
    "        bad_cnt += 1 if sim < bad_threshold else 0\n",
    "    total += 1\n",
    "print(total, cnt, bad_cnt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5656960b",
   "metadata": {},
   "source": [
    "### how many pairs score significantly differently than their label?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eeabd4be",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "threshold = 0.25\n",
    "total = 0\n",
    "cnt = 0\n",
    "for ix, (anchor, pos, pos_score, neg, neg_score) in enumerate(zip(\n",
    "    triplets_df['anchor'], \n",
    "    triplets_df['positive'], \n",
    "    triplets_df['positive_score'], \n",
    "    triplets_df['negative'],\n",
    "    triplets_df['negative_score'],\n",
    ")):\n",
    "    if ix > 100_000:\n",
    "        break\n",
    "    anchor_toks = tokenize(anchor)\n",
    "    pos_toks = tokenize(pos)\n",
    "    neg_toks = tokenize(neg)\n",
    "    pos_pred = model.predict(anchor_toks, pos_toks)\n",
    "    neg_pred = model.predict(anchor_toks, neg_toks)\n",
    "    if abs(pos_score - pos_pred) > threshold:\n",
    "        if cnt < 50:\n",
    "            print(anchor, pos, pos_pred, pos_score)\n",
    "        cnt += 1\n",
    "    if abs(neg_score - neg_pred) > threshold:\n",
    "        if cnt < 50:\n",
    "            print(anchor, neg, neg_pred, neg_score)\n",
    "        cnt += 1\n",
    "    total += 2\n",
    "print(total, cnt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98dfdcd2",
   "metadata": {},
   "source": [
    "### how many positive pairs score negatively, and how many negative pairs score positively?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b09b31d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "threshold = 0.1\n",
    "midpoint = 0.3\n",
    "total_pos = 0\n",
    "total_neg = 0\n",
    "cnt = 0\n",
    "pos_neg_cnt = 0\n",
    "neg_pos_cnt = 0\n",
    "for ix, (anchor, pos, pos_score, neg, neg_score) in enumerate(zip(\n",
    "    triplets_df['anchor'], \n",
    "    triplets_df['positive'], \n",
    "    triplets_df['positive_score'], \n",
    "    triplets_df['negative'],\n",
    "    triplets_df['negative_score'],\n",
    ")):\n",
    "    if ix > 100_000:\n",
    "        break\n",
    "    anchor_toks = tokenize(anchor)\n",
    "    pos_toks = tokenize(pos)\n",
    "    neg_toks = tokenize(neg)\n",
    "    pos_pred = model.predict(anchor_toks, pos_toks)\n",
    "    neg_pred = model.predict(anchor_toks, neg_toks)\n",
    "    if pos_score >= midpoint+threshold:\n",
    "        if pos_pred < midpoint-threshold:\n",
    "            pos_neg_cnt += 1\n",
    "            if cnt < 50:\n",
    "                print(anchor, pos, pos_pred, pos_score, '***')\n",
    "            cnt += 1\n",
    "        total_pos += 1\n",
    "    if neg_score >= midpoint+threshold:\n",
    "        if neg_pred < midpoint-threshold:\n",
    "            pos_neg_cnt += 1\n",
    "            if cnt < 50:\n",
    "                print(anchor, neg, neg_pred, neg_score, '***')\n",
    "            cnt += 1\n",
    "        total_pos += 1\n",
    "    if pos_score < midpoint-threshold:\n",
    "        if pos_pred >= midpoint+threshold:\n",
    "            neg_pos_cnt += 1\n",
    "            if cnt < 50:\n",
    "                print(anchor, pos, pos_pred, pos_score)\n",
    "            cnt += 1\n",
    "        total_neg += 1\n",
    "    if neg_score < midpoint-threshold:\n",
    "        if neg_pred >= midpoint+threshold:\n",
    "            neg_pos_cnt += 1\n",
    "            if cnt < 50:\n",
    "                print(anchor, neg, neg_pred, neg_score)\n",
    "            cnt += 1\n",
    "        total_neg += 1\n",
    "print(total_pos, pos_neg_cnt, total_neg, neg_pos_cnt)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef848648",
   "metadata": {},
   "source": [
    "### Welch t-test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "837d3c3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# larger ttest is better, smaller mann is better\n",
    "t_ttest, _ = ttest_ind(random_pair_scores, non_negative_scores, equal_var=False)\n",
    "t_mann, _  = mannwhitneyu(random_pair_scores, non_negative_scores, use_continuity=False)\n",
    "print(int(abs(t_ttest)), int(t_mann/1_000_000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8308f04d",
   "metadata": {},
   "outputs": [],
   "source": [
    "rps_mean = sum(random_pair_scores) / len(random_pair_scores)\n",
    "nps_mean = sum(non_negative_scores) / len(non_negative_scores)\n",
    "avg_mean = (rps_mean + nps_mean) / 2\n",
    "rps_above_mean = len([score for score in random_pair_scores if score > avg_mean])\n",
    "nns_below_mean = len([score for score in non_negative_scores if score < avg_mean])\n",
    "print(f\"{avg_mean:0.2} {len(random_pair_scores)} {len(non_negative_scores)}\")\n",
    "print(f\"{rps_mean:0.2} {nps_mean:0.2} {rps_above_mean} {nns_below_mean}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78ddfc8b",
   "metadata": {},
   "source": [
    "### graph results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "982797b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 6))\n",
    "plt.hist(non_negative_scores, bins=30, alpha=0.5, label=\"Non negatives\", color='green')\n",
    "plt.hist(random_pair_scores, bins=30, alpha=0.5, label=\"Random pairs\", color='red')\n",
    "plt.title('Overlapping Histogram')\n",
    "plt.xlabel('Value')\n",
    "plt.ylabel('Frequency')\n",
    "plt.legend(loc='upper right')\n",
    "\n",
    "# Show the plot\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6169ea1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nama",
   "language": "python",
   "name": "nama"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

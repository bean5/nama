{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58ffe7d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "872dc4ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import torch\n",
    "import numpy as np\n",
    "from src.data.ancestry import load_train_test\n",
    "from src.metrics import metrics\n",
    "from src.models import utils\n",
    "from src.models import triplet_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "769bf5e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_NAME_LENGTH = 30\n",
    "char_to_idx_map, idx_to_char_map = utils.build_token_idx_maps()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29019353",
   "metadata": {},
   "source": [
    "### Load model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6b757e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b41c1045",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = torch.load(\"../models/anc-encoder-bilstm-100-512.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d789bb2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(device)\n",
    "model.to(device)\n",
    "model.device = device"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db37d904",
   "metadata": {},
   "source": [
    "### Load data for fine-tuning and evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "783c70ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = load_train_test(f\"../data/raw/records25k_data_train.csv\", f\"../data/raw/records25k_data_test.csv\")\n",
    "\n",
    "input_names_train, weighted_actual_names_train, candidate_names_train = train\n",
    "input_names_test, weighted_actual_names_test, candidate_names_test = test\n",
    "\n",
    "actual_names_train = [[name for name, _, _ in name_weights] for name_weights in weighted_actual_names_train]\n",
    "actual_names_test = [[name for name, _, _ in name_weights] for name_weights in weighted_actual_names_test]\n",
    "\n",
    "candidate_names_all = np.concatenate((candidate_names_train, candidate_names_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8abdd31b",
   "metadata": {},
   "source": [
    "### Fine-tune"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5dcd20f",
   "metadata": {},
   "outputs": [],
   "source": [
    "near_negatives_train = triplet_loss.get_near_negatives(\n",
    "    input_names_train, weighted_actual_names_train, candidate_names_train, k=50\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ba8285a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save near_negatives\n",
    "with open(\"../data/processed/ancestry_near_negatives.pickle\", \"wb\") as f:\n",
    "    pickle.dump(near_negatives_train, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f056d9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load near_negatives\n",
    "with open(\"../data/processed/ancestry_near_negatives.pickle\", \"rb\") as f:\n",
    "    near_negatives_train = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd326deb",
   "metadata": {},
   "outputs": [],
   "source": [
    "triplet_loss.train_triplet_loss(\n",
    "    model,\n",
    "    input_names_train,\n",
    "    weighted_actual_names_train,\n",
    "    near_negatives_train,\n",
    "    input_names_test,\n",
    "    weighted_actual_names_test,\n",
    "    candidate_names_test,\n",
    "    candidate_names_train,\n",
    "    candidate_names_all,\n",
    "    char_to_idx_map,\n",
    "    MAX_NAME_LENGTH,\n",
    "    40,\n",
    "    512,\n",
    "    0.05,\n",
    "    100,\n",
    "    device,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06066e62",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model, \"../data/models/anc-triplet-bilstm-100-512-40-05.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef26e442",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = torch.load(\"../data/models/anc-triplet-bilstm-100-512-40-05.pth\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d889499",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e8bcf9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# move to cpu for evaluation so we don't run out of GPU memory\n",
    "model.to(\"cpu\")\n",
    "model.device = \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a7eebdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get embeddings for train candidate names\n",
    "candidate_names_train_X, _ = utils.convert_names_to_model_inputs(\n",
    "    candidate_names_train, char_to_idx_map, MAX_NAME_LENGTH\n",
    ")\n",
    "# Get Embeddings for the names from the encoder\n",
    "candidate_names_train_encoded = model(candidate_names_train_X, just_encoder=True).detach().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ff46594",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get embeddings for test input names\n",
    "input_names_test_X, _ = utils.convert_names_to_model_inputs(input_names_test, char_to_idx_map, MAX_NAME_LENGTH)\n",
    "# Get Embeddings for the names from the encoder\n",
    "input_names_test_encoded = model(input_names_test_X, just_encoder=True).detach().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb6327dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get embeddings for test candidate names\n",
    "candidate_names_test_X, _ = utils.convert_names_to_model_inputs(candidate_names_test, char_to_idx_map, MAX_NAME_LENGTH)\n",
    "candidate_names_test_encoded = model(candidate_names_test_X, just_encoder=True).detach().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a082f08",
   "metadata": {},
   "outputs": [],
   "source": [
    "candidate_names_all_encoded = np.vstack((candidate_names_train_encoded, candidate_names_test_encoded))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc690881",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_names_test_encoded.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ae233a4",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da3ae885",
   "metadata": {},
   "outputs": [],
   "source": [
    "# matric=euclidean is what TripletMarginLoss optimizes by default\n",
    "# but this means that scores will be in terms of distance, not similarity, so take this into account when computing PR at thresholds\n",
    "k = 100\n",
    "best_matches = utils.get_best_matches(\n",
    "    input_names_test_encoded, candidate_names_all_encoded, candidate_names_all, num_candidates=k, metric=\"euclidean\"\n",
    ")\n",
    "print(best_matches.shape)\n",
    "print(best_matches[0, 0, 0])\n",
    "print(best_matches[0, 0, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfb1325a",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_matches_names = best_matches[:, :, 0]\n",
    "print(best_matches_names.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31435016",
   "metadata": {},
   "source": [
    "### PR Curve at k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff5749c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics.precision_recall_curve_at_k(actual_names_test, best_matches_names, k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c52ce221",
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics.avg_precision_at_threshold(weighted_actual_names_test, best_matches, 0.145, distances=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1048b0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics.avg_weighted_recall_at_threshold(weighted_actual_names_test, best_matches, 0.145, distances=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8365cd0e",
   "metadata": {},
   "source": [
    "### PR Curve at threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c410dc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# minimum score threshold to test\n",
    "metrics.precision_weighted_recall_curve_at_threshold(\n",
    "    weighted_actual_names_test, best_matches, min_threshold=0.01, max_threshold=1.0, step=0.005, distances=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "722f7594",
   "metadata": {},
   "source": [
    "### AUC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8f80783",
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics.get_auc(\n",
    "    weighted_actual_names_test, best_matches, min_threshold=0.01, max_threshold=1.0, step=0.005, distances=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9530bf14",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Precision and recall at a specific threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acf9552b",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "threshold = 0.14\n",
    "print(\n",
    "    \"precision\",\n",
    "    metrics.avg_precision_at_threshold(weighted_actual_names_test, best_matches, threshold=threshold, distances=True),\n",
    ")\n",
    "print(\n",
    "    \"recall\",\n",
    "    metrics.avg_weighted_recall_at_threshold(\n",
    "        weighted_actual_names_test, best_matches, threshold=threshold, distances=True\n",
    "    ),\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nama",
   "language": "python",
   "name": "nama"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

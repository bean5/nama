{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ccd0eb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bebacbdb",
   "metadata": {},
   "source": [
    "# Train cross encoder\n",
    "Train a cross-encoder on the triplets from notebook 200, using the Roberta model from notebook 221.\n",
    "\n",
    "\n",
    "| vocab | notes                           | corr | random / mean | difference | pos-neg / mean | name-name |\n",
    "| ----- | ------------------------------- | ---- | ------ | ---------- | ------- | --------- |\n",
    "| 261   |                                 | 0.931| 56(41) |    183     |  36(3)  |   766     |\n",
    "| 261   | 2 epochs                        | 0.964| **28(15)** |     58     |  17(2)  |   802     |\n",
    "| 261   | each pair once, 6 epochs        | 0.851| 43(25) |    384     | 115(94) |   900     |\n",
    "| 261   | add same-name                   | 0.937| 43(28) |    165     |  32(2)  |   **149**     |\n",
    "| 265   |                                 | 0.941| 48(30) / **30(16)** |    156     |  29(0) / **21(0)**  |   750     |\n",
    "| 265   | 2 epochs                        | 0.960| 41(24) |     71     |  21(1)  |   816     |\n",
    "| 265   | add same-name          | 0.942| 47(27) / **24(14)** |    141  |  24(1) / **22(0)** |  **394**      |\n",
    "| 300   | add same-name                   | 0.948| 43(30) |    104     |  23(3)  |   **370**     |\n",
    "| 400   |                                 | 0.951| 263(??)|     88     |  12(1)  |   892     |\n",
    "| 265   | new-triplets, add same-name     | 0.897| >0.4 / **57(12)**     | **40**  |  / **7(1)** |  **14**   |\n",
    "| 265   | all, .38-triplets, add same-name| 0.901| >0.4 / **75(19)**     | **19**  |  / **4(0)** |  **5**   |\n",
    "| 265   | all, .40-triplets, add same-name| 0.947|>0.4 / 220(49) >0.41 / 146(28)| **9**   |  / **0**    |  **5** |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2525d3d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "import math\n",
    "import os\n",
    "import random\n",
    "import re\n",
    "\n",
    "import pandas as pd\n",
    "from sentence_transformers import InputExample\n",
    "from sentence_transformers.cross_encoder import CrossEncoder\n",
    "from sentence_transformers.cross_encoder.evaluation import CECorrelationEvaluator\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm import tqdm\n",
    "from transformers import AutoTokenizer\n",
    "\n",
    "from src.data.utils import read_csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd5420dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "given_surname = 'surname'\n",
    "\n",
    "num_epochs = 1\n",
    "train_batch_size = 16\n",
    "warmup_fraction = 0.1\n",
    "train_all = True\n",
    "# these flags affect the test data, so when comparing models generated with different flag values,\n",
    "# make sure you re-generate the test data with the same flag values for the comparisons\n",
    "each_pair_once = False\n",
    "add_same_name = True\n",
    "\n",
    "vocab_size = 265\n",
    "tokenizer_max_length = 32\n",
    "roberta_dir = f\"../data/models/roberta-{given_surname}-10m-{vocab_size}\"\n",
    "triplets_path=f\"../data/processed/tree-hr-{given_surname}-triplets-v2-1000-augmented.csv.gz\"\n",
    "\n",
    "cross_encoder_dir = f\"../data/models/cross-encoder-{given_surname}-10m{num_epochs if num_epochs > 1 else ''}-{vocab_size}{'-once' if each_pair_once else ''}{'-same' if add_same_name else ''}{'-all' if train_all else ''}\"\n",
    "\n",
    "print(cross_encoder_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "942e1ba9",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(cross_encoder_dir):\n",
    "    os.makedirs(cross_encoder_dir) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da1ac45b",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()\n",
    "print(torch.cuda.is_available())\n",
    "print(\"cuda total\", torch.cuda.get_device_properties(0).total_memory)\n",
    "print(\"cuda reserved\", torch.cuda.memory_reserved(0))\n",
    "print(\"cuda allocated\", torch.cuda.memory_allocated(0))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24804494",
   "metadata": {},
   "source": [
    "## Load triplets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58a1bc26",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read triplets\n",
    "triplets_df = read_csv(triplets_path)\n",
    "print(len(triplets_df))\n",
    "triplets_df.head(30)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2caa0752",
   "metadata": {},
   "source": [
    "## Convert triplets into training examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5e9e739",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = []\n",
    "all_names = set()\n",
    "seen_pairs = set()\n",
    "for anchor, pos, pos_score, neg, neg_score in tqdm(zip(\n",
    "    triplets_df['anchor'],\n",
    "    triplets_df['positive'],\n",
    "    triplets_df['positive_score'],\n",
    "    triplets_df['negative'],\n",
    "    triplets_df['negative_score'],\n",
    ")):\n",
    "    if (not add_same_name or anchor != pos) and \\\n",
    "       (not each_pair_once or (not (anchor, pos) in seen_pairs and not (pos, anchor) in seen_pairs)):\n",
    "        data.append(InputExample(texts=[anchor, pos], label=pos_score))\n",
    "        seen_pairs.add((anchor, pos))\n",
    "    if (not add_same_name or anchor != neg) and \\\n",
    "       (not each_pair_once or (not (anchor, neg) in seen_pairs and not (neg, anchor) in seen_pairs)):\n",
    "        data.append(InputExample(texts=[anchor, neg], label=neg_score))\n",
    "        seen_pairs.add((anchor, neg))\n",
    "    all_names.add(anchor)\n",
    "    all_names.add(pos)\n",
    "    all_names.add(neg)\n",
    "len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92f8279d",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(all_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "302c93d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# add name, name, 1.0\n",
    "if add_same_name:\n",
    "    for name in all_names:\n",
    "        data.append(InputExample(texts=[name, name], label=1.0))\n",
    "len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a34f64fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "if train_all:\n",
    "    dev_size = 0.01\n",
    "    test_size = 0.01\n",
    "else:\n",
    "    dev_size = 0.1\n",
    "    test_size = 0.1\n",
    "raw_train_data, test_data = train_test_split(data, test_size=(dev_size+test_size), random_state=42)\n",
    "dev_data, test_data = train_test_split(test_data, test_size=(test_size / (dev_size+test_size)), random_state=42)\n",
    "\n",
    "train_data = []\n",
    "for example in raw_train_data:\n",
    "    name1, name2 = example.texts\n",
    "    train_data.append(InputExample(texts=[name1, name2], label=example.label))\n",
    "    if name1 != name2:\n",
    "        train_data.append(InputExample(texts=[name2, name1], label=example.label))\n",
    "del raw_train_data\n",
    "\n",
    "random.shuffle(train_data)\n",
    "\n",
    "print('train', len(train_data))\n",
    "print('dev', len(dev_data))\n",
    "print('test', len(test_data))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97c53c89",
   "metadata": {},
   "source": [
    "## Train cross-encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e70b9d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We wrap train_samples (which is a List[InputExample]) into a pytorch DataLoader\n",
    "train_dataloader = DataLoader(train_data, shuffle=True, batch_size=train_batch_size)\n",
    "\n",
    "# We add an evaluator, which evaluates the performance during training\n",
    "evaluator = CECorrelationEvaluator.from_input_examples(dev_data, name='dev')\n",
    "\n",
    "# Configure the training\n",
    "warmup_steps = math.ceil(len(train_dataloader) * num_epochs * warmup_fraction) #N% of train data for warm-up\n",
    "print(\"Warmup-steps: {}\".format(warmup_steps))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "878f7697",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = CrossEncoder(roberta_dir, num_labels=1, max_length=tokenizer_max_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1b1c7f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "model.fit(train_dataloader=train_dataloader,\n",
    "          evaluator=evaluator,\n",
    "          epochs=num_epochs,\n",
    "          warmup_steps=warmup_steps,\n",
    "          evaluation_steps=200_000,\n",
    "          show_progress_bar=True,\n",
    "          output_path=cross_encoder_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0eddbd71",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(cross_encoder_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "115b388b",
   "metadata": {},
   "source": [
    "## Evaluate cross-encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cdd63fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = CrossEncoder(cross_encoder_dir, max_length=tokenizer_max_length)\n",
    "cross_encoder_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52e2af85",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "evaluator = CECorrelationEvaluator.from_input_examples(test_data, name='test')\n",
    "evaluator(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45d58f3d",
   "metadata": {},
   "source": [
    "## Test predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f764ba8",
   "metadata": {},
   "source": [
    "### Sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f50d9849",
   "metadata": {},
   "outputs": [],
   "source": [
    "for example in test_data[:250]:\n",
    "    if example.label == 0.0:\n",
    "        continue\n",
    "    name1, name2 = example.texts\n",
    "    score = model.predict([[name1, name2]])[0]\n",
    "    print(name1, name2, score, example.label)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c4cb90c",
   "metadata": {},
   "source": [
    "### How many random pairs score above a low threshold?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27822f30",
   "metadata": {},
   "outputs": [],
   "source": [
    "def harmonic_mean(x,y):\n",
    "    return 2 / (1/x+1/y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a19179b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "threshold = 0.41\n",
    "cnt = 0\n",
    "seen_pairs = set()\n",
    "for i in range(0, min(len(test_data)-1, 50000)):\n",
    "    name1 = test_data[i].texts[0]\n",
    "    name2 = test_data[i+1].texts[0]\n",
    "    if name1 == name2 or (name1,name2) in seen_pairs or (name2,name1) in seen_pairs:\n",
    "        continue\n",
    "    scores = model.predict([[name1, name2],[name2, name1]])\n",
    "    if harmonic_mean(scores[0],scores[1]) > threshold:\n",
    "        print(name1, name2, scores)\n",
    "        cnt += 1\n",
    "    seen_pairs.add((name1,name2))\n",
    "print(cnt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb74ddd7",
   "metadata": {},
   "source": [
    "### How many pairs score significantly differently than their label?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ef0c258",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "threshold = 0.1\n",
    "cnt = 0\n",
    "for example in test_data[:1000]:\n",
    "    name1, name2 = example.texts\n",
    "    scores = model.predict([[name1, name2],[name2, name1]])\n",
    "    score = harmonic_mean(scores[0],scores[1])\n",
    "    if abs(score - example.label) > threshold:\n",
    "        print(name1, name2, score, example.label)\n",
    "        cnt += 1\n",
    "print(cnt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8224590",
   "metadata": {},
   "source": [
    "### How many positive pairs score negatively, and how many negative pairs score positively?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0825f91b",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "threshold = 0.1\n",
    "cnt = 0\n",
    "for example in test_data[:1000]:\n",
    "    name1, name2 = example.texts\n",
    "    scores = model.predict([[name1, name2],[name2, name1]])\n",
    "    score = harmonic_mean(scores[0],scores[1])\n",
    "    if (example.label >= 0.5+threshold and score < 0.5) or (example.label < 0.5-threshold and score >= 0.5):\n",
    "        print(name1, name2, score, example.label, '***' if example.label >= 0.5+threshold and score < 0.5 else '')\n",
    "        cnt += 1\n",
    "print(cnt)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d91d6ab",
   "metadata": {},
   "source": [
    "### How many names don't score highly against themselves?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "940a82e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "threshold = 0.75\n",
    "cnt = 0\n",
    "seen_names = set()\n",
    "for example in test_data[:1000]:\n",
    "    name1, name2 = example.texts\n",
    "    scores = model.predict([[name1, name1],[name2, name2]])\n",
    "    if name1 not in seen_names and scores[0] < threshold:\n",
    "        print(name1, scores[0])\n",
    "        cnt += 1\n",
    "        seen_names.add(name1)\n",
    "    if name2 not in seen_names and scores[1] < threshold:\n",
    "        print(name2, scores[1])\n",
    "        cnt += 1\n",
    "        seen_names.add(name2)\n",
    "print(cnt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fe420c8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nama",
   "language": "python",
   "name": "nama"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

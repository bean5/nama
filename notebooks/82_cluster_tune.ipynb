{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from collections import namedtuple\n",
    "\n",
    "import pandas as pd\n",
    "import ray\n",
    "from ray import tune\n",
    "from ray.tune.schedulers import ASHAScheduler\n",
    "from ray.tune.suggest.hyperopt import HyperOptSearch\n",
    "from ray.tune.integration.wandb import WandbLoggerCallback\n",
    "import torch\n",
    "\n",
    "from src.data.utils import load_train_test\n",
    "from src.data.filesystem import fopen\n",
    "from src.eval.metrics import avg_precision_at_threshold, avg_weighted_recall_at_threshold\n",
    "from src.models.cluster import (\n",
    "    get_scores,\n",
    "    generate_closures,\n",
    "    generate_clusters,\n",
    "    assign_names_to_clusters,\n",
    "    get_best_cluster_matches,\n",
    ")\n",
    "from src.models.swivel import get_swivel_embeddings\n",
    "from src.models.utils import add_padding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# configure\n",
    "\n",
    "wandb_api_key_file = \"\"  # \"../.wandb-api-key\"\n",
    "given_surname = \"given\"\n",
    "size = \"freq\"\n",
    "DEFAULT_NAMES_TO_CLUSTER = 100000\n",
    "DEFAULT_CLOSURE_THRESHOLD = 1000\n",
    "DEFAULT_CLUSTER_THRESHOLD = 0.4\n",
    "DEFAULT_CLUSTER_LINKAGE = \"average\"\n",
    "DEFAULT_K_NN = 1\n",
    "\n",
    "vocab_size = 500000\n",
    "embed_dim = 200\n",
    "Config = namedtuple(\"Config\", \"train_path pref_path embed_dim vocab_path model_path\")\n",
    "config = Config(\n",
    "    train_path=f\"s3://familysearch-names/processed/tree-hr-{given_surname}-similar-train-{size}.csv.gz\",\n",
    "    pref_path=f\"s3://familysearch-names/processed/tree-preferred-{given_surname}-aggr.csv.gz\",\n",
    "    embed_dim=embed_dim,\n",
    "    vocab_path=f\"s3://nama-data/data/models/fs-{given_surname}-{size}-swivel-{vocab_size}-vocab-tfidf.csv\",\n",
    "    model_path=f\"../data/models/fs-{given_surname}-{size}-swivel-{vocab_size}-{embed_dim}-tfidf.pt\",\n",
    "    #     model_path=f\"s3://nama-data/data/models/fs-{given_surname}-{size}-swivel-{vocab_size}-{embed_dim}-tfidf.pt\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "[train] = load_train_test([config.train_path])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "input_names_train, weighted_actual_names_train, candidate_names_train = train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# load preferred names (in frequency order)\n",
    "pref_df = pd.read_csv(config.pref_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "pref_df[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "vocab_df = pd.read_csv(fopen(config.vocab_path, \"rb\"))\n",
    "print(len(vocab_df))\n",
    "print(vocab_df.head(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "swivel_vocab = {name: _id for name, _id in zip(vocab_df[\"name\"], vocab_df[\"index\"])}\n",
    "print(next(iter(swivel_vocab.items())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "swivel_model = torch.load(fopen(config.model_path, \"rb\"))\n",
    "swivel_model.eval()\n",
    "print(swivel_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Get all_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "all_names = set(input_names_train).union(set(candidate_names_train))\n",
    "print(len(all_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "pref_names = [add_padding(str(name)) for name in pref_df[\"name\"] if add_padding(str(name)) in all_names]\n",
    "print(len(pref_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "all_names = list(all_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Optimize hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def ray_training_function(config,\n",
    "                          swivel_model,\n",
    "                          swivel_vocab,\n",
    "                          input_names_train,\n",
    "                          all_names,\n",
    "                          pref_names):\n",
    "    all_embeddings = get_swivel_embeddings(swivel_model, swivel_vocab, all_names).astype('float32')\n",
    "    clustered_names = pref_names[:config[\"names_to_cluster\"]]\n",
    "    clustered_embeddings = get_swivel_embeddings(swivel_model, swivel_vocab, clustered_names).astype('float32')\n",
    "    clustered_scores_sparse, sorted_scores = get_scores(clustered_embeddings, threshold=0.4)\n",
    "\n",
    "    # generate closures\n",
    "    id2closure, closure2ids, _, _ = generate_closures(sorted_scores, config[\"closure_threshold\"])\n",
    "\n",
    "    # clean up\n",
    "    sorted_scores = None\n",
    "    \n",
    "    # generate clusters\n",
    "    id2cluster = generate_clusters(closure2ids, \n",
    "                                   clustered_scores_sparse, \n",
    "                                   clustered_names, \n",
    "                                   config[\"cluster_threshold\"], \n",
    "                                   config[\"cluster_linkage\"],\n",
    "                                   verbose=False,\n",
    "                                   n_jobs=1,\n",
    "                                  )\n",
    "    \n",
    "    # clean up\n",
    "    closure2ids = clustered_scores_sparse = clustered_names = None\n",
    "\n",
    "    # assign all names to clusters\n",
    "    name2cluster, cluster2names = assign_names_to_clusters(all_names,\n",
    "                                                           all_embeddings,\n",
    "                                                           id2cluster,\n",
    "                                                           clustered_embeddings,\n",
    "                                                           k=config[\"k_nn\"])\n",
    "    num_clusters = len(cluster2names)\n",
    "    max_cluster_size = max([len(names) for names in cluster2names.values()])\n",
    "    \n",
    "    # clean up\n",
    "    all_names = all_embeddings = id2cluster = clustered_embeddings = None\n",
    "    \n",
    "    # get best matches\n",
    "    best_matches = get_best_cluster_matches(name2cluster, cluster2names, input_names_train)\n",
    "    \n",
    "    # clean up\n",
    "    name2cluster = cluster2names = input_names_train = None\n",
    "    \n",
    "    # eval f1\n",
    "    precision = avg_precision_at_threshold(weighted_actual_names_train, best_matches, 0.5)\n",
    "    recall = avg_weighted_recall_at_threshold(weighted_actual_names_train, best_matches, 0.5)\n",
    "    f1 = 2 * (precision * recall) / (precision + recall)\n",
    "\n",
    "    # Report the metrics to Ray\n",
    "    tune.report(f1=f1, \n",
    "                precision=precision, \n",
    "                recall=recall, \n",
    "                num_clusters=num_clusters,\n",
    "                max_cluster_size=max_cluster_size\n",
    "               )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "config_params={\n",
    "    \"names_to_cluster\": tune.qrandint(100000, 450000, 50000),\n",
    "    \"closure_threshold\": DEFAULT_CLOSURE_THRESHOLD,\n",
    "    \"cluster_threshold\": tune.quniform(0.2, 0.8, 0.05),\n",
    "    \"cluster_linkage\": tune.choice([\"average\", \"single\", \"complete\"]),\n",
    "    \"k_nn\": tune.choice([1, 3, 5, 7]),\n",
    "}\n",
    "\n",
    "current_best_params = [{\n",
    "    \"names_to_cluster\": DEFAULT_NAMES_TO_CLUSTER,\n",
    "    \"closure_threshold\": DEFAULT_CLOSURE_THRESHOLD,\n",
    "    \"cluster_threshold\": DEFAULT_CLUSTER_THRESHOLD,\n",
    "    \"cluster_linkage\": DEFAULT_CLUSTER_LINKAGE,\n",
    "    \"k_nn\": DEFAULT_K_NN,\n",
    "}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# https://docs.ray.io/en/latest/tune/api_docs/suggestion.html#tune-hyperopt\n",
    "search_alg = HyperOptSearch(points_to_evaluate=current_best_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "ray.shutdown()\n",
    "ray.init(_redis_max_memory=4*10**9)  # give redis extra memory\n",
    "\n",
    "callbacks = []\n",
    "if wandb_api_key_file:\n",
    "    callbacks.append(WandbLoggerCallback(\n",
    "        project=\"nama\",\n",
    "        entity=\"nama\",\n",
    "        group=\"82_cluster_tune_\"+given_surname,\n",
    "        notes=\"\",\n",
    "        config=config._asdict(),\n",
    "        api_key_file=wandb_api_key_file\n",
    "    ))\n",
    "\n",
    "result = tune.run(\n",
    "    tune.with_parameters(ray_training_function,\n",
    "                         swivel_model=swivel_model,\n",
    "                         swivel_vocab=swivel_vocab,\n",
    "                         input_names_train=input_names_train,\n",
    "                         all_names=all_names,\n",
    "                         pref_names=pref_names),\n",
    "    resources_per_trial={\"cpu\": 2.0, \"gpu\": 0.0},\n",
    "    max_concurrent_trials=6,\n",
    "    config=config_params,\n",
    "    search_alg=search_alg,\n",
    "    num_samples=12,\n",
    "    metric=\"f1\",\n",
    "    mode=\"max\",\n",
    "    checkpoint_score_attr=\"f1\",\n",
    "    time_budget_s=1*3600,\n",
    "    progress_reporter=tune.JupyterNotebookReporter(\n",
    "        overwrite=False,\n",
    "        max_report_frequency=5*60\n",
    "    ),\n",
    "    callbacks=callbacks\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Get best model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Get trial that has the highest F1\n",
    "best_trial = result.get_best_trial(metric='f1', mode='max', scope='all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Parameters with the highest AUC\n",
    "best_trial.config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "print(f\"Best trial final train f1: {best_trial.last_result['f1']}\")\n",
    "print(f\"Best trial final train precision: {best_trial.last_result['precision']}\")\n",
    "print(f\"Best trial final train recall: {best_trial.last_result['recall']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Get all trials as DF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# All trials as pandas dataframe\n",
    "df = result.results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nama",
   "language": "python",
   "name": "nama"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}

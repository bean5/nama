{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2882991e",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d671df72",
   "metadata": {},
   "source": [
    "# Augment clusters with preferred names\n",
    "\n",
    "Load clusters and preferred tree names, and determine which common tree names do not appear in the clusters.\n",
    "\n",
    "Use a bi-encoder followed by a cross-encoder to determine which cluster they should go into."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ab5d9f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict, Counter\n",
    "import json\n",
    "import math\n",
    "import os\n",
    "import re\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "# from py4j.java_gateway import JavaGateway\n",
    "from sentence_transformers.cross_encoder import CrossEncoder\n",
    "from sklearn.cluster import AgglomerativeClustering\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import torch\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "from src.data.normalize import normalize\n",
    "from src.data.utils import read_csv\n",
    "from src.models.biencoder import BiEncoder\n",
    "from src.models.tokenizer import get_tokenize_function_and_vocab\n",
    "from src.models.utils import get_cross_encoder_score, top_similar_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ff83f53",
   "metadata": {},
   "outputs": [],
   "source": [
    "# configure\n",
    "given_surname = \"given\"\n",
    "\n",
    "max_tokens = 10\n",
    "subwords_path=f\"../data/models/fs-{given_surname}-subword-tokenizer-2000f.json\"\n",
    "common_name_threshold = 100 # TODO 105\n",
    "pref_path = f\"s3://familysearch-names/processed/tree-preferred-{given_surname}-aggr.csv.gz\"\n",
    "ce_model_dir = f\"../data/models/cross-encoder-{given_surname}-10m-265-same-all\"\n",
    "be_model_type = 'cecommon+0+aug-0-1'\n",
    "be_model_path = f\"../data/models/bi_encoder-{given_surname}-{be_model_type}.pth\"\n",
    "tokenizer_max_length = 32\n",
    "ce_model_dir = f\"../data/models/cross-encoder-{given_surname}-10m-265-same-all\"\n",
    "linkage = \"average\"\n",
    "scorer = \"ce\"  # be, ce, or cebe\n",
    "similarity_threshold = 0.10\n",
    "cluster_freq_normalizer = \"none\"\n",
    "clusters_path = f\"../data/processed/clusters_{given_surname}-{scorer}-{linkage}-{similarity_threshold}-{cluster_freq_normalizer}.json\"\n",
    "\n",
    "augmented_clusters_path = f\"../data/processed/clusters_{given_surname}-{scorer}-{linkage}-{similarity_threshold}-{cluster_freq_normalizer}-augmented.json\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2159fd1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()\n",
    "print(torch.cuda.is_available())\n",
    "print(\"cuda total\", torch.cuda.get_device_properties(0).total_memory)\n",
    "print(\"cuda reserved\", torch.cuda.memory_reserved(0))\n",
    "print(\"cuda allocated\", torch.cuda.memory_allocated(0))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad87f02c",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "raw",
   "id": "30ca3606",
   "metadata": {},
   "source": [
    "# # read triplets\n",
    "# triplets_df = read_csv(triplets_path)\n",
    "# print(len(triplets_df))\n",
    "# triplets_df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "deaa1fe1",
   "metadata": {},
   "outputs": [],
   "source": [
    "name_cluster = {}             # name -> cluster label\n",
    "cluster_names = {}            # cluster label -> names\n",
    "cluster_centroids = []        # centroid for each cluster\n",
    "cluster_centroid_labels = []  # label for each cluster\n",
    "\n",
    "with open(clusters_path, 'r') as f:\n",
    "    clusters = json.load(f)  # cluster label -> names, centroid\n",
    "\n",
    "for label, cluster in clusters.items():\n",
    "    cluster_names[label] = set(cluster['names'])\n",
    "    for name in cluster['names']:\n",
    "        name_cluster[name] = label\n",
    "    cluster_centroid_labels.append(label)\n",
    "    cluster_centroids.append(np.array(cluster['centroid']))\n",
    "cluster_centroid_labels = np.array(cluster_centroid_labels)\n",
    "\n",
    "print(len(cluster_names), len(name_cluster))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b855c628",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load pref names\n",
    "pref_df = read_csv(pref_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ff9bd69",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get total frequency, including names w frequency=1 that aren't in pref_df\n",
    "total_freq = sum(pref_df['frequency']) + len(pref_df[pref_df['frequency'] == 2]) * 2\n",
    "total_freq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bd5996a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate % of total frequency of the top N names \n",
    "freq = sum(pref_df['frequency'][:117000])\n",
    "print(freq/total_freq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf12581a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create common names pref names that occur >= common_name_threshold\n",
    "common_names = [name for name, freq in zip(pref_df['name'], pref_df['frequency']) \\\n",
    "                if len(name) > 1 and re.fullmatch(r'[a-z]+', name) and freq >= common_name_threshold]\n",
    "len(common_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13e8dc5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load tokenize function\n",
    "tokenize, tokenizer_vocab = get_tokenize_function_and_vocab(\n",
    "    max_tokens=max_tokens,\n",
    "    subwords_path=subwords_path,\n",
    ")\n",
    "len(tokenizer_vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3588988",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load bi-encoder model\n",
    "be_model = torch.load(be_model_path)\n",
    "be_model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddc9b628",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load cross encoder model\n",
    "ce_model = CrossEncoder(ce_model_dir, max_length=tokenizer_max_length)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0065abb3",
   "metadata": {},
   "source": [
    "## Which names are not in the clusters?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "838b8a3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print_cnt = 10\n",
    "unseen_names = []\n",
    "for ix, name in enumerate(common_names):\n",
    "    name_pieces = normalize(name, is_surname=given_surname=='surname', dont_return_empty=False)\n",
    "    if len(name_pieces) != 1:\n",
    "        continue\n",
    "    name = name_pieces[0]\n",
    "    if ix % 1000 == 0 and len(unseen_names) > 0:\n",
    "        print(ix, len(unseen_names))\n",
    "        print_cnt = 10\n",
    "    if name in name_cluster:\n",
    "        continue\n",
    "    unseen_names.append(name)\n",
    "    if print_cnt > 0:\n",
    "        print('   ', ix, name)\n",
    "        print_cnt -= 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03775e2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(unseen_names))\n",
    "unseen_names[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b34b468",
   "metadata": {},
   "source": [
    "### get name embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f9fd0b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_embedding(name):\n",
    "    embedding = be_model.get_embedding(tokenize(name)) \n",
    "    embedding /= np.linalg.norm(embedding)\n",
    "    return embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d77de9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "name_embeddings_names = np.array(list(name_cluster.keys()))\n",
    "name_embeddings = [get_embedding(name) for name in name_cluster.keys()]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df760a52",
   "metadata": {},
   "source": [
    "## Figure out which cluster to put the names into"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1499bc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_nearest_bi_encoder_names(name, threshold=0.3, limit=10):\n",
    "    embedding = get_embedding(name)\n",
    "    return top_similar_names(embedding, name_embeddings, name_embeddings_names, threshold, limit)\n",
    "\n",
    "def get_bi_encoder_score(name, other_name):\n",
    "    emb1 = get_embedding(name)\n",
    "    emb2 = get_embedding(other_name)\n",
    "    result = cosine_similarity([emb1], [emb2])[0][0]\n",
    "    return result\n",
    "\n",
    "def get_bi_encoder_cluster_score(name, cluster, use_max=False):\n",
    "    scores = []\n",
    "    # print('cluster', cluster)\n",
    "    for cluster_name in cluster_names[cluster]:\n",
    "        score = get_bi_encoder_score(name, cluster_name)\n",
    "        # print('  score', name, cluster_name, score)\n",
    "        scores.append(score)\n",
    "    return max(scores) if use_max else sum(scores)/len(scores)\n",
    "\n",
    "def get_nearest_bi_encoder_cluster_score(name, other_names, limit=10, use_max=False):\n",
    "    # get most-frequently occurring clusters\n",
    "    clusters = Counter()\n",
    "    for other_name in other_names:\n",
    "        if other_name not in name_cluster:\n",
    "            continue\n",
    "        cluster = name_cluster[other_name]\n",
    "        clusters[cluster] += 1\n",
    "    if len(clusters) == 0:\n",
    "        return None, None\n",
    "    # get nearest cluster\n",
    "    max_cluster = None\n",
    "    max_score = None\n",
    "    for cluster, count in clusters.most_common(limit):\n",
    "        # print('cluster, count', cluster, count)\n",
    "        score = get_bi_encoder_cluster_score(name, cluster, use_max=use_max)\n",
    "        # print('   score', score)\n",
    "        if max_score is None or score > max_score:\n",
    "            max_score = score\n",
    "            max_cluster = cluster\n",
    "    return max_cluster, max_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "199c7a2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_cross_encoder_cluster_score(name, cluster, use_max=False):\n",
    "    scores = []\n",
    "    # print('cluster', cluster)\n",
    "    for cluster_name in cluster_names[cluster]:\n",
    "        score = get_cross_encoder_score(name, cluster_name, ce_model)\n",
    "        # print('   score', name, cluster_name, score)\n",
    "        scores.append(score)\n",
    "    return max(scores) if use_max else sum(scores)/len(scores)\n",
    "\n",
    "def get_nearest_cross_encoder_cluster_score(name, other_names, limit=10, use_max=False):\n",
    "    # get most-frequently occurring clusters\n",
    "    clusters = Counter()\n",
    "    for other_name in other_names:\n",
    "        if other_name not in name_cluster:\n",
    "            continue\n",
    "        cluster = name_cluster[other_name]\n",
    "        clusters[cluster] += 1\n",
    "    if len(clusters) == 0:\n",
    "        return None, None\n",
    "    # get nearest cluster\n",
    "    max_cluster = None\n",
    "    max_score = None\n",
    "    for cluster, count in clusters.most_common(limit):\n",
    "        # print('cluster, count', cluster, count)\n",
    "        score = get_cross_encoder_cluster_score(name, cluster, use_max=use_max)\n",
    "        # print('   score', score)\n",
    "        if max_score is None or score > max_score:\n",
    "            max_score = score\n",
    "            max_cluster = cluster\n",
    "    return max_cluster, max_score"
   ]
  },
  {
   "cell_type": "raw",
   "id": "26b52beb",
   "metadata": {},
   "source": [
    "# match-spark/pipeline\n",
    "# java -cp target/spark-pipeline.jar org.familysearch.search.spark.py4j.Py4JGateway\n",
    "\n",
    "# gateway = JavaGateway()\n",
    "\n",
    "# def get_fs_bucket_score(name):\n",
    "#     bucket = gateway.getClusters(name, given_surname == 'surname')\n",
    "#     score = max([get_cross_encoder_score(name, bucket_name) for bucket_name in bucket_names[bucket]])\n",
    "#     return bucket, score"
   ]
  },
  {
   "cell_type": "raw",
   "id": "69abd4b0",
   "metadata": {},
   "source": [
    "# def get_triplets_bucket_score(name, threshold = 0.4):\n",
    "#     df = triplets_df[(triplets_df['anchor'] == name) | (triplets_df['positive'] == name)]\n",
    "#     df = df[(df['anchor'] != name) | (df['positive'] != name)]\n",
    "#     df = df[df['positive_score'] > threshold]\n",
    "#     df = df.sort_values(by='positive_score', ascending=False)\n",
    "#     for i in range(len(df)):\n",
    "#         top_row = df.iloc[i]\n",
    "#         top_name = top_row['anchor'] if top_row['positive'] == name else top_row['positive']\n",
    "#         if top_name in name_buckets:\n",
    "#             return next(iter(name_buckets[top_name])), top_row['positive_score']\n",
    "#     return None, None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c4a5b77",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test\n",
    "name = 'ivanovna'\n",
    "names, scores = get_nearest_bi_encoder_names(name, limit=20)\n",
    "print(names, scores)\n",
    "# names = names[1:]\n",
    "# scores = scores[1:]\n",
    "ce_cluster, ce_score = get_nearest_cross_encoder_cluster_score(name, names)\n",
    "print('cross-encoder', ce_cluster, ce_score)\n",
    "\n",
    "be_cluster, be_score = get_nearest_bi_encoder_cluster_score(name, names)\n",
    "print('bi-encoder', be_cluster, be_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db4f1b0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_names(cluster):\n",
    "    if not cluster:\n",
    "        return ''\n",
    "    return ' '.join(list(cluster_names[cluster])[:8])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e926c8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(cluster_names), len(name_cluster))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2abc8118",
   "metadata": {},
   "outputs": [],
   "source": [
    "testing = False\n",
    "\n",
    "score_threshold = 0.10\n",
    "\n",
    "unseen_names_set = set(unseen_names)\n",
    "n_new_clusters = 0\n",
    "\n",
    "for name in unseen_names[:1000] if testing else tqdm(unseen_names, mininterval=1.0):\n",
    "    # get fs vote\n",
    "    # fs_cluster, fs_score = get_fs_cluster_score(name)\n",
    "    # if fs_cluster is not None:\n",
    "    #     votes[fs_cluster] += fs_score * fs_weight + fs_boost\n",
    "    cluster = None\n",
    "    score = 0.0\n",
    "    # get nearby names\n",
    "    names, scores = get_nearest_bi_encoder_names(name)\n",
    "    if len(names) > 0:\n",
    "        # get cross-encoder vote\n",
    "        cluster, score = get_nearest_cross_encoder_cluster_score(name, names)\n",
    "    \n",
    "    # print stuff if testing\n",
    "    if testing and abs(score - score_threshold) < 0.05:\n",
    "        print()\n",
    "        print(name)\n",
    "        # print('   fs', fs_cluster, fs_score, sample_names(fs_cluster))\n",
    "        print('   ce', cluster, score, sample_names(cluster))\n",
    "        if score > score_threshold:\n",
    "            print('WINNER', cluster, score)\n",
    "        continue\n",
    "\n",
    "    # add name to existing cluster, or create a new cluster\n",
    "    if score >= score_threshold:\n",
    "        name_cluster[name] = cluster\n",
    "        cluster_names[cluster].add(name)\n",
    "    else:\n",
    "        n_new_clusters += 1\n",
    "        name_cluster[name] = name\n",
    "        cluster_names[name] = {name}\n",
    "\n",
    "    # add embedding\n",
    "    name_embeddings_names = np.append(name_embeddings_names, [name], axis=0)\n",
    "    name_embeddings = np.append(name_embeddings, [get_embedding(name)], axis=0)\n",
    "\n",
    "print('new clusters', n_new_clusters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b55a788e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(cluster_names), len(name_cluster))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bddd9c7",
   "metadata": {},
   "source": [
    "## Save augmented clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "978762eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_centroid(names):\n",
    "    total_embedding = None\n",
    "    for name in names:\n",
    "        embedding = get_embedding(name)\n",
    "        if total_embedding is None:\n",
    "            total_embedding = embedding\n",
    "        else:\n",
    "            total_embedding += embedding\n",
    "    # get average embedding\n",
    "    total_embedding = total_embedding / len(names)\n",
    "    # normalize\n",
    "    total_embedding = total_embedding / np.linalg.norm(total_embedding)\n",
    "    return total_embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10d9f150",
   "metadata": {},
   "outputs": [],
   "source": [
    "augmented_clusters_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6eadb4b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "clusters = {}\n",
    "for label, names in cluster_names.items():\n",
    "    centroid = get_centroid(names)\n",
    "    clusters[label] = {\"names\": list(names), \"centroid\": centroid.tolist()}\n",
    "\n",
    "with open(augmented_clusters_path, 'w') as f:\n",
    "    json.dump(clusters, f, indent=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5702e865",
   "metadata": {},
   "source": [
    "## Compare centroids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8af699f",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(augmented_clusters_path, 'r') as f:\n",
    "    augmented_clusters = json.load(f)  # cluster label -> names, centroid\n",
    "\n",
    "with open(clusters_path, 'r') as f:\n",
    "    clusters = json.load(f)  # cluster label -> names, centroid\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2cf23c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "sims = []\n",
    "cnt = 0\n",
    "for label in clusters:\n",
    "    centroid = clusters[label]['centroid']\n",
    "    if label not in augmented_clusters:\n",
    "        print('Should not happen', label)\n",
    "        continue\n",
    "    aug_centroid = augmented_clusters[label]['centroid']\n",
    "    sim = cosine_similarity([centroid], [aug_centroid])[0][0]\n",
    "    if sim < 0.8:\n",
    "        cnt += 1\n",
    "        print()\n",
    "        print(label)\n",
    "        print('1', len(clusters[label]['names']), clusters[label]['names'])\n",
    "        print('2', len(augmented_clusters[label]['names']), augmented_clusters[label]['names'])\n",
    "    sims.append(sim)\n",
    "cnt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09ea27bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.hist(sims, bins=100, label=\"sim\", color='green')\n",
    "plt.legend(loc='upper right')\n",
    "# Show the plot\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5146991",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nama",
   "language": "python",
   "name": "nama"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

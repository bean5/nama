{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2907945b",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b2dac44",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Train a greedy clustering model\n",
    "Add names to clusters from most-frequent to least-frequent, \n",
    "with a clustering threshold that varies based upon frequency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d131857",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from collections import Counter, defaultdict\n",
    "import math\n",
    "import random\n",
    "\n",
    "import boto3\n",
    "import jellyfish\n",
    "import pandas as pd\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import torch\n",
    "from tqdm.autonotebook import tqdm\n",
    "\n",
    "from src.data.normalize import normalize_freq_names\n",
    "from src.data.filesystem import fopen\n",
    "from src.eval.freq_metrics import calc_avg_precision_recall\n",
    "from src.models.cluster import write_clusters\n",
    "from src.models.swivel import SwivelModel\n",
    "from src.models.utils import add_padding\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b54bdec3",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# configure\n",
    "given_surname = \"given\"\n",
    "vocab_size = 610000 if given_surname == \"given\" else 2100000\n",
    "n_jobs = 8\n",
    "\n",
    "embed_dim = 100\n",
    "verbose = True\n",
    "\n",
    "tree_freq_path=f\"s3://familysearch-names/processed/tree-preferred-{given_surname}-aggr.csv.gz\"\n",
    "train_path = f\"s3://familysearch-names/processed/tree-hr-{given_surname}-train-v2.csv.gz\"\n",
    "swivel_vocab_path=f\"s3://nama-data/data/models/fs-{given_surname}-swivel-vocab-{vocab_size}-augmented.csv\"\n",
    "swivel_model_path=f\"s3://nama-data/data/models/fs-{given_surname}-swivel-model-{vocab_size}-{embed_dim}-augmented.pth\"\n",
    "query_path = f\"s3://familysearch-names/processed/query-names-{given_surname}-v2.csv.gz\"\n",
    "nickname_bucket = \"familysearch-names\"\n",
    "nickname_path = \"processed/givenname_nicknames.csv\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4190d2c0",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3aa76e0e",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f282f6c7",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "freq_df = pd.read_csv(tree_freq_path, na_filter=False)\n",
    "tree_name_freq = normalize_freq_names(freq_df, \n",
    "                                      is_surname=given_surname != \"given\", \n",
    "                                      add_padding=False,\n",
    "                                      dont_return_empty=False)\n",
    "freq_df = None\n",
    "tree_name_freq['mary' if given_surname == 'given' else 'johnson']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd557247",
   "metadata": {},
   "outputs": [],
   "source": [
    "name_counter = Counter(tree_name_freq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ba98139",
   "metadata": {},
   "outputs": [],
   "source": [
    "for ix, (name, freq) in enumerate(name_counter.most_common()):\n",
    "    if name == \"vicky\":\n",
    "        print(ix, name, freq)\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e4ca49f",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "vocab_df = pd.read_csv(fopen(swivel_vocab_path, \"rb\"), na_filter=False)\n",
    "swivel_vocab = {name: _id for name, _id in zip(vocab_df[\"name\"], vocab_df[\"index\"])}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7597e75d",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "swivel_model = SwivelModel(len(swivel_vocab), embed_dim)\n",
    "swivel_model.load_state_dict(torch.load(fopen(swivel_model_path, \"rb\"), map_location=torch.device(device)))\n",
    "swivel_model.to(device)\n",
    "swivel_model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f5157ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "s3 = boto3.resource('s3')\n",
    "\n",
    "# these nicknames include nickname heads going to themselves (e.g., john -> john)\n",
    "nicknames = defaultdict(set)\n",
    "if given_surname == \"given\":\n",
    "    obj = s3.Object(nickname_bucket, nickname_path)\n",
    "    contents = obj.get()['Body'].read().decode('utf-8')\n",
    "    for ix, line in enumerate(contents.split('\\n')):\n",
    "        line = line.strip()\n",
    "        names = line.split(',')\n",
    "        headname = names[0]\n",
    "        for name in names:\n",
    "            nicknames[name].add(headname)\n",
    "print(len(nicknames))\n",
    "print(nicknames['zachery'])\n",
    "print(nicknames['zachariah'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b215bc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "query_names = pd.read_csv(query_path, na_filter=False)[\"name\"].tolist()\n",
    "print(len(query_names))\n",
    "query_names[0:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74186497",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv(train_path, na_filter=False)\n",
    "print(train_df.shape)\n",
    "train_df.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5802942e",
   "metadata": {},
   "source": [
    "## Greedy Cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b1acd30",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cluster(name_counter, nicknames, swivel_vocab, swivel_model, \n",
    "            n_to_cluster, threshold):\n",
    "    \n",
    "    clustered_names = []\n",
    "    clustered_vectors = []\n",
    "    name2clusters = defaultdict(set)\n",
    "    cluster2names = defaultdict(set)\n",
    "    count = 0\n",
    "    name_freqs = name_counter.most_common(n_to_cluster)\n",
    "    # add nicknames to names to cluster\n",
    "    if given_surname == \"given\":\n",
    "        names_to_cluster = set(name for name, _ in name_freqs)\n",
    "        for nickname in nicknames.keys():\n",
    "            if nickname not in names_to_cluster:\n",
    "                print(\"adding\", nickname)\n",
    "                names_to_cluster.add(nickname)\n",
    "                name_freqs.append((nickname, 1))\n",
    "            \n",
    "    for name, freq in tqdm(name_freqs):\n",
    "        # print stats periodically\n",
    "        if count % 10000 == 0:\n",
    "            print(count, 'n_clusters', len(cluster2names))\n",
    "        count += 1\n",
    "        \n",
    "        # get name vector\n",
    "        name_ix = swivel_vocab.get(add_padding(name), -1)\n",
    "        if name_ix < 0:\n",
    "            continue\n",
    "        name_vector = swivel_model.wi.weight.data[name_ix].cpu().numpy()\n",
    "\n",
    "        # is this the first name?\n",
    "        if len(clustered_names) == 0:\n",
    "            name2clusters[name].add(name)\n",
    "            cluster2names[name].add(name)\n",
    "            \n",
    "        # compare name vector to clustered vectors\n",
    "        else:\n",
    "            scores = cosine_similarity([name_vector], clustered_vectors)[0]\n",
    "            max_score_ix = max(range(len(scores)), key=lambda i: scores[i])\n",
    "            # is name vector within threshold to an existing clustered name?\n",
    "            if scores[max_score_ix] >= threshold:\n",
    "                # add the name to the same cluster as the nearest name\n",
    "                nearest_name = clustered_names[max_score_ix]\n",
    "                for cluster in name2clusters[nearest_name]:\n",
    "                    name2clusters[name].add(cluster)\n",
    "                    cluster2names[cluster].add(name)\n",
    "            else:\n",
    "                # otherwise, create a new cluster\n",
    "                cluster = name\n",
    "                name2clusters[name].add(cluster)\n",
    "                cluster2names[cluster].add(name)\n",
    "                \n",
    "        # add name to clustered names\n",
    "        # TODO consider only adding cluster heads to clustered names + vectors\n",
    "        clustered_names.append(name)\n",
    "        clustered_vectors.append(name_vector)\n",
    "        \n",
    "    return name2clusters, cluster2names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d742bac",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _get_nama_standards(nicknames, name2clusters, name):\n",
    "    standards = set()\n",
    "    lookups = set([name])\n",
    "    if given_surname == \"given\" and name in nicknames:\n",
    "        lookups.update(nicknames[name])\n",
    "    for lookup in lookups:\n",
    "        if lookup in name2clusters:\n",
    "            standards.update(name2clusters[lookup])\n",
    "    return standards\n",
    "\n",
    "def get_nama_nysiis(nicknames, name2clusters, names):\n",
    "    # name2codes simulates query: given a name, what codes to lookup\n",
    "    name2codes = defaultdict(set)\n",
    "    # code2names simulates index: given acode, what names are indexed under that code\n",
    "    code2names = defaultdict(set)\n",
    "    for name in names:\n",
    "        # get codes for name\n",
    "        codes = name2clusters[name] if name in name2clusters else set()\n",
    "        for code in codes:\n",
    "            # query each code for the name\n",
    "            name2codes[name].add(code)\n",
    "            # index name under each code\n",
    "            code2names[code].add(name)\n",
    "        # always query nysiis for the name\n",
    "        nysiis_code = jellyfish.nysiis(name)\n",
    "        # always query nysiis code\n",
    "        name2codes[name].add(nysiis_code)\n",
    "        # add name to nysiis bucket only if it isn't in another bucket\n",
    "        if len(codes) == 0:\n",
    "            code2names[nysiis_code].add(name)\n",
    "        # query codes for each nickname\n",
    "        if given_surname == \"given\" and name in nicknames:\n",
    "            for nickhead in nicknames[name]:\n",
    "                if nickhead in name2clusters:\n",
    "                    for code in name2clusters[nickhead]:\n",
    "                        name2codes[name].add(code)\n",
    "    return name2codes, code2names\n",
    "\n",
    "def eval_clusters(nicknames, name2clusters, train_df, query_names):\n",
    "        name2codes, code2names = get_nama_nysiis(nicknames,\n",
    "                                                 name2clusters,\n",
    "                                                 set(train_df[\"tree_name\"]) | set(train_df[\"record_name\"]))\n",
    "        print(\"total names\", len(name2codes))\n",
    "        print(\"total index entries\", sum(len(names) for names in code2names.values()))\n",
    "        print(\"total codes\", len(code2names))\n",
    "        print(\"total queries\", len(query_names))\n",
    "        print(\"total lookups\", sum(len(name2codes[query]) for query in query_names))\n",
    "        precision, recall, f1, f2 = calc_avg_precision_recall(query_names, name2codes, code2names, train_df)\n",
    "        print(f\"precision={precision}, recall={recall} f1={f1} f2={f2}\")    \n",
    "\n",
    "def save_clusters(path, cluster2names):\n",
    "    all_names = []\n",
    "    all_clusters = []\n",
    "    for cluster_id, names in cluster2names.items():\n",
    "        for name in names:\n",
    "            all_clusters.append(cluster_id)\n",
    "            all_names.append(name)\n",
    "    df = pd.DataFrame({\"name\": all_names, \"cluster\": all_clusters})\n",
    "    df.to_csv(path, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eaf09d31",
   "metadata": {},
   "source": [
    "## Hyperparameter Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91168206",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_to_cluster_values = [100000]\n",
    "threshold_values = [0.7]\n",
    "\n",
    "hyperparameters = []\n",
    "for n_to_cluster in n_to_cluster_values:\n",
    "    for threshold in threshold_values:\n",
    "        hyperparameters.append({\n",
    "            'n_to_cluster': n_to_cluster,\n",
    "            'threshold': threshold,\n",
    "        })\n",
    "print(len(hyperparameters))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e7e9fb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "for hyperparameter in hyperparameters:\n",
    "    print(hyperparameter)\n",
    "    name2clusters, cluster2names = cluster(name_counter, \n",
    "                                           nicknames, \n",
    "                                           swivel_vocab, \n",
    "                                           swivel_model, \n",
    "                                           **hyperparameter)\n",
    "    eval_clusters(nicknames, name2clusters, train_df, query_names)\n",
    "    path = f\"../data/models/fs-{given_surname}-cluster-greedy-{hyperparameter['n_to_cluster']}-threshold_{hyperparameter['threshold']}.csv\"\n",
    "    # save_clusters(path, cluster2names)\n",
    "    print(len(cluster2names), path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbbb33e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "for hyperparameter in hyperparameters:\n",
    "    print(hyperparameter)\n",
    "    name2clusters, cluster2names = cluster(name_counter, \n",
    "                                           nicknames, \n",
    "                                           swivel_vocab, \n",
    "                                           swivel_model, \n",
    "                                           **hyperparameter)\n",
    "    eval_clusters(nicknames, name2clusters, train_df, query_names)\n",
    "    path = f\"../data/models/fs-{given_surname}-cluster-greedy-{hyperparameter['n_to_cluster']}-upper_{hyperparameter['upper']}-lower_{hyperparameter['lower']}-high_freq_ix_{hyperparameter['high_freq_ix']}-low_freq_ix_{hyperparameter['low_freq_ix']}.csv\"\n",
    "    save_clusters(path, cluster2names)\n",
    "    print(len(cluster2names), path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f08af9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "for hyperparameter in hyperparameters:\n",
    "    print(hyperparameter)\n",
    "    name2clusters, cluster2names = cluster(name_counter, \n",
    "                                           nicknames, \n",
    "                                           swivel_vocab, \n",
    "                                           swivel_model, \n",
    "                                           **hyperparameter)\n",
    "    eval_clusters(nicknames, name2clusters, train_df, query_names)\n",
    "    path = f\"../data/models/fs-{given_surname}-cluster-greedy-{hyperparameter['n_to_cluster']}-threshold_{hyperparameter['threshold']}.csv\"\n",
    "    # save_clusters(path, cluster2names)\n",
    "    print(len(cluster2names), path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5549e2fb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nama",
   "language": "python",
   "name": "nama"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

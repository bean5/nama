{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffc470e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88416416",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.sparse import vstack\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.utils.extmath import safe_sparse_dot\n",
    "from tqdm import tqdm\n",
    "\n",
    "from src.data.ancestry import load_train_test\n",
    "from src.metrics import metrics\n",
    "from src.models import utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc72b337",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.set_printoptions(suppress=True)\n",
    "tqdm.pandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94bc468b",
   "metadata": {},
   "source": [
    "### Load and process data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eeade0d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Only need to run this once\n",
    "# It we split the data into train/test and will persist the data on disk\n",
    "# dataset.load_split_init(test_size=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b34568c",
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = load_train_test(f\"../data/raw/records25k_data_train.csv\", f\"../data/raw/records25k_data_test.csv\")\n",
    "\n",
    "input_names_train, weighted_actual_names_train, candidate_names_train = train\n",
    "input_names_test, weighted_actual_names_test, candidate_names_test = test\n",
    "\n",
    "candidate_names_all = np.concatenate((candidate_names_train, candidate_names_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40dad3cb",
   "metadata": {},
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "197ff22b",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer(ngram_range=(1, 3), analyzer=\"char_wb\", min_df=10, max_df=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c87171f",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = vectorizer.fit_transform(candidate_names_train)\n",
    "X_test = vectorizer.transform(candidate_names_test)\n",
    "X_all = vstack((X_train, X_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d0e494c",
   "metadata": {},
   "source": [
    "#### Similarity Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae30193c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_similars(name, k=10, demo_mode=False):\n",
    "    if demo_mode:\n",
    "        name = utils.add_padding(name)\n",
    "    x = vectorizer.transform([name]).toarray()\n",
    "    scores = safe_sparse_dot(X_all, x.T).flatten()\n",
    "    sorted_scores_idx = np.argsort(scores)[::-1][:k]\n",
    "    candidates = candidate_names_all[sorted_scores_idx]\n",
    "    if demo_mode:\n",
    "        candidates = [utils.remove_padding(candidate) for candidate in candidates]\n",
    "    candidates_scores = scores[sorted_scores_idx]\n",
    "\n",
    "    return list(zip(candidates, candidates_scores))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac46b393",
   "metadata": {},
   "source": [
    "#### Demo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbab0ce5",
   "metadata": {},
   "outputs": [],
   "source": [
    "get_similars(\"schumacher\", 10, True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e4dd15e",
   "metadata": {},
   "source": [
    "### Generate candidates for all test names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5853d0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "k = 100  # Number of candidates to consider\n",
    "similar_names_scores_test = list(map(lambda x: get_similars(x, k=k), tqdm(input_names_test)))\n",
    "similar_names_test = np.array(similar_names_scores_test)[:, :, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dc9280a",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(similar_names_scores_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a313ae35",
   "metadata": {},
   "source": [
    "#### Ugh - how can I create a 3D array with (str, float) as the third axis without taking apart and re-assembling the array?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f7705a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# names is a 2D array axis 0 = names, axis 1 = name of k similar-names\n",
    "names = np.array(list(list(cell[0] for cell in row) for row in similar_names_scores_test), dtype=\"O\")\n",
    "# scores is a 2D array axis 0 = names, axis 1 = score of k similar-names\n",
    "scores = np.array(list(list(cell[1] for cell in row) for row in similar_names_scores_test), dtype=\"f8\")\n",
    "# similar_names_test is now a 3D array axis 0 = names, axis 1 = k similar-names, axis 2 = name or score\n",
    "similar_names_scores_test = np.dstack((names, scores))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f978f156",
   "metadata": {},
   "source": [
    "### Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f10fb3a5",
   "metadata": {},
   "source": [
    "### Average precision @0.65"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7c71eb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics.avg_precision_at_threshold(weighted_actual_names_test, similar_names_scores_test, 0.65)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4670887d",
   "metadata": {},
   "source": [
    "### Average recall @0.65"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20aea89c",
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics.avg_weighted_recall_at_threshold(weighted_actual_names_test, similar_names_scores_test, 0.65)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56095684",
   "metadata": {},
   "source": [
    "### Precision-Recall Curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "504827fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# minimum score threshold to test\n",
    "min_threshold = 0.5\n",
    "metrics.precision_weighted_recall_curve_at_threshold(\n",
    "    weighted_actual_names_test, similar_names_scores_test, min_threshold\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97d09412",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Remove weights for mean average precision evaluations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16aaa599",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "actual_names_test = [[name for name, _, _ in name_weights] for name_weights in weighted_actual_names_test]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61b79811",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### mAP@1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5917b58",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "metrics.mean_avg_precision_k(actual_names_test, similar_names_test, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e62b8d6d",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### mAP@3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6446b8df",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "metrics.mean_avg_precision_k(actual_names_test, similar_names_test, 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f07b0d2",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Precision-Recall Curve at k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "069008c6",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Number of rank cutoffs to test i.e precision_{i}, recall_{i} for i in (1, ..., N)\n",
    "N = 100\n",
    "metrics.precision_recall_curve_at_k(actual_names_test, similar_names_test, N)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91506272",
   "metadata": {},
   "source": [
    "### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "519cfc95",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_names_test[251]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d222b4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "weighted_actual_names_test[251]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7864fcd8",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "pd.DataFrame(similar_names_scores_test[251, 0:10], columns=[\"name\", \"score\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8535d3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics.weighted_recall_at_threshold(weighted_actual_names_test[251], similar_names_scores_test[251], 0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b4737c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics.weighted_recall_at_threshold(weighted_actual_names_test[251], similar_names_scores_test[251], 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f3fe1e7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nama",
   "language": "python",
   "name": "nama"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2882991e",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d671df72",
   "metadata": {},
   "source": [
    "# Split buckets into clusters and super-clusters using cross-encoder\n",
    "\n",
    "Load the parser and trained model, and use a hierarchal agglomerative clustering algorithm to split existing FamilySearch buckets into clusters and super-clusters based upon similarity computed using the cross-encoder model. Each cluster contains the names in the bucket that the model determines are similar to each other, and each super-cluster contains all of the clusters in the bucket.\n",
    "\n",
    "Each cluster contains:\n",
    "\n",
    "1. a list of names, \n",
    "2. the most-common name as the cluster label, and \n",
    "3. a cluster centroid: a vector depicting the center of the cluster using a bi-encoder. \n",
    "\n",
    "Each super-cluster contains:\n",
    "\n",
    "1. a list of cluster labels\n",
    "2. the most-common name in the cluster as the super-cluster label\n",
    "\n",
    "If a bucket has only one cluster, we don't create a super-cluster for the bucket.\n",
    "\n",
    "When determine which cluster a rare name belongs to, we will choose the closest centroid.\n",
    "\n",
    "The questions to answer are:\n",
    "\n",
    "1. What should the threshold be?\n",
    "\n",
    "ISSUES\n",
    "- cross-encoder scores much lower than bi-encoder: why?\n",
    "    - do we need to combine both scores?\n",
    "    - is cross-encoder really wrong when it scores near 0?\n",
    "- why is the cross-encoder score so much lower than the bi-encoder score?\n",
    "- is taking the average cross-encoder score the right thing to do?\n",
    "    - what about taking the max score for each name, and then averaging the maximums???\n",
    "- does the problem go away if we take the average of the two ce scores instead of the harmonic mean?\n",
    "    - is the bi-encoder closer to the average or the harmonic mean?\n",
    "- we should try to **graph** correlation between Y=bi-encoder score and X=average vs harmonic mean of ce score\n",
    "- when you sort the two scores, is the order different?\n",
    "\n",
    "larger ttest is better, smaller mann is better\n",
    "t_ttest, _ = ttest_ind(random_pair_scores, non_negative_scores, equal_var=False)\n",
    "t_mann, _  = mannwhitneyu(random_pair_scores, non_negative_scores, use_continuity=False)\n",
    "print(int(abs(t_ttest)), int(t_mann/1_000_000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ab5d9f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "import json\n",
    "import math\n",
    "import os\n",
    "import random\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sentence_transformers.cross_encoder import CrossEncoder\n",
    "from sklearn.cluster import AgglomerativeClustering\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from statistics import harmonic_mean\n",
    "import torch\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "from src.models.biencoder import BiEncoder\n",
    "from src.models.tokenizer import get_tokenize_function_and_vocab\n",
    "from src.models.utils import get_cross_encoder_score\n",
    "\n",
    "os.environ['TOKENIZERS_PARALLELISM'] = 'true'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ff83f53",
   "metadata": {},
   "outputs": [],
   "source": [
    "# configure\n",
    "given_surname = \"given\"\n",
    "\n",
    "linkage = \"average\"  # average, complete\n",
    "scorer = \"ce\"  # be, ce, or cebe\n",
    "similarity_threshold = 0.1  # be=0.3, ce=0.08 or 0.10 or 0.15, cebe=0.28\n",
    "cluster_freq_normalizer = \"none\"  # log, log10, none\n",
    "\n",
    "experiment_name = f\"{linkage}-{similarity_threshold}-{cluster_freq_normalizer}\"\n",
    "\n",
    "max_tokens = 10\n",
    "subwords_path=f\"../data/models/fs-{given_surname}-subword-tokenizer-2000f.json\"\n",
    "std_path = f\"../references/std_{given_surname}.txt\"\n",
    "tokenizer_max_length = 32\n",
    "ce_model_dir = f\"../data/models/cross-encoder-{given_surname}-10m-265-same-all\"\n",
    "be_model_type = 'cecommon+0+aug-0-1'\n",
    "be_model_path = f\"../data/models/bi_encoder-{given_surname}-{be_model_type}.pth\"\n",
    "pref_path = f\"s3://familysearch-names/processed/tree-preferred-{given_surname}-aggr.csv.gz\"\n",
    "\n",
    "# experiment_dir = f\"../reports/\"\n",
    "clusters_path = f\"../data/processed/clusters_{given_surname}-{scorer}-{linkage}-{similarity_threshold}-{cluster_freq_normalizer}.json\"\n",
    "super_clusters_path = f\"../data/processed/super_clusters_{given_surname}-{scorer}-{linkage}-{similarity_threshold}-{cluster_freq_normalizer}.json\"\n",
    "clusters_path"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad87f02c",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56affce8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_cluster_freq(name):\n",
    "    freq = name_freq.get(name, 0)\n",
    "    if cluster_freq_normalizer == \"log\":\n",
    "        return max(1, math.floor(math.log(max(1,freq))))\n",
    "    elif cluster_freq_normalizer == \"log10\":\n",
    "        return max(1, math.floor(math.log10(max(1,freq))))\n",
    "    else:\n",
    "        return 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "deaa1fe1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load buckets\n",
    "bucket_names = defaultdict(set)\n",
    "name_buckets = defaultdict(set)\n",
    "with open(std_path, 'rt') as f:\n",
    "    for line in f.readlines():\n",
    "        names = line.strip().replace(':', ' ').split(' ')\n",
    "        bucket_name = names[0]\n",
    "        for name in names:\n",
    "            name = name.strip()\n",
    "            if len(name) == 0:\n",
    "                continue\n",
    "            bucket_names[bucket_name].add(name)\n",
    "            name_buckets[name].add(bucket_name)\n",
    "print(len(bucket_names), len(name_buckets))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf12581a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load pref names\n",
    "pref_df = pd.read_csv(pref_path, na_filter=False)\n",
    "name_freq = {name: freq for name, freq in zip(pref_df['name'], pref_df['frequency'])}\n",
    "pref_df = None\n",
    "print(len(name_freq))\n",
    "print('john', name_freq['john'], get_cluster_freq('john'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec03d8e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "cnt = 0\n",
    "for name in name_buckets:\n",
    "    if name not in name_freq:\n",
    "        cnt += 1\n",
    "        print(name)\n",
    "print(cnt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "356cb540",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_most_freq_name(names):\n",
    "    most_freq_name = None\n",
    "    most_freq_freq = None\n",
    "    for name in names:\n",
    "        freq = name_freq.get(name, 0)\n",
    "        if most_freq_name is None or freq > most_freq_freq:\n",
    "            most_freq_name = name\n",
    "            most_freq_freq = freq\n",
    "    return most_freq_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d701cfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load tokenize function\n",
    "tokenize, tokenizer_vocab = get_tokenize_function_and_vocab(\n",
    "    max_tokens=max_tokens,\n",
    "    subwords_path=subwords_path,\n",
    ")\n",
    "len(tokenizer_vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8768fe48",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load bi-encoder model\n",
    "be_model = torch.load(be_model_path)\n",
    "be_model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f558fb51",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load cross encoder model\n",
    "ce_model = CrossEncoder(ce_model_dir, max_length=tokenizer_max_length)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb9fea5e",
   "metadata": {},
   "source": [
    "## Compute Bi-Encoder Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9928bcfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "name_embedding = {}\n",
    "for names in tqdm(bucket_names.values()):\n",
    "    for name in names:\n",
    "        embedding = be_model.get_embedding(tokenize(name))\n",
    "        name_embedding[name] = embedding"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f71ea56",
   "metadata": {},
   "source": [
    "## Compare Bi-encoder and Cross-encoder scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a54ac523",
   "metadata": {},
   "outputs": [],
   "source": [
    "bi_encoder_scores = []\n",
    "ce_avg_scores = []\n",
    "ce_harmonic_scores = []\n",
    "ce_max_scores = []\n",
    "\n",
    "for bucket_name, names in tqdm(bucket_names.items()):\n",
    "    if len(names) == 1:\n",
    "        continue\n",
    "    # compute X and clustered_names\n",
    "    X = []\n",
    "    names = list(names)\n",
    "    for name1 in random.sample(names, min(len(names), 3)):\n",
    "        for name2 in random.sample(names, min(len(names), 3)):\n",
    "            if name1 == name2:\n",
    "                continue\n",
    "            # compute bi-encoder score\n",
    "            emb1 = name_embedding[name1]\n",
    "            emb2 = name_embedding[name2]\n",
    "            bi_encoder_score = cosine_similarity([emb1], [emb2])[0][0]\n",
    "            # compute cross-encoder scores\n",
    "            ce_scores = ce_model.predict([[name1, name2], [name2, name1]])\n",
    "            ce_harmonic_score = harmonic_mean([ce_scores[0], ce_scores[1]])\n",
    "            ce_avg_score = (ce_scores[0]+ce_scores[1])/2\n",
    "            ce_max_score = max(ce_scores[0], ce_scores[1])\n",
    "            # save them\n",
    "            bi_encoder_scores.append(bi_encoder_score)\n",
    "            ce_harmonic_scores.append(ce_harmonic_score)\n",
    "            ce_avg_scores.append(ce_avg_score)\n",
    "            ce_max_scores.append(ce_max_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72e8461d",
   "metadata": {},
   "outputs": [],
   "source": [
    "for ix, (h, a, m) in enumerate(zip(ce_harmonic_scores, ce_avg_scores, ce_max_scores)):\n",
    "    if ix > 20:\n",
    "        break\n",
    "    print(h, a, m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "697ed8a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(bi_encoder_scores), len(ce_harmonic_scores), len(ce_avg_scores), len(ce_max_scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "686b6d0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(bi_encoder_scores, ce_harmonic_scores, s=1, alpha=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5185ef12",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(bi_encoder_scores, ce_avg_scores, s=1, alpha=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9bf00c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(bi_encoder_scores, ce_max_scores, s=1, alpha=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5873ec0",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 6))\n",
    "plt.hist(bi_encoder_scores, bins=100, alpha=0.5, label=\"bi-encoder\", color='green')\n",
    "plt.hist(ce_harmonic_scores, bins=100, alpha=0.5, label=\"cross-encoder\", color='red')\n",
    "plt.legend(loc='upper right')\n",
    "# Show the plot\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bf39b3f",
   "metadata": {},
   "source": [
    "## Cluster names"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3367ceb",
   "metadata": {},
   "source": [
    "### create clusterer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eee9e679",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_row(name, names, scorer=\"ce\"):  # scorer=ce, ce, be, or cebe\n",
    "    # compute pairs\n",
    "    pairs = []\n",
    "    if scorer != \"be\":\n",
    "        for name2 in names:\n",
    "            if name2 != name:\n",
    "                pairs.append([name, name2])\n",
    "                pairs.append([name2, name])\n",
    "        if len(pairs) > 0:\n",
    "            scores = ce_model.predict(pairs)\n",
    "    # construct row\n",
    "    row = []\n",
    "    ix = 0\n",
    "    for name2 in names:\n",
    "        score = 0.0\n",
    "        if scorer != \"be\":\n",
    "            if name2 == name:\n",
    "                score = 1.0\n",
    "            else:\n",
    "                score = harmonic_mean([scores[ix], scores[ix+1]])\n",
    "                ix += 2\n",
    "        if scorer == \"be\" or (scorer == \"cebe\" and score < 0.2):\n",
    "            emb1 = name_embedding[name]\n",
    "            emb2 = name_embedding[name2]\n",
    "            score = cosine_similarity([emb1], [emb2])[0][0]\n",
    "                \n",
    "        # store the distance between name and name2\n",
    "        for _ in range(get_cluster_freq(name2)):\n",
    "            row.append(1.0 - score)\n",
    "    return row"
   ]
  },
  {
   "cell_type": "raw",
   "id": "b9caeb8e",
   "metadata": {},
   "source": [
    "# test different hyperparameters\n",
    "similarity_threshold = 0.15  # be=0.3, ce=0.08 or 0.15, cebe=0.28\n",
    "linkage = \"average\"\n",
    "# be, ce, cebe\n",
    "scorer = \"ce\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44d81f4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "clusterer = AgglomerativeClustering(\n",
    "    n_clusters=None,\n",
    "    metric=\"precomputed\",\n",
    "    linkage=linkage,\n",
    "    distance_threshold=(1-similarity_threshold),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7375094e",
   "metadata": {},
   "source": [
    "### test clusterer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb1f29ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "# test_names = ['david', 'dan', 'daniel', 'dave']  # , 'darris', 'darrin', 'daren',\n",
    "#               'abraham','abe','aabraham','ab','abaham','abaraham','abarham','abb',\n",
    "#               'abelarde','abera','aberaham']\n",
    "# test_names = ['maholy', 'malay', 'mauley', 'ma', 'mala']\n",
    "test_names = bucket_names['elizabeth']\n",
    "print(len(test_names))\n",
    "X = []\n",
    "names = []\n",
    "for name in test_names:\n",
    "    row = compute_row(name, test_names, scorer)\n",
    "    for _ in range(get_cluster_freq(name)):\n",
    "        names.append(name)\n",
    "        X.append(row)\n",
    "print(len(X))\n",
    "clustering = clusterer.fit(X)\n",
    "clusters = [set() for _ in range(clustering.n_clusters_)]\n",
    "if scorer == \"be\":\n",
    "    be_clusters = clusters\n",
    "elif scorer == \"ce\":\n",
    "    ce_clusters = clusters\n",
    "elif scorer == \"cebe\":\n",
    "    cebe_clusters = clusters\n",
    "print('n_clusters', clustering.n_clusters_)\n",
    "print('labels', clustering.labels_)\n",
    "print('names', names)\n",
    "for name, cluster in zip(names, clustering.labels_):\n",
    "    clusters[cluster].add(name)\n",
    "for cluster in clusters:\n",
    "    print()\n",
    "    print('cluster', get_most_freq_name(cluster), ':', cluster)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1876e73",
   "metadata": {},
   "outputs": [],
   "source": [
    "ce_15_clusters = ce_clusters\n",
    "print(len(ce_15_clusters))\n",
    "for cluster in ce_15_clusters:\n",
    "    print()\n",
    "    print('cluster', get_most_freq_name(cluster), ':', cluster)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b22a8505",
   "metadata": {},
   "outputs": [],
   "source": [
    "ce_20_clusters = ce_clusters\n",
    "print(len(ce_20_clusters))\n",
    "for cluster in ce_20_clusters:\n",
    "    print()\n",
    "    print('cluster', get_most_freq_name(cluster), ':', cluster)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2575be87",
   "metadata": {},
   "outputs": [],
   "source": [
    "ce_25_clusters = ce_clusters\n",
    "print(len(ce_25_clusters))\n",
    "for cluster in ce_25_clusters:\n",
    "    print()\n",
    "    print('cluster', get_most_freq_name(cluster), ':', cluster)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea2d69f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_be_score(name1, name2):\n",
    "    emb1 = name_embedding[name1]\n",
    "    emb2 = name_embedding[name2]\n",
    "    return cosine_similarity([emb1], [emb2])[0][0]\n",
    "           \n",
    "def get_ce_score(name1, name2):\n",
    "    scores = ce_model.predict([[name1, name2], [name2, name1]])\n",
    "    print(scores)\n",
    "    return harmonic_mean([scores[0], scores[1]])\n",
    "\n",
    "name1 = 'mauley'\n",
    "name2 = 'mala'\n",
    "print(get_be_score(name1, name2), get_ce_score(name1, name2))\n",
    "print(compute_row(name1, [name2], scorer=\"ce\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30331a86",
   "metadata": {},
   "source": [
    "### run clusterer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f300cec",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(scorer, linkage, similarity_threshold, clusters_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f12c0ec3",
   "metadata": {},
   "outputs": [],
   "source": [
    "clusterer = AgglomerativeClustering(\n",
    "    n_clusters=None,\n",
    "    metric=\"precomputed\",\n",
    "    linkage=linkage,\n",
    "    distance_threshold=(1-similarity_threshold),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55325152",
   "metadata": {},
   "outputs": [],
   "source": [
    "bucket_clusters = {}\n",
    "for bucket_name, names in tqdm(bucket_names.items()):\n",
    "    if len(names) == 1:\n",
    "        bucket_clusters[bucket_name] = [names]\n",
    "    else:\n",
    "        # compute X and clustered_names\n",
    "        X = []\n",
    "        clustered_names = []\n",
    "        for name in names:\n",
    "            row = compute_row(name, names, scorer)\n",
    "            for _ in range(get_cluster_freq(name)):\n",
    "                clustered_names.append(name)\n",
    "                X.append(row)\n",
    "        X = np.array(X)\n",
    "        # cluster\n",
    "        clustering = clusterer.fit(X)\n",
    "        # create the clusters\n",
    "        clusters = [set() for _ in range(clustering.n_clusters_)]\n",
    "        for name, cluster in zip(clustered_names, clustering.labels_):\n",
    "            clusters[cluster].add(name)\n",
    "        bucket_clusters[bucket_name] = clusters\n",
    "len(bucket_clusters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2eff716",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\n",
    "    len(bucket_clusters), \n",
    "    sum(len(bucket_cluster) for bucket_cluster in bucket_clusters.values()),\n",
    "    sum(sum(len(cluster) for cluster in clusters) for clusters in bucket_clusters.values())  \n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36337a99",
   "metadata": {},
   "source": [
    "## Evaluate results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dadc595",
   "metadata": {},
   "outputs": [],
   "source": [
    "bucket_cluster_total = sum(len(clusters) for clusters in bucket_clusters.values())\n",
    "print(len(bucket_clusters), bucket_cluster_total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86360730",
   "metadata": {},
   "outputs": [],
   "source": [
    "# what about the top 100, 1000 names?\n",
    "total_clusters = 0\n",
    "total_names = 0\n",
    "for ix, name in enumerate(name_freq.keys()):\n",
    "    if ix % 100 == 0 and ix > 0:\n",
    "        print(total_names, total_clusters / total_names)\n",
    "    if ix == 2000:\n",
    "        break\n",
    "    if name not in name_buckets:\n",
    "        continue\n",
    "    bucket_name = next(iter(name_buckets[name]))\n",
    "    total_clusters += len(bucket_clusters[bucket_name])\n",
    "    total_names += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a05c438",
   "metadata": {},
   "outputs": [],
   "source": [
    "for name in list(name_freq.keys())[:10]:\n",
    "    if name not in name_buckets:\n",
    "        continue\n",
    "    bucket_name = next(iter(name_buckets[name]))\n",
    "    print('***', name, bucket_name)\n",
    "    for ix, cluster in enumerate(bucket_clusters[bucket_name]):\n",
    "        print(' ', ix, get_most_freq_name(cluster), ':', ' '.join(cluster))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7efe7a89",
   "metadata": {},
   "source": [
    "### Write experiment report\n",
    "\n",
    "deprecated"
   ]
  },
  {
   "cell_type": "raw",
   "id": "87a1a1b7",
   "metadata": {},
   "source": [
    "# gather every 25'th name into an experiment\n",
    "experiment = {}\n",
    "for ix, (bucket_name, clusters) in enumerate(bucket_clusters.items()):\n",
    "    if ix % 25 != 0:\n",
    "        continue\n",
    "    experiment[bucket_name] = clusters"
   ]
  },
  {
   "cell_type": "raw",
   "id": "0d653f96",
   "metadata": {},
   "source": [
    "def name_sort_key(name):\n",
    "    freq = name_freq.get(name, 0)\n",
    "    return f\"{freq:12d}:{name}\""
   ]
  },
  {
   "cell_type": "raw",
   "id": "7fbade36",
   "metadata": {},
   "source": [
    "lines = []\n",
    "lines.append(f\"Experiment: {experiment_name}\")\n",
    "lines.append(f\"sub-buckets={bucket_cluster_total}\")\n",
    "for bucket_name, clusters in experiment.items():\n",
    "    lines.append(bucket_name)\n",
    "    clusters.sort(key=lambda cluster: name_sort_key(get_most_freq_name(cluster)), reverse=True)\n",
    "    for cluster in clusters:\n",
    "        cluster.sort(key=name_sort_key, reverse=True)\n",
    "        lines.append(f\"- {get_most_freq_name(cluster)}: {' '.join(cluster)}\")"
   ]
  },
  {
   "cell_type": "raw",
   "id": "07b04218",
   "metadata": {},
   "source": [
    "for line in lines:\n",
    "    print(line)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "cc1752f9",
   "metadata": {},
   "source": [
    "experiment_name"
   ]
  },
  {
   "cell_type": "raw",
   "id": "fd11adf9",
   "metadata": {},
   "source": [
    "experiment_filename = f\"{experiment_name}.txt\"\n",
    "with open(os.path.join(experiment_dir, experiment_filename), 'wt') as f:\n",
    "    f.write(\"\\n\".join(lines))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cbfb4ce",
   "metadata": {},
   "source": [
    "## Save Clusters and Super-Clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "582d08b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_cluster_centroid(cluster):\n",
    "    centroid = None\n",
    "    for name in cluster:\n",
    "        embedding = name_embedding[name]\n",
    "        for _ in range(get_cluster_freq(name)):\n",
    "            if centroid is None:\n",
    "                centroid = embedding.copy()\n",
    "            else:\n",
    "                centroid += embedding\n",
    "    return centroid / np.linalg.norm(centroid)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dcbde4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "get_cluster_freq('richard')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2d5daa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "emb1 = name_embedding['richard']\n",
    "emb2 = name_embedding['dallan']\n",
    "print(cosine_similarity([emb1], [emb2]))\n",
    "print(cosine_similarity([emb1], [emb1]))\n",
    "print(cosine_similarity([emb1], [emb1+emb2]))\n",
    "print(cosine_similarity([emb1], [get_cluster_centroid(['richard', 'dallan'])]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7173cf88",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_clusters = {}\n",
    "super_clusters = {}\n",
    "for bucket_name, clusters in bucket_clusters.items():\n",
    "    cluster_names = []\n",
    "    for cluster in clusters:\n",
    "        centroid = get_cluster_centroid(cluster)\n",
    "        cluster_name = f\"{bucket_name}/{get_most_freq_name(cluster)}\"\n",
    "        cluster_names.append(cluster_name)\n",
    "        all_clusters[cluster_name] = {\n",
    "            \"names\": list(cluster),\n",
    "            \"centroid\": centroid.tolist(),\n",
    "        }\n",
    "    if len(cluster_names) > 1:\n",
    "        super_clusters[bucket_name] = cluster_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5ae9082",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(all_clusters), len(super_clusters))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8acd092",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(clusters_path, super_clusters_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "373f49ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(clusters_path, 'wt') as f:\n",
    "    json.dump(all_clusters, f, indent=2)\n",
    "with open(super_clusters_path, 'wt') as f:\n",
    "    json.dump(super_clusters, f, indent=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67ae3e23",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nama",
   "language": "python",
   "name": "nama"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8262d44",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b02bd1c",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Compare our approach to handling out of vocab names to four simpler approaches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2c205f5",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from collections import namedtuple, defaultdict\n",
    "from datetime import datetime\n",
    "\n",
    "import cologne_phonetics\n",
    "import jellyfish\n",
    "import joblib\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.pyplot import cm\n",
    "from metaphone import doublemetaphone\n",
    "from mpire import WorkerPool\n",
    "import numpy as np\n",
    "from pyphonetics import RefinedSoundex\n",
    "from sklearn.model_selection import train_test_split\n",
    "from spellwise import CaverphoneOne, CaverphoneTwo\n",
    "import pandas as pd\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "import wandb\n",
    "\n",
    "from src.data.filesystem import fopen\n",
    "from src.data.normalize import normalize_freq_names\n",
    "from src.data.utils import load_dataset, select_frequent_k\n",
    "from src.eval import metrics\n",
    "from src.models.levenshtein import get_best_lev_matches\n",
    "from src.models.utils import remove_padding, add_padding\n",
    "from src.models.cluster import read_clusters, get_validation_results, read_cluster_scores\n",
    "from src.models.swivel import SwivelModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56a0fe18",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# config\n",
    "\n",
    "given_surname = \"surname\"\n",
    "vocab_size = 610000 if given_surname == \"given\" else 2100000\n",
    "eval_size = 200000\n",
    "sample_size = 5000\n",
    "embed_dim = 100\n",
    "NAMA_MAX_CLUSTERS = 20\n",
    "n_jobs = 1\n",
    "verbose = True\n",
    "num_matches = 1000  # Number of candidates to consider\n",
    "\n",
    "Config = namedtuple(\"Config\", [\n",
    "    \"eval_path\",\n",
    "    \"test_path\",\n",
    "    \"freq_path\",\n",
    "    \"embed_dim\",\n",
    "    \"swivel_vocab_path\",\n",
    "    \"swivel_model_path\",\n",
    "    \"tfidf_path\",\n",
    "    \"ensemble_model_path\",\n",
    "    \"cluster_path\",\n",
    "    \"cluster_scores_path\",\n",
    "    \"aggr_path\",\n",
    "])\n",
    "config = Config(\n",
    "    eval_path=f\"s3://familysearch-names/processed/tree-hr-{given_surname}-train.csv.gz\",\n",
    "    test_path=f\"s3://familysearch-names/processed/tree-hr-{given_surname}-test.csv.gz\",\n",
    "    freq_path=f\"s3://familysearch-names/processed/tree-preferred-{given_surname}-aggr.csv.gz\",\n",
    "    embed_dim=embed_dim,\n",
    "    swivel_vocab_path=f\"s3://nama-data/data/models/fs-{given_surname}-swivel-vocab-{vocab_size}-augmented.csv\",\n",
    "    swivel_model_path=f\"s3://nama-data/data/models/fs-{given_surname}-swivel-model-{vocab_size}-{embed_dim}-augmented.pth\",\n",
    "    tfidf_path=f\"s3://nama-data/data/models/fs-{given_surname}-tfidf.joblib\",\n",
    "    ensemble_model_path=f\"s3://nama-data/data/models/fs-{given_surname}-ensemble-model-{vocab_size}-{embed_dim}-augmented-100.joblib\",    \n",
    "    cluster_path=f\"s3://nama-data/data/models/fs-{given_surname}-cluster-names.csv\",\n",
    "    cluster_scores_path=f\"s3://nama-data/data/processed/fs-{given_surname}-cluster-scores-{vocab_size}-{embed_dim}-precomputed.jsonl.gz\",\n",
    "    aggr_path=f\"s3://familysearch-names/interim/tree-hr-{given_surname}-aggr.parquet\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa465334",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "np.set_printoptions(suppress=True)\n",
    "tqdm.pandas()\n",
    "\n",
    "wandb.init(\n",
    "    project=\"nama\",\n",
    "    entity=\"nama\",\n",
    "    name=\"92_compare_oov_approaches\",\n",
    "    group=given_surname,\n",
    "    notes=\"\",\n",
    "    config=config._asdict(),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7498122",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fbf0a75",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36556f13",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "input_names_test, weighted_actual_names_test, candidate_names_test = load_dataset(config.test_path, is_eval=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a04ad20d",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "print(\"input_names_test\", len(input_names_test))\n",
    "print(\"candidate_names_test\", len(candidate_names_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c5ebe65",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "freq_df = pd.read_csv(config.freq_path, na_filter=False)\n",
    "name_freq = normalize_freq_names(freq_df, is_surname=given_surname != \"given\", add_padding=True)\n",
    "freq_df = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0557b726",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "vocab_df = pd.read_csv(fopen(config.swivel_vocab_path, \"rb\"))\n",
    "swivel_vocab = {name: _id for name, _id in zip(vocab_df[\"name\"], vocab_df[\"index\"])}\n",
    "len(swivel_vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "394d3428",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "swivel_model = SwivelModel(len(swivel_vocab), config.embed_dim)\n",
    "swivel_model.load_state_dict(torch.load(fopen(config.swivel_model_path, \"rb\"), map_location=torch.device(device)))\n",
    "swivel_model.to(device)\n",
    "swivel_model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79e28667",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "tfidf_vectorizer = joblib.load(fopen(config.tfidf_path, mode='rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad8f82bf",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "print(len(tfidf_vectorizer.vocabulary_))\n",
    "tfidf_vectorizer.vocabulary_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "255896bf",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "tfidf_vectorizer.idf_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3da9aa63",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "tfidf_vectorizer.transform([\"<richard>\", \"<dallan>\"]).todense()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "379be513",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "ensemble_model = joblib.load(fopen(config.ensemble_model_path, mode='rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24fd88f7",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "name_cluster = read_clusters(config.cluster_path)\n",
    "print(\"name_cluster\", len(name_cluster))\n",
    "print(\"unique clusters\", len(set(name_cluster.values())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "463dfb91",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "for ix, (key, value) in enumerate(name_cluster.items()):\n",
    "    print(key, value)\n",
    "    if ix > 20:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f426c57d",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "cluster_scores = read_cluster_scores(config.cluster_scores_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c89c00bb",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "name_cluster_large = {name: name_scores[0][0] for name, name_scores in cluster_scores.items()}\n",
    "len(name_cluster_large)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3e53732",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "for ix, (key, value) in enumerate(name_cluster_large.items()):\n",
    "    print(key, value)\n",
    "    if ix > 10:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dba71f7",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# remove oov names from input_names_test and remove in-vocab names from weighted_actual_names_test\n",
    "# so we only compare in-vocab against out-of-vocab\n",
    "input_names_test_iv = []\n",
    "weighted_actual_names_test_iv = []\n",
    "candidate_names_test_oov = set()\n",
    "for input_name, wans in zip(input_names_test, weighted_actual_names_test):\n",
    "    if input_name not in swivel_vocab:\n",
    "        continue\n",
    "    if input_name not in name_cluster_large:\n",
    "        continue\n",
    "    wans_oov = []\n",
    "    sum_freq = 0\n",
    "    for name, weight, freq in wans:\n",
    "        if name in swivel_vocab or freq == 0:\n",
    "            continue\n",
    "        wans_oov.append((name, freq))\n",
    "        sum_freq += freq\n",
    "    wans_oov = [(name, freq / sum_freq, freq) for name, freq in wans_oov]\n",
    "    if len(wans_oov) == 0:\n",
    "        continue\n",
    "    input_names_test_iv.append(input_name)\n",
    "    weighted_actual_names_test_iv.append(wans_oov)\n",
    "    for name, _, _ in wans_oov:\n",
    "        candidate_names_test_oov.add(name)\n",
    "candidate_names_test_oov = list(candidate_names_test_oov)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2104c5d1",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "print(len(input_names_test))\n",
    "print(len(input_names_test_iv))\n",
    "print(len(candidate_names_test))\n",
    "print(len(candidate_names_test_oov))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf041cec",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "input_names_test = input_names_test_iv\n",
    "weighted_actual_names_test = weighted_actual_names_test_iv\n",
    "candidate_names_test = np.array(candidate_names_test_oov)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f648503",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Other Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2336669d",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "refined_soundex = RefinedSoundex()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cebaa126",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "coding_algos = [\n",
    "    \"levclustered-100\",\n",
    "    \"levclusters-100\",\n",
    "    \"soundex\",\n",
    "    \"refined_soundex\",\n",
    "    \"nysiis\",\n",
    "    \"metaphone\",\n",
    "#     \"nama-60\",\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e339779",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Similarity functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db1c41b0",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def get_codes(name, algo):\n",
    "    name = remove_padding(name)\n",
    "    if algo == \"soundex\":\n",
    "        return [jellyfish.soundex(name)]\n",
    "    elif algo == \"nysiis\":\n",
    "        return [jellyfish.nysiis(name)]\n",
    "    elif algo == \"metaphone\":\n",
    "        return [jellyfish.metaphone(name)]\n",
    "    elif algo == \"refined_soundex\":\n",
    "        return [refined_soundex.phonetics(name)]    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a37d97b",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def calc_similarity_to(name, name2codes):\n",
    "    codes1 = set(name2codes[name])\n",
    "\n",
    "    def calc_similarity(row):\n",
    "        cand_name = row[0]\n",
    "        code2 = name2codes[cand_name][0]  # code2 is the code cand_name is indexed under\n",
    "        return 1.0 if code2 in codes1 else 0.0\n",
    "\n",
    "    return calc_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fb8560e",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def get_similars(shared, name=\"\"):\n",
    "    candidate_names, k, name2codes = shared\n",
    "    scores = np.apply_along_axis(calc_similarity_to(name, name2codes), 1, candidate_names[:, None])\n",
    "    sorted_scores_idx = np.argsort(scores)[::-1][:k]\n",
    "    candidate_names = candidate_names[sorted_scores_idx]\n",
    "    candidate_scores = scores[sorted_scores_idx]\n",
    "\n",
    "    return list(zip(candidate_names, candidate_scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3939021f",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def _get_similar_names_scores(input_names, cluster_candidates, name_cluster_large):\n",
    "    similar_names = []\n",
    "    max_names = 0\n",
    "    similar_scores = []\n",
    "    # get candidate names in the input name's cluster\n",
    "    for input_name in input_names:\n",
    "        candidates = list(cluster_candidates[name_cluster_large[input_name]])\n",
    "        similar_names.append(candidates)\n",
    "        similar_scores.append([1.0] * len(candidates))\n",
    "        if len(candidates) > max_names:\n",
    "            max_names = len(candidates)\n",
    "    # pad\n",
    "    for ix in range(len(input_names)):\n",
    "        if len(similar_names[ix]) < max_names:\n",
    "            similar_names[ix] += [''] * (max_names - len(similar_names[ix]))\n",
    "            similar_scores[ix] += [0.0] * (max_names - len(similar_scores[ix]))\n",
    "    # turn into np array\n",
    "    similar_names = np.array(similar_names, dtype=\"O\")\n",
    "    similar_scores = np.array(similar_scores, dtype=\"f8\")\n",
    "    # return np.array(input names, candidate names (name, score))\n",
    "    return np.dstack((similar_names, similar_scores))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37e1f414",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Evaluate each algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dab98f85",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def evaluate_algos(coding_algos,\n",
    "                   swivel_vocab,\n",
    "                   swivel_model,\n",
    "                   name_freq,\n",
    "                   name_cluster,\n",
    "                   tfidf_vectorizer,\n",
    "                   ensemble_model,\n",
    "                   input_names,\n",
    "                   weighted_actual_names,\n",
    "                   candidate_names,\n",
    "                   name_cluster_large):\n",
    "\n",
    "    figure, ax = plt.subplots(1, 1, figsize=(20, 15))\n",
    "    ax.set_title(\"PR at threshold\")\n",
    "    colors = cm.rainbow(np.linspace(0, 1, len(coding_algos)))\n",
    "    all_names = list(set(input_names).union(set(candidate_names)))\n",
    "\n",
    "    for algo, color in zip(coding_algos, colors):\n",
    "        print(algo, datetime.now())\n",
    "        if algo.startswith(\"nama\"):\n",
    "            if algo == \"nama\":\n",
    "                search_threshold = 0\n",
    "                max_clusters = 1  # return just one cluster\n",
    "            else:\n",
    "                _, search_threshold = algo.split('-')\n",
    "                search_threshold = int(search_threshold) / 100.0\n",
    "                max_clusters = NAMA_MAX_CLUSTERS\n",
    "            results = get_validation_results(\n",
    "                input_names_eval=input_names,\n",
    "                weighted_actual_names_eval=weighted_actual_names,\n",
    "                candidate_names_eval=candidate_names,\n",
    "                name_freq=name_freq,\n",
    "                name_cluster=name_cluster,\n",
    "                swivel_model=swivel_model,\n",
    "                swivel_vocab=swivel_vocab,\n",
    "                tfidf_vectorizer=tfidf_vectorizer,\n",
    "                ensemble_model=ensemble_model,\n",
    "                search_threshold=search_threshold,\n",
    "                num_matches=num_matches,\n",
    "                max_clusters=max_clusters,\n",
    "                sample_size=sample_size,\n",
    "                validation_sizes=[0],\n",
    "                n_jobs=n_jobs,\n",
    "                verbose=verbose) \n",
    "            precision = results['precisions'][0][search_threshold]\n",
    "            recall = results['recalls'][0][search_threshold]\n",
    "        elif algo.startswith(\"levclusters\"):\n",
    "            # associate candidates with the closest cluster \"root\"\n",
    "            _, num_candidates = algo.split('-')\n",
    "            num_candidates = int(num_candidates)\n",
    "            print(\"candidate_names\", len(candidate_names))\n",
    "            # clusters is the \"root\" names for each cluster\n",
    "            clusters = np.array([add_padding(cluster) for cluster in set(name_cluster.values())])\n",
    "            print(\"clusters\", len(clusters))\n",
    "            # lev_matches is a list of cluster matches for each candidate name\n",
    "            lev_matches = get_best_lev_matches(tfidf_vectorizer, candidate_names, clusters, num_candidates, \\\n",
    "                                               n_jobs=8)\n",
    "            print(\"lev_matches\", len(lev_matches))\n",
    "            # candidate_clusters is the cluster that each candidate is closest to\n",
    "            candidate_clusters = {}\n",
    "            for candidate_name, lev_match in zip(candidate_names, lev_matches):\n",
    "                candidate_clusters[candidate_name] = lev_match[0][0]\n",
    "            # cluster_candidates is the candidates assigned to each cluster\n",
    "            cluster_candidates = defaultdict(set)\n",
    "            for candidate, cluster in candidate_clusters.items():\n",
    "                cluster_candidates[remove_padding(cluster)].add(candidate)\n",
    "            print(\"cluster_candidates\", len(cluster_candidates))\n",
    "            # for each input name, similar_names_scores contains (candidate_name, 1.0)\n",
    "            # for each candidate name in the cluster that the input name has been assigned to\n",
    "            similar_names_scores = _get_similar_names_scores(input_names, cluster_candidates, name_cluster_large)\n",
    "            print(\"similar_names_scores\", len(similar_names_scores))\n",
    "            # calculate precision and recall\n",
    "            precision = metrics.avg_precision_at_threshold(weighted_actual_names, similar_names_scores, 0.5)\n",
    "            recall = metrics.avg_weighted_recall_at_threshold(weighted_actual_names, similar_names_scores, 0.5)\n",
    "        elif algo.startswith(\"levclustered\"):\n",
    "            # associate candidates with the cluster of the closest clustered name\n",
    "            _, num_candidates = algo.split('-')\n",
    "            num_candidates = int(num_candidates)\n",
    "            print(\"candidate_names\", len(candidate_names))\n",
    "            # clusters is the \"clustered\" names for each cluster\n",
    "            clusters = np.array([clustered_name for clustered_name in name_cluster.keys()])\n",
    "            print(\"clusters\", len(clusters))\n",
    "            # lev_matches is a list of clustered-name matches for each candidate name\n",
    "            lev_matches = get_best_lev_matches(tfidf_vectorizer, candidate_names, clusters, num_candidates, \\\n",
    "                                               n_jobs=8)\n",
    "            print(\"lev_matches\", len(lev_matches))\n",
    "            # candidate_clusters is the clustered-name that each candidate is closest to\n",
    "            candidate_clusters = {}\n",
    "            for candidate_name, lev_match in zip(candidate_names, lev_matches):\n",
    "                candidate_clusters[candidate_name] = lev_match[0][0]\n",
    "            # cluster_candidates is the candidates assigned to each cluster\n",
    "            cluster_candidates = defaultdict(set)\n",
    "            for candidate, clustered_name in candidate_clusters.items():\n",
    "                cluster_candidates[name_cluster_large[clustered_name]].add(candidate)\n",
    "            print(\"cluster_candidates\", len(cluster_candidates))\n",
    "            # for each input name, similar_names_scores contains (candidate_name, 1.0)\n",
    "            # for each candidate name in the cluster that the input name has been assigned to\n",
    "            similar_names_scores = _get_similar_names_scores(input_names, cluster_candidates, name_cluster_large)\n",
    "            print(\"similar_names_scores\", len(similar_names_scores))\n",
    "            # calculate precision and recall\n",
    "            precision = metrics.avg_precision_at_threshold(weighted_actual_names, similar_names_scores, 0.5)\n",
    "            recall = metrics.avg_weighted_recall_at_threshold(weighted_actual_names, similar_names_scores, 0.5)\n",
    "        else:\n",
    "            name2codes = {name: get_codes(name, algo) for name in all_names}\n",
    "            with WorkerPool(shared_objects=(candidate_names, num_matches, name2codes)) as pool:\n",
    "                similar_names_scores = pool.map(get_similars, input_names, progress_bar=True)\n",
    "            similar_names = [[name for name, _ in name_similarities] for name_similarities in similar_names_scores]\n",
    "            names = np.array(list(list(cell[0] for cell in row) for row in similar_names_scores), dtype=\"O\")\n",
    "            scores = np.array(list(list(cell[1] for cell in row) for row in similar_names_scores), dtype=\"f8\")\n",
    "            total = max(scores.sum(axis=1))\n",
    "            print(\"max sum of scores\", total)\n",
    "            if total == num_matches:\n",
    "                print(\"WARNING: need to increase num_matches\")\n",
    "            similar_names_scores = np.dstack((names, scores))\n",
    "            precision = metrics.avg_precision_at_threshold(weighted_actual_names, similar_names_scores, 0.5)\n",
    "            recall = metrics.avg_weighted_recall_at_threshold(weighted_actual_names, similar_names_scores, 0.5)\n",
    "        print(f\"precision={precision} recall={recall}\")\n",
    "        precisions = [precision]\n",
    "        recalls = [recall]\n",
    "        ax.plot(recalls, precisions, \"o--\", color=color, label=algo)\n",
    "    print(\"complete\", datetime.now())\n",
    "\n",
    "    ax.legend()\n",
    "    plt.xlim([0, 1.0])\n",
    "    plt.ylim([0, 1.0])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1f25279",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "#### on out-of-vocabulary names (test data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58b364b5",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "_, input_names_sample, _, weighted_actual_names_sample = \\\n",
    "    train_test_split(input_names_test, weighted_actual_names_test, test_size=sample_size)\n",
    "candidate_names_sample = candidate_names_test\n",
    "\n",
    "print(\"input_names\", len(input_names_sample))\n",
    "print(\"weighted_actual_names\", len(weighted_actual_names_sample))\n",
    "print(\"candidate_names\", len(candidate_names_sample))\n",
    "print(\"all names\", len(set(input_names_sample).union(set(candidate_names_sample))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8e6832a",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "n_zero = n_one = n_two = 0\n",
    "for input_name, wans in zip(input_names_sample, weighted_actual_names_sample):\n",
    "    for actual_name, _, _ in wans:\n",
    "        if input_name in swivel_vocab and actual_name in swivel_vocab:\n",
    "            n_two += 1\n",
    "        elif input_name in swivel_vocab or actual_name in swivel_vocab:\n",
    "            n_one += 1\n",
    "        else:\n",
    "            n_zero += 1\n",
    "print(\"two names in vocab (should not be possible)\", n_two)\n",
    "print(\"one name in vocab\", n_one)\n",
    "print(\"zero names in vocab\", n_zero)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3277d44c",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "evaluate_algos(coding_algos,\n",
    "               swivel_vocab,\n",
    "               swivel_model,\n",
    "               name_freq,\n",
    "               name_cluster,\n",
    "               tfidf_vectorizer,\n",
    "               ensemble_model,\n",
    "               input_names_sample,\n",
    "               weighted_actual_names_sample,\n",
    "               candidate_names_sample,\n",
    "               name_cluster_large)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8881b9f5",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "aggr_df = pd.read_parquet(config.aggr_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "953e5f9b",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "print(aggr_df.shape)\n",
    "aggr_df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "351dab1b",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "total_in_cluster_scores = 0\n",
    "total_not_in_cluster_scores = 0\n",
    "for name, alt_name, frequency in zip(aggr_df['name'], aggr_df['alt_name'], aggr_df['frequency']):\n",
    "    if len(name) > 1:\n",
    "        if add_padding(name) in cluster_scores:\n",
    "            total_in_cluster_scores += frequency\n",
    "        else:\n",
    "            total_not_in_cluster_scores += frequency\n",
    "    if len(alt_name) > 1:\n",
    "        if add_padding(alt_name) in cluster_scores:\n",
    "            total_in_cluster_scores += frequency\n",
    "        else:\n",
    "            total_not_in_cluster_scores += frequency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64c769ab",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "print(total_in_cluster_scores)\n",
    "print(total_not_in_cluster_scores)\n",
    "print(total_not_in_cluster_scores / (total_in_cluster_scores + total_not_in_cluster_scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed367dde",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "254e2a07",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nama",
   "language": "python",
   "name": "nama"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

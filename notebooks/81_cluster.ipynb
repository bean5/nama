{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2907945b",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d131857",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import namedtuple\n",
    "import heapq\n",
    "\n",
    "import joblib\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import wandb\n",
    "\n",
    "from src.data.normalize import normalize_freq_names\n",
    "from src.data.utils import load_dataset\n",
    "from src.data.filesystem import fopen\n",
    "from src.models.cluster import (\n",
    "    get_names_to_cluster,\n",
    "    get_distances,\n",
    "    generate_clusters_from_distances,\n",
    "    write_clusters,\n",
    ")\n",
    "from src.models.swivel import SwivelModel\n",
    "from src.models.utils import remove_padding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b54bdec3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# configure\n",
    "given_surname = \"given\"\n",
    "vocab_size = 610000 if given_surname == \"given\" else 2100000\n",
    "save_partitions = False\n",
    "save_clusters = True\n",
    "max_partitions = 720 if save_partitions else 0\n",
    "n_to_cluster = 200000\n",
    "cluster_threshold = 0.4 if given_surname == \"given\" else 0.6\n",
    "n_jobs = 64\n",
    "\n",
    "embed_dim = 100\n",
    "encoder_layers = 2\n",
    "num_matches = 5000\n",
    "batch_size = 256\n",
    "verbose = True\n",
    "\n",
    "Config = namedtuple(\"Config\", [\n",
    "    \"eval_path\",\n",
    "    \"freq_path\",\n",
    "    \"embed_dim\",\n",
    "    \"swivel_vocab_path\",\n",
    "    \"swivel_model_path\",\n",
    "    \"tfidf_path\",\n",
    "    \"ensemble_model_path\",\n",
    "    \"name_partition_path\",\n",
    "    \"cluster_path\",\n",
    "])\n",
    "config = Config(\n",
    "    eval_path=f\"s3://familysearch-names/processed/tree-hr-{given_surname}-train.csv.gz\",\n",
    "    freq_path=f\"s3://familysearch-names/processed/tree-preferred-{given_surname}-aggr.csv.gz\",\n",
    "    embed_dim=embed_dim,\n",
    "    swivel_vocab_path=f\"s3://nama-data/data/models/fs-{given_surname}-swivel-vocab-{vocab_size}-augmented.csv\",\n",
    "    swivel_model_path=f\"s3://nama-data/data/models/fs-{given_surname}-swivel-model-{vocab_size}-{embed_dim}-augmented.pth\",\n",
    "    tfidf_path=f\"s3://nama-data/data/models/fs-{given_surname}-tfidf.joblib\",\n",
    "    ensemble_model_path=f\"s3://nama-data/data/models/fs-{given_surname}-ensemble-model-{vocab_size}-{embed_dim}-augmented-100.joblib\",\n",
    "    name_partition_path=f\"s3://nama-data/data/models/fs-{given_surname}-cluster_partitions.csv\",\n",
    "    cluster_path=f\"s3://nama-data/data/models/fs-{given_surname}-cluster_names.csv\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72dfc8f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "wandb.init(\n",
    "    project=\"nama\",\n",
    "    entity=\"nama\",\n",
    "    name=\"81_cluster\",\n",
    "    group=given_surname,\n",
    "    notes=\"\",\n",
    "    config=config._asdict()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4190d2c0",
   "metadata": {},
   "source": [
    "### Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3aa76e0e",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "138b8c92",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_names_eval, weighted_actual_names_eval, candidate_names_eval = load_dataset(config.eval_path, is_eval=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "032b6a3f",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "actual_names_eval = set([name for wans in weighted_actual_names_eval for name, _, _ in wans])\n",
    "candidate_names_eval = np.array(list(actual_names_eval))\n",
    "del actual_names_eval\n",
    "print(len(candidate_names_eval))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "254b42b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "freq_df = pd.read_csv(config.freq_path, na_filter=False)\n",
    "name_freq = normalize_freq_names(freq_df, is_surname=given_surname != \"given\", add_padding=True)\n",
    "freq_df = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e4ca49f",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_df = pd.read_csv(fopen(config.swivel_vocab_path, \"rb\"))\n",
    "swivel_vocab = {name: _id for name, _id in zip(vocab_df[\"name\"], vocab_df[\"index\"])}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7597e75d",
   "metadata": {},
   "outputs": [],
   "source": [
    "swivel_model = SwivelModel(len(swivel_vocab), config.embed_dim)\n",
    "swivel_model.load_state_dict(torch.load(fopen(config.swivel_model_path, \"rb\"), map_location=torch.device(device)))\n",
    "swivel_model.to(device)\n",
    "swivel_model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d5f139a",
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_vectorizer = joblib.load(fopen(config.tfidf_path, mode='rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e33b5fcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "ensemble_model = joblib.load(fopen(config.ensemble_model_path, mode='rb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0948df4b",
   "metadata": {},
   "source": [
    "### Get names to cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a943799",
   "metadata": {},
   "outputs": [],
   "source": [
    "names_to_cluster = get_names_to_cluster(name_freq, n_to_cluster)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80414d65",
   "metadata": {},
   "source": [
    "### Compute cluster hierarchy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a97a6e62",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "distances = get_distances(name_freq, \n",
    "                          names_to_cluster,\n",
    "                          swivel_model=swivel_model,\n",
    "                          swivel_vocab=swivel_vocab,\n",
    "                          tfidf_vectorizer=tfidf_vectorizer,\n",
    "                          ensemble_model=ensemble_model,\n",
    "                          num_matches=num_matches,\n",
    "                          verbose=verbose,\n",
    "                          n_jobs=n_jobs,\n",
    "                         )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3fff038",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "model, name_cluster = generate_clusters_from_distances(\n",
    "                            cluster_algo=\"agglomerative\",\n",
    "                            cluster_linkage=\"average\",\n",
    "                            cluster_threshold=-10.0,  # initially put everything into a single cluster\n",
    "                            distances=distances,\n",
    "                            names_to_cluster=names_to_cluster,\n",
    "                            verbose=verbose,\n",
    "                            n_jobs=n_jobs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8437fc8",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "#### Split into partitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b04a0db9",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# model.children_ is a list of all non-leaf nodes in the cluster hierarchy that contains their immediate children\n",
    "leaf_node_count = len(names_to_cluster)\n",
    "non_leaf_node_count = len(model.children_)\n",
    "total_node_count = leaf_node_count + non_leaf_node_count\n",
    "\n",
    "# count the total name frequency in each leaf and non-leaf node\n",
    "cluster_freq = np.zeros(total_node_count)\n",
    "for ix in range(0, leaf_node_count):\n",
    "    cluster_freq[ix] = name_freq[names_to_cluster[ix]]\n",
    "\n",
    "for ix in range(0, non_leaf_node_count):\n",
    "    count = 0\n",
    "    for child in model.children_[ix]:\n",
    "        count += cluster_freq[child]\n",
    "    cluster_freq[ix + leaf_node_count] = count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4aefe29a",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# starting with the partition at the root of the cluster hierarchy, split the largest partition until you have max_partitions\n",
    "total_partitions = 1\n",
    "partitions = []\n",
    "initial_partition = total_node_count - 1\n",
    "heapq.heappush(partitions, (-cluster_freq[initial_partition], initial_partition, 1))\n",
    "\n",
    "while total_partitions < max_partitions:\n",
    "    freq, partition, n_partitions = heapq.heappop(partitions)\n",
    "    total_partitions -= n_partitions\n",
    "    # if this is a leaf node that needs to be split, this will be a multi-partition leaf\n",
    "    if partition < leaf_node_count:\n",
    "        n_partitions += 1\n",
    "        total_partitions += n_partitions\n",
    "        heapq.heappush(partitions, (-cluster_freq[partition] / n_partitions, partition, n_partitions))\n",
    "    else:\n",
    "        for child in model.children_[partition - leaf_node_count]:\n",
    "            total_partitions += 1\n",
    "            heapq.heappush(partitions, (-cluster_freq[child], child, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ea5f634",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# TODO merge smaller partitions?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3db0593",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# histo on partition sizes\n",
    "partition_sizes_df = pd.DataFrame([-freq for freq, _, _ in partitions])\n",
    "partition_sizes_df.hist()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b3e7f38",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "#### Split partition(s) into clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ff47c1f",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "if save_clusters:\n",
    "    clusters = []\n",
    "    # start with the partition nodes\n",
    "    for _, partition, _ in partitions:\n",
    "        distance = 0.0 if partition < leaf_node_count else model.distances_[partition - leaf_node_count]\n",
    "        heapq.heappush(clusters, (-distance, partition))\n",
    "\n",
    "    # then split each node into clusters if the node's distance is above threshold\n",
    "    while True:\n",
    "        distance, cluster = heapq.heappop(clusters)\n",
    "        if distance >= -(1 - cluster_threshold):  # cluster threshold is measured in terms of (1 - distance)\n",
    "            heapq.heappush(clusters, (distance, cluster))\n",
    "            break\n",
    "        for child in model.children_[cluster - leaf_node_count]:\n",
    "            distance = 0.0 if child < leaf_node_count else model.distances_[child - leaf_node_count]\n",
    "            heapq.heappush(clusters, (-distance, child))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65dfefa3",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "#### Save partitions and clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e677078f",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "partition_map = {partition_id: n_partitions for _, partition_id, n_partitions in partitions}\n",
    "\n",
    "def get_most_frequent_name(names):\n",
    "    most_freq_name = None\n",
    "    highest_freq = -1\n",
    "    for name in names:\n",
    "        freq = name_freq.get(name, -1)\n",
    "        if freq > highest_freq:\n",
    "            most_freq_name = name\n",
    "            highest_freq = freq\n",
    "    return most_freq_name\n",
    "\n",
    "def partition_finder(node_id):\n",
    "    return (names_to_cluster[node_id], partition_map.get(node_id, 1)) if node_id < leaf_node_count else None\n",
    "\n",
    "def name_finder(node_id):\n",
    "    return names_to_cluster[node_id] if node_id < leaf_node_count else None\n",
    "\n",
    "def gather_children(node_id, fn, result):\n",
    "    item = fn(node_id)\n",
    "    if item:\n",
    "        result.append(item)\n",
    "    elif node_id >= leaf_node_count:\n",
    "        for child in model.children_[node_id - leaf_node_count]:\n",
    "            gather_children(child, fn, result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1fa1bc0",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "if save_partitions:\n",
    "    # walk the cluster hierarchy to get the names in each partition\n",
    "    partition2names = {}\n",
    "    for _, partition, _ in partitions:\n",
    "        name_partitions = []\n",
    "        gather_children(partition, partition_finder, name_partitions)\n",
    "        if len(name_partitions) == 0:\n",
    "            print(\"ERROR empty partition\", partition)\n",
    "        partition2names[partition] = name_partitions\n",
    "\n",
    "    # invert partition2names to get a dataframe with name, partition pairs\n",
    "    partition_number = 0\n",
    "    name_partition_name = []\n",
    "    name_partition_partition = []\n",
    "    name_partition_count = []\n",
    "    for partition, name_partitions in partition2names.items():\n",
    "        for name, n_partitions in name_partitions:\n",
    "            name_partition_name.append(remove_padding(name))\n",
    "            name_partition_partition.append(partition_number)\n",
    "            name_partition_count.append(n_partitions)\n",
    "        partition_number += 1 if len(name_partitions) > 1 else name_partitions[0][1]\n",
    "    name_partition_df = pd.DataFrame({\n",
    "        \"name\": name_partition_name,\n",
    "        \"start_partition\": name_partition_partition,\n",
    "        \"n_partitions\": name_partition_count,\n",
    "    })\n",
    "\n",
    "    # write the dataframe to a csv file\n",
    "    name_partition_df.to_csv(config.name_partition_path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd472eea",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "if save_clusters:\n",
    "    # walk the cluster hierarchy to get the names in each cluster\n",
    "    cluster2names = {}\n",
    "    for _, cluster in clusters:\n",
    "        names = []\n",
    "        gather_children(cluster, name_finder, names)\n",
    "        if len(names) == 0:\n",
    "            print(\"ERROR: empty cluster\", cluster)\n",
    "        # the name of the cluster is the most-frequent name\n",
    "        freq_name = remove_padding(get_most_frequent_name(names))\n",
    "        cluster2names[freq_name] = names\n",
    "\n",
    "    # invert cluster2names\n",
    "    name_cluster = {}\n",
    "    for cluster, names in cluster2names.items():\n",
    "        for name in names:\n",
    "            name_cluster[name] = cluster\n",
    "\n",
    "    # write the dataframe to a csv file\n",
    "    write_clusters(config.cluster_path, name_cluster)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18ae1f38",
   "metadata": {},
   "outputs": [],
   "source": [
    "wandb.finish()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nama",
   "language": "python",
   "name": "nama"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

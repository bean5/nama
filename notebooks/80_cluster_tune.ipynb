{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from collections import namedtuple\n",
    "\n",
    "import pandas as pd\n",
    "import ray\n",
    "from ray import tune\n",
    "from ray.tune.suggest.hyperopt import HyperOptSearch\n",
    "from ray.tune.integration.wandb import WandbLoggerCallback\n",
    "import torch\n",
    "\n",
    "from src.data.utils import load_datasets, select_frequent_k\n",
    "from src.data.filesystem import fopen\n",
    "from src.eval.metrics import avg_precision_at_threshold, avg_weighted_recall_at_threshold\n",
    "from src.models.cluster import (\n",
    "    get_sorted_similarities,\n",
    "    generate_closures,\n",
    "    generate_clusters,\n",
    "    assign_names_to_clusters,\n",
    "    get_best_cluster_matches,\n",
    ")\n",
    "from src.models.swivel import SwivelModel, get_swivel_embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# configure\n",
    "wandb_api_key_file = \"../.wandb-api-key\"\n",
    "given_surname = \"given\"\n",
    "DEFAULT_NAMES_TO_CLUSTER = 400000\n",
    "DEFAULT_CLOSURE_THRESHOLD = 1000\n",
    "DEFAULT_CLUSTER_THRESHOLD = 0.4\n",
    "DEFAULT_CLUSTER_LINKAGE = \"average\"\n",
    "DEFAULT_K_NN = 1\n",
    "\n",
    "vocab_size = 600000 if given_surname == \"given\" else 2100000\n",
    "embed_dim = 100\n",
    "Config = namedtuple(\"Config\", \"train_path embed_dim swivel_vocab_path swivel_model_path\")\n",
    "config = Config(\n",
    "    train_path=f\"s3://familysearch-names/processed/tree-hr-{given_surname}-train.csv.gz\",\n",
    "    embed_dim=embed_dim,\n",
    "    swivel_vocab_path=f\"s3://nama-data/data/models/fs-{given_surname}-swivel-vocab-{vocab_size}.csv\",\n",
    "    # TODO fix\n",
    "    swivel_model_path=f\"s3://nama-data/data/models/fs-{given_surname}-swivel-model-{vocab_size}-{embed_dim}-50.pth.26\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "[train] = load_datasets([config.train_path])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "input_names_train, weighted_actual_names_train, candidate_names_train = train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "vocab_df = pd.read_csv(fopen(config.swivel_vocab_path, \"rb\"))\n",
    "print(len(vocab_df))\n",
    "print(vocab_df.head(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "swivel_vocab = {name: _id for name, _id in zip(vocab_df[\"name\"], vocab_df[\"index\"])}\n",
    "print(next(iter(swivel_vocab.items())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "swivel_model = SwivelModel(len(swivel_vocab), config.embed_dim)\n",
    "swivel_model.load_state_dict(torch.load(fopen(config.swivel_model_path, \"rb\")))\n",
    "swivel_model.eval()\n",
    "print(swivel_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Optimize hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def ray_training_function(config,\n",
    "                          swivel_model,\n",
    "                          swivel_vocab,\n",
    "                          input_names_train,\n",
    "                          weighted_actual_names_train,\n",
    "                          candidate_names_train,\n",
    "                          checkpoint_dir=None):\n",
    "\n",
    "    # filter names to cluster from train\n",
    "    input_names_cluster, weighted_actual_names_cluster, candidate_names_cluster = \\\n",
    "        select_frequent_k(input_names_train, \n",
    "                          weighted_actual_names_train, \n",
    "                          candidate_names_train,\n",
    "                          config[\"n_to_cluster\"])\n",
    "\n",
    "    ### remove - validate on clustered names only\n",
    "    input_names_train = input_names_cluster\n",
    "    weighted_actual_names_train = weighted_actual_names_cluster\n",
    "    candidate_names_train = candidate_names_cluster\n",
    "    \n",
    "    # get names to cluster\n",
    "    cluster_names = list(set(input_names_cluster).union(set(candidate_names_cluster)))\n",
    "    input_names_cluster = candidate_names_cluster = None  # release memory\n",
    "\n",
    "    # get embeddings for names to cluster\n",
    "    cluster_embeddings = get_swivel_embeddings(swivel_model, swivel_vocab, cluster_names).astype('float32')\n",
    "    cluster_names = None  # release memory\n",
    "\n",
    "    # get sorted_similarities from embeddings\n",
    "    sorted_similarities = get_sorted_similarities(cluster_embeddings, threshold=0.4)\n",
    "\n",
    "    # generate closures from sorted similarities\n",
    "    _, closure2ids, _, max_score_not_merged = generate_closures(sorted_similarities, config[\"closure_threshold\"])\n",
    "    sorted_similarities = None  # release memory\n",
    "\n",
    "    # generate clusters from closures and embeddings\n",
    "    id2cluster = generate_clusters(closure2ids,\n",
    "                                   cluster_embeddings,\n",
    "                                   config[\"cluster_threshold\"],\n",
    "                                   config[\"cluster_linkage\"],\n",
    "                                   n_jobs=1,\n",
    "                                   verbose=False,\n",
    "                                  )\n",
    "    closure2ids = None  # release memory\n",
    "\n",
    "    # get all embeddings\n",
    "    all_names = list(set(input_names_train).union(set(candidate_names_train)))\n",
    "    all_embeddings = get_swivel_embeddings(swivel_model, swivel_vocab, all_names).astype('float32')\n",
    "    candidate_names_train = swivel_model = swivel_vocab = None  # release memory\n",
    "\n",
    "    # assign all names to clusters\n",
    "    name2cluster, cluster2names = assign_names_to_clusters(all_names,\n",
    "                                                           all_embeddings,\n",
    "                                                           id2cluster,\n",
    "                                                           cluster_embeddings,\n",
    "                                                           k=config[\"k_nn\"],\n",
    "                                                           verbose=False,\n",
    "                                                          )\n",
    "    all_names = all_embeddings = id2cluster = cluster_embeddings = None  # release memory\n",
    "\n",
    "    num_clusters = len(cluster2names)\n",
    "    max_cluster_size = max([len(names) for names in cluster2names.values()])\n",
    "    \n",
    "    print(\"max_score_not_merged\", max_score_not_merged)\n",
    "    print(\"num_clusters\", num_clusters)\n",
    "    print(\"max_cluster_size\", max_cluster_size)\n",
    "\n",
    "\n",
    "    # get best matches\n",
    "    best_matches = get_best_cluster_matches(name2cluster, cluster2names, input_names_train)\n",
    "    name2cluster = cluster2names = input_names_train = None  # release memory\n",
    "\n",
    "    # eval f1\n",
    "    precision = avg_precision_at_threshold(weighted_actual_names_train, best_matches, 0.5)\n",
    "    recall = avg_weighted_recall_at_threshold(weighted_actual_names_train, best_matches, 0.5)\n",
    "    f1 = 2 * (precision * recall) / (precision + recall)\n",
    "\n",
    "    # Report the metrics to Ray\n",
    "    tune.report(f1=f1, \n",
    "                precision=precision, \n",
    "                recall=recall,\n",
    "               )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "config_params={\n",
    "    \"n_to_cluster\": DEFAULT_NAMES_TO_CLUSTER,  # tune.qrandint(100000, vocab_size, 100000),\n",
    "    \"closure_threshold\": DEFAULT_CLOSURE_THRESHOLD,\n",
    "    \"cluster_threshold\": tune.quniform(0.1, 0.8, 0.05),\n",
    "    \"cluster_linkage\": tune.choice([\"average\", \"single\", \"complete\", \"ward\"]),\n",
    "    \"k_nn\": DEFAULT_K_NN,  # tune.choice([1, 3, 5]),\n",
    "}\n",
    "\n",
    "current_best_params = [{\n",
    "    \"n_to_cluster\": DEFAULT_NAMES_TO_CLUSTER,\n",
    "    \"closure_threshold\": DEFAULT_CLOSURE_THRESHOLD,\n",
    "    \"cluster_threshold\": DEFAULT_CLUSTER_THRESHOLD,\n",
    "    \"cluster_linkage\": DEFAULT_CLUSTER_LINKAGE,\n",
    "    \"k_nn\": DEFAULT_K_NN,\n",
    "}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# https://docs.ray.io/en/latest/tune/api_docs/suggestion.html#tune-hyperopt\n",
    "search_alg = HyperOptSearch(points_to_evaluate=current_best_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "ray.shutdown()\n",
    "ray.init()\n",
    "\n",
    "callbacks = []\n",
    "if wandb_api_key_file:\n",
    "    callbacks.append(WandbLoggerCallback(\n",
    "        project=\"nama\",\n",
    "        entity=\"nama\",\n",
    "        group=\"80_cluster_tune_\"+given_surname,\n",
    "        notes=\"\",\n",
    "        config=config._asdict(),\n",
    "        api_key_file=wandb_api_key_file\n",
    "    ))\n",
    "\n",
    "result = tune.run(\n",
    "    tune.with_parameters(ray_training_function,\n",
    "                         swivel_model=swivel_model,\n",
    "                         swivel_vocab=swivel_vocab,\n",
    "                         input_names_train=input_names_train,\n",
    "                         weighted_actual_names_train=weighted_actual_names_train,\n",
    "                         candidate_names_train=candidate_names_train),\n",
    "    resources_per_trial={\"cpu\": 2.0, \"gpu\": 0.0},\n",
    "    max_concurrent_trials=3,\n",
    "    config=config_params,\n",
    "    search_alg=search_alg,\n",
    "    num_samples=50,\n",
    "    metric=\"f1\",\n",
    "    mode=\"max\",\n",
    "    checkpoint_score_attr=\"f1\",\n",
    "    time_budget_s=10*3600,\n",
    "    progress_reporter=tune.JupyterNotebookReporter(\n",
    "        overwrite=False,\n",
    "        max_report_frequency=5*60\n",
    "    ),\n",
    "    callbacks=callbacks\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Get best model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Get trial that has the highest F1\n",
    "best_trial = result.get_best_trial(metric='f1', mode='max', scope='all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Parameters with the highest AUC\n",
    "best_trial.config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "print(f\"Best trial final train f1: {best_trial.last_result['f1']}\")\n",
    "print(f\"Best trial final train precision: {best_trial.last_result['precision']}\")\n",
    "print(f\"Best trial final train recall: {best_trial.last_result['recall']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Get all trials as DF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# All trials as pandas dataframe\n",
    "df = result.results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[(df[\"f1\"] > 0.44) & (df[\"recall\"] > 0.46)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_names = [\"<john>\", \"<jonathan>\", \"<mary>\", \"<marie>\", \"<maria>\"]\n",
    "closure2ids = {\"c\": [0,1,2,3,4]}\n",
    "cluster_embeddings = get_swivel_embeddings(swivel_model, swivel_vocab, cluster_names).astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "id2cluster = generate_clusters(closure2ids, cluster_embeddings, 0.6, \"average\", n_jobs=1)\n",
    "print(id2cluster)\n",
    "id2cluster = generate_clusters(closure2ids, cluster_embeddings, 0.99, \"average\", n_jobs=1)\n",
    "print(id2cluster)\n",
    "id2cluster = generate_clusters(closure2ids, cluster_embeddings, 0.01, \"average\", n_jobs=1)\n",
    "print(id2cluster)\n",
    "id2cluster = generate_clusters(closure2ids, cluster_embeddings, 0.6, \"ward\", n_jobs=1)\n",
    "print(id2cluster)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nama",
   "language": "python",
   "name": "nama"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from collections import namedtuple\n",
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import ray\n",
    "from ray import tune\n",
    "from ray.tune.schedulers import ASHAScheduler\n",
    "from ray.tune.suggest.hyperopt import HyperOptSearch\n",
    "from ray.tune.integration.wandb import WandbLoggerCallback\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch\n",
    "import wandb\n",
    "\n",
    "from src.data.filesystem import fopen\n",
    "from src.data.utils import load_train_test\n",
    "from src.eval import metrics\n",
    "from src.models.swivel import get_swivel_embeddings, get_best_swivel_matches\n",
    "from src.models.swivel_encoder import SwivelEncoderModel, convert_names_to_model_inputs, train_swivel_encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Config\n",
    "\n",
    "wandb_api_key_file = \"../.wandb-api-key\"\n",
    "given_surname = \"given\"\n",
    "size = \"tiny\"\n",
    "swivel_size = \"freq\"\n",
    "vocab_size = 500000\n",
    "embed_dim = 200\n",
    "Config = namedtuple(\"Config\", \"train_path test_path embed_dim vocab_path model_path\")\n",
    "config = Config(\n",
    "    train_path=f\"s3://familysearch-names/processed/tree-hr-{given_surname}-similar-train-{size}.csv.gz\",\n",
    "    test_path=f\"s3://familysearch-names/processed/tree-hr-{given_surname}-similar-test-{size}.csv.gz\",\n",
    "    embed_dim=embed_dim,\n",
    "    vocab_path=f\"s3://nama-data/data/models/fs-{given_surname}-{swivel_size}-swivel-{vocab_size}-vocab-tfidf.csv\",\n",
    "    model_path=f\"../data/models/fs-{given_surname}-{swivel_size}-swivel-{vocab_size}-{embed_dim}-tfidf.pt\",\n",
    "#     model_path=f\"s3://nama-data/data/models/fs-{given_surname}-{swivel_size}-swivel-{vocab_size}-{embed_dim}-tfidf.pt\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "[train, test] = load_train_test([config.train_path, config.test_path])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "input_names_train, weighted_actual_names_train, candidate_names_train = train\n",
    "input_names_test, weighted_actual_names_test, candidate_names_test = test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "print(\"input_names_train\", len(input_names_train))\n",
    "print(\"weighted_actual_names_train\", sum(len(wan) for wan in weighted_actual_names_train))\n",
    "print(\"candidate_names_train\", len(candidate_names_train))\n",
    "\n",
    "print(\"input_names_test\", len(input_names_test))\n",
    "print(\"weighted_actual_names_test\", sum(len(wan) for wan in weighted_actual_names_test))\n",
    "print(\"candidate_names_test\", len(candidate_names_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "vocab_df = pd.read_csv(fopen(config.vocab_path, \"rb\"))\n",
    "print(vocab_df.head(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# restrict vocab to just input names train\n",
    "swivel_vocab = {name: _id for name, _id in zip(vocab_df[\"name\"], vocab_df[\"index\"])}\n",
    "print(len(swivel_vocab))\n",
    "print(swivel_vocab[\"<john>\"])\n",
    "\n",
    "input_names_train_set = set(input_names_train)\n",
    "input_names_vocab = {name: _id for name, _id in swivel_vocab.items() \\\n",
    "                if name in input_names_train_set}\n",
    "print(len(input_names_vocab))\n",
    "print(input_names_vocab[\"<john>\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "swivel_model = torch.load(fopen(config.model_path, \"rb\"))\n",
    "swivel_model.eval()\n",
    "print(swivel_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Optimize Hyperparameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "#### Create optimization and validation sets from the training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# split out the candidate names into train and validate sets\n",
    "train_size=0.8\n",
    "test_size=0.2\n",
    "candidate_names_optimize, candidate_names_validate = \\\n",
    "    train_test_split(candidate_names_train, train_size=train_size, test_size=test_size)\n",
    "print(\"candidate_names_optimize\", len(candidate_names_optimize))\n",
    "print(\"candidate_names_validate\", len(candidate_names_validate))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# generate weighted_actual_names_validate from weighted_actual_names_train and candidate_names_validate\n",
    "candidate_names_validate_set = set(candidate_names_validate)\n",
    "weighted_actual_names_validate = []\n",
    "for input_name, wans in zip(input_names_train, weighted_actual_names_train):\n",
    "    total_freq = sum([freq for name, _, freq in wans if name in candidate_names_validate_set])\n",
    "    wans = [(name, freq/total_freq, freq) for name, _, freq in wans if freq > 0 and name in candidate_names_validate_set]\n",
    "    wans.append((input_name, 0.0, 0))  # so precision isn't hurt by matching the input name\n",
    "    total_weight = sum([weight for _, weight, _ in wans])\n",
    "    if total_weight > 1.0001:    # Error if total weight > 1\n",
    "        print(\"total\", total_weight, \"wans\", wans)\n",
    "    weighted_actual_names_validate.append(wans)\n",
    "print(weighted_actual_names_validate[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "candidate_names_optimize_inputs = convert_names_to_model_inputs(candidate_names_optimize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "candidate_names_optimize_embeddings = torch.Tensor(get_swivel_embeddings(swivel_model, swivel_vocab, candidate_names_optimize))\n",
    "print(candidate_names_optimize_embeddings.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "#### Use Ray to perform the search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def ray_training_function(config,\n",
    "                          swivel_model,\n",
    "                          swivel_vocab,\n",
    "                          candidate_names_optimize_inputs,\n",
    "                          candidate_names_optimize_embeddings,\n",
    "                          input_names_train,\n",
    "                          candidate_names_validate,\n",
    "                          weighted_actual_names_validate,\n",
    "                          device,\n",
    "                          checkpoint_dir=None):\n",
    "    # create model\n",
    "    embed_dim = 200\n",
    "    encoder_model = SwivelEncoderModel(n_layers=config[\"n_layers\"],\n",
    "                               char_embed_dim=config[\"char_embed_dim\"],\n",
    "                               n_hidden_units=config[\"n_hidden_units\"],\n",
    "                               output_dim=embed_dim,\n",
    "                               bidirectional=config[\"bidirectional\"],\n",
    "                               device=device)\n",
    "    encoder_model.to(device=device)\n",
    "    \n",
    "    optimizer = torch.optim.Adam(encoder_model.parameters(), lr=config[\"lr\"]) \\\n",
    "        if config[\"use_adam_opt\"] \\\n",
    "        else torch.optim.Adagrad(encoder_model.parameters(), lr=config[\"lr\"])\n",
    "\n",
    "    # Load checkpoint if exists\n",
    "    if checkpoint_dir:\n",
    "        model_state, optimizer_state = torch.load(\n",
    "            os.path.join(checkpoint_dir, \"checkpoint\"))\n",
    "        encoder_model.load_state_dict(model_state)\n",
    "        optimizer.load_state_dict(optimizer_state)\n",
    "\n",
    "    for epoch in range(config[\"n_epochs\"]):\n",
    "        losses = train_swivel_encoder(encoder_model,\n",
    "                                      candidate_names_optimize_inputs,\n",
    "                                      candidate_names_optimize_embeddings,\n",
    "                                      num_epochs=1,\n",
    "                                      batch_size=config[\"batch_size\"],\n",
    "                                      use_adam_opt=config[\"use_adam_opt\"],\n",
    "                                      verbose=False,\n",
    "                                      optimizer=optimizer)\n",
    "        best_matches = get_best_swivel_matches(swivel_model,\n",
    "                                               swivel_vocab,\n",
    "                                               input_names_train,\n",
    "                                               candidate_names_validate,\n",
    "                                               k=100,\n",
    "                                               batch_size=256,\n",
    "                                               add_context=True,\n",
    "                                               encoder_model=encoder_model,\n",
    "                                               n_jobs=1)\n",
    "        auc = metrics.get_auc(\n",
    "            weighted_actual_names_validate, best_matches, min_threshold=0.01, max_threshold=2.0, step=0.05, distances=False\n",
    "        )\n",
    "\n",
    "        # Checkpoint the model\n",
    "        with tune.checkpoint_dir(epoch) as checkpoint_dir:\n",
    "            path = os.path.join(checkpoint_dir, \"checkpoint\")\n",
    "            torch.save((encoder_model.state_dict(), optimizer.state_dict()), path)\n",
    "\n",
    "        # Report the metrics to Ray\n",
    "        tune.report(auc=auc, mean_loss=np.mean(losses))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "config_params={\n",
    "    \"n_layers\": tune.choice([1, 2, 3]),\n",
    "    \"char_embed_dim\": tune.choice([32, 64]),\n",
    "    \"n_hidden_units\": tune.choice([200, 300, 400]),\n",
    "    \"bidirectional\": True,\n",
    "    \"lr\": tune.quniform(0.02, 0.07, 0.01),\n",
    "    \"batch_size\": tune.choice([128, 256]),\n",
    "    \"use_adam_opt\": False,\n",
    "    \"n_epochs\": 50\n",
    "}\n",
    "\n",
    "current_best_params = [{\n",
    "        \"n_layers\": 3,\n",
    "        \"char_embed_dim\": 32,\n",
    "        \"n_hidden_units\": 400,\n",
    "        \"bidirectional\": True,\n",
    "        \"lr\": 0.03,\n",
    "        \"batch_size\": 128,\n",
    "        \"use_adam_opt\": False,\n",
    "        \"n_epochs\": 50,\n",
    "    }]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Will try to terminate bad trials early\n",
    "# https://docs.ray.io/en/latest/tune/api_docs/schedulers.html\n",
    "scheduler = ASHAScheduler(max_t=100,\n",
    "                          grace_period=3,\n",
    "                          reduction_factor=4)\n",
    "\n",
    "# https://docs.ray.io/en/latest/tune/api_docs/suggestion.html#tune-hyperopt\n",
    "search_alg = HyperOptSearch(points_to_evaluate=current_best_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "ray.shutdown()\n",
    "ray.init(_redis_max_memory=4*10**9)  # give redis extra memory\n",
    "\n",
    "callbacks = []\n",
    "if wandb_api_key_file:\n",
    "    callbacks.append(WandbLoggerCallback(\n",
    "        project=\"nama\",\n",
    "        entity=\"nama\",\n",
    "        group=\"56_swivel_encoder_tune_\"+given_surname,\n",
    "        notes=\"\",\n",
    "        config=config._asdict(),\n",
    "        api_key_file=wandb_api_key_file\n",
    "    ))\n",
    "\n",
    "result = tune.run(\n",
    "    tune.with_parameters(ray_training_function,\n",
    "                         swivel_model=swivel_model,\n",
    "                         swivel_vocab=input_names_vocab,\n",
    "                         candidate_names_optimize_inputs=candidate_names_optimize_inputs,\n",
    "                         candidate_names_optimize_embeddings=candidate_names_optimize_embeddings,\n",
    "                         input_names_train=input_names_train,\n",
    "                         candidate_names_validate=candidate_names_validate,\n",
    "                         weighted_actual_names_validate=weighted_actual_names_validate,\n",
    "                         device=device),\n",
    "    resources_per_trial={\"cpu\": 0.5, \"gpu\": 1.0},\n",
    "    config=config_params,\n",
    "    scheduler=scheduler,\n",
    "    search_alg=search_alg,\n",
    "    num_samples=100,\n",
    "    metric=\"auc\",\n",
    "    mode=\"max\",\n",
    "    checkpoint_score_attr=\"auc\",\n",
    "    time_budget_s=24*3600,\n",
    "    keep_checkpoints_num=100,\n",
    "    progress_reporter=tune.JupyterNotebookReporter(\n",
    "        overwrite=False,\n",
    "        max_report_frequency=5*60\n",
    "    ),\n",
    "    callbacks=callbacks\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get best model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Get trial that has the highest AUC (can also do with mean_loss or any other metric)\n",
    "best_trial_auc = result.get_best_trial(metric='auc', mode='max', scope='all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Parameters with the highest AUC\n",
    "best_trial_auc.config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "print(f\"Best trial final train loss: {best_trial_auc.last_result['mean_loss']}\")\n",
    "print(f\"Best trial final train auc: {best_trial_auc.last_result['auc']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Get checkpoint dir for best model\n",
    "best_checkpoint_dir = best_trial_auc.checkpoint.value\n",
    "\n",
    "# Load best model\n",
    "model_state, optimizer_state = torch.load(os.path.join(best_checkpoint_dir, 'checkpoint'))\n",
    "best_trained_model = SwivelEncoderModel(n_layers=best_trial_auc.config[\"n_layers\"],\n",
    "                                        char_embed_dim=best_trial_auc.config[\"char_embed_dim\"],\n",
    "                                        n_hidden_units=best_trial_auc.config[\"n_hidden_units\"],\n",
    "                                        output_dim=embed_dim,\n",
    "                                        bidirectional=best_trial_auc.config[\"bidirectional\"],\n",
    "                                        device=device)\n",
    "best_trained_model.load_state_dict(model_state)\n",
    "best_trained_model.eval()\n",
    "best_trained_model.to(device=device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot PR curve on validate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot pr curve with best model\n",
    "best_matches = get_best_swivel_matches(swivel_model,\n",
    "                                       input_names_vocab,\n",
    "                                       input_names_train,\n",
    "                                       candidate_names_validate,\n",
    "                                       k=100,\n",
    "                                       batch_size=256,\n",
    "                                       add_context=True,\n",
    "                                       encoder_model=best_trained_model,\n",
    "                                       n_jobs=4)\n",
    "\n",
    "metrics.precision_weighted_recall_curve_at_threshold(weighted_actual_names_validate,\n",
    "                                                     best_matches,\n",
    "                                                     min_threshold=0.01,\n",
    "                                                     max_threshold=2.0,\n",
    "                                                     step=0.05,\n",
    "                                                     distances=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot PR curve on Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# plot pr curve with best model\n",
    "best_matches = get_best_swivel_matches(swivel_model,\n",
    "                                       input_names_vocab,\n",
    "                                       input_names_test,\n",
    "                                       candidate_names_test,\n",
    "                                       k=100,\n",
    "                                       batch_size=256,\n",
    "                                       add_context=True,\n",
    "                                       encoder_model=best_trained_model,\n",
    "                                       n_jobs=4)\n",
    "\n",
    "metrics.precision_weighted_recall_curve_at_threshold(weighted_actual_names_test,\n",
    "                                                     best_matches,\n",
    "                                                     min_threshold=0.01,\n",
    "                                                     max_threshold=2.0,\n",
    "                                                     step=0.05,\n",
    "                                                     distances=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Demo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "rndmx_name_idx = np.random.randint(len(input_names_test))\n",
    "print(f\"Input name:  {input_names_test[rndmx_name_idx]}\")\n",
    "print(\"Nearest names:\")\n",
    "print(best_matches[rndmx_name_idx][:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "print(\"Actual names:\")\n",
    "sorted(weighted_actual_names_test[rndmx_name_idx][:10], key=lambda k: k[1], reverse=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get all trials as DF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# All trials as pandas dataframe\n",
    "df = result.results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "df[(df[\"auc\"] > 0.78) & (df[\"mean_loss\"] < 0.31)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# precision and recall at a specific threshold\n",
    "\n",
    "from src.eval.metrics import precision_at_threshold, weighted_recall_at_threshold\n",
    "\n",
    "threshold = 0.4\n",
    "precision = np.mean([precision_at_threshold(a, c, threshold, distances=False) \\\n",
    "                     for a, c in zip(weighted_actual_names_validate, best_matches)])\n",
    "recall = np.mean([weighted_recall_at_threshold(a, c, threshold, distances=False) \\\n",
    "                     for a, c in zip(weighted_actual_names_validate, best_matches)])\n",
    "\n",
    "print(precision, recall)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nama",
   "language": "python",
   "name": "nama"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}

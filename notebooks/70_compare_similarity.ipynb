{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c63679db",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29a1d9ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import namedtuple\n",
    "\n",
    "import jellyfish\n",
    "import joblib\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.pyplot import cm\n",
    "from mpire import WorkerPool\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "# from rapidfuzz.string_metric import levenshtein\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils.extmath import safe_sparse_dot\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "import wandb\n",
    "\n",
    "from src.data.filesystem import fopen\n",
    "from src.data.utils import load_dataset, select_frequent_k, frequent_k_names\n",
    "from src.eval import metrics\n",
    "from src.eval.utils import similars_to_ndarray\n",
    "from src.models.ensemble import get_best_ensemble_matches\n",
    "from src.models.swivel import SwivelModel, get_best_swivel_matches\n",
    "from src.models.swivel_encoder import SwivelEncoderModel\n",
    "from src.models.utils import remove_padding, add_padding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e770235",
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "# config\n",
    "\n",
    "given_surname = \"surname\"\n",
    "vocab_size = 610000 if given_surname == \"given\" else 2100000\n",
    "sample_size = 10000\n",
    "embed_dim = 100\n",
    "encoder_layers = 2\n",
    "num_matches = 5000\n",
    "batch_size = 256\n",
    "Config = namedtuple(\"Config\", [\n",
    "    \"train_path\",\n",
    "    \"eval_path\",\n",
    "    \"test_path\",\n",
    "    \"freq_path\",\n",
    "    \"embed_dim\",\n",
    "    \"swivel_vocab_path\",\n",
    "    \"swivel_model_path\",\n",
    "    \"tfidf_path\",\n",
    "    \"ensemble_model_path_100\",\n",
    "])\n",
    "config = Config(\n",
    "    train_path=f\"s3://familysearch-names/processed/tree-hr-{given_surname}-train-augmented.csv.gz\",\n",
    "    eval_path=f\"s3://familysearch-names/processed/tree-hr-{given_surname}-train.csv.gz\",\n",
    "    test_path=f\"s3://familysearch-names/processed/tree-hr-{given_surname}-test.csv.gz\",\n",
    "    freq_path=f\"s3://familysearch-names/processed/tree-preferred-{given_surname}-aggr.csv.gz\",\n",
    "    embed_dim=embed_dim,\n",
    "    swivel_vocab_path=f\"s3://nama-data/data/models/fs-{given_surname}-swivel-vocab-{vocab_size}-augmented.csv\",\n",
    "    swivel_model_path=f\"s3://nama-data/data/models/fs-{given_surname}-swivel-model-{vocab_size}-{embed_dim}-augmented.pth\",\n",
    "    tfidf_path=f\"s3://nama-data/data/models/fs-{given_surname}-tfidf.joblib\",\n",
    "    ensemble_model_path_100=f\"s3://nama-data/data/models/fs-{given_surname}-ensemble-model-{vocab_size}-{embed_dim}-augmented-100.joblib\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b482fe7e",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "wandb.init(\n",
    "    project=\"nama\",\n",
    "    entity=\"nama\",\n",
    "    name=\"70_compare_similarity\",\n",
    "    group=given_surname,\n",
    "    notes=\"final\",\n",
    "    config=config._asdict(),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c2da8b6",
   "metadata": {},
   "source": [
    "### Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75c95ea6",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)\n",
    "if torch.cuda.is_available():\n",
    "    print(\"cuda total\", torch.cuda.get_device_properties(0).total_memory)\n",
    "    print(\"cuda reserved\", torch.cuda.memory_reserved(0))\n",
    "    print(\"cuda allocated\", torch.cuda.memory_allocated(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73bd600c",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_names_train, weighted_actual_names_train, candidate_names_train = load_dataset(config.train_path)\n",
    "input_names_eval, weighted_actual_names_eval, candidate_names_eval = load_dataset(config.eval_path, is_eval=True)\n",
    "input_names_test, weighted_actual_names_test, candidate_names_test = load_dataset(config.test_path, is_eval=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7310b7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "freq_df = pd.read_csv(config.freq_path, na_filter=False)\n",
    "name_freq = {add_padding(name): freq for name, freq in zip(freq_df[\"name\"], freq_df[\"frequency\"])}\n",
    "freq_df = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "822ffeb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_df = pd.read_csv(fopen(config.swivel_vocab_path, \"rb\"))\n",
    "swivel_vocab = {name: _id for name, _id in zip(vocab_df[\"name\"], vocab_df[\"index\"])}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8b34e8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "swivel_model = SwivelModel(len(swivel_vocab), config.embed_dim)\n",
    "swivel_model.load_state_dict(torch.load(fopen(config.swivel_model_path, \"rb\"), map_location=torch.device(device)))\n",
    "swivel_model.to(device)\n",
    "swivel_model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60330495",
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_vectorizer = joblib.load(fopen(config.tfidf_path, mode='rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4bb0ca3",
   "metadata": {},
   "outputs": [],
   "source": [
    "ensemble_model_100 = joblib.load(fopen(config.ensemble_model_path_100, mode='rb'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f930f91",
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove oov names from input_names_test and remove in-vocab names from candidate_names_test\n",
    "# so we only compare in-vocab against out-of-vocab\n",
    "input_names_test_iv = []\n",
    "weighted_actual_names_test_iv = []\n",
    "candidate_names_test_oov = []\n",
    "for input_name, weighted_actual_name in zip(input_names_test, weighted_actual_names_test):\n",
    "    if input_name not in swivel_vocab:\n",
    "        continue\n",
    "    input_names_test_iv.append(input_name)\n",
    "    weighted_actual_names_test_iv.append(weighted_actual_name)\n",
    "for candidate_name in candidate_names_test:\n",
    "    if candidate_name in swivel_vocab:\n",
    "        continue\n",
    "    candidate_names_test_oov.append(candidate_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c66b1e00",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(input_names_test))\n",
    "print(len(input_names_test_iv))\n",
    "print(len(candidate_names_test))\n",
    "print(len(candidate_names_test_oov))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a29113c",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_names_test = input_names_test_iv\n",
    "weighted_actual_names_test = weighted_actual_names_test_iv\n",
    "candidate_names_test = np.array(candidate_names_test_oov)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03a03eec",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# sample names (train, eval, and freq_eval for in-vocab and test for out-of-vocab)\n",
    "_, input_names_train_sample, _, weighted_actual_names_train_sample = \\\n",
    "    train_test_split(input_names_train, weighted_actual_names_train, test_size=sample_size)\n",
    "candidate_names_train_sample = candidate_names_train\n",
    "\n",
    "_, input_names_eval_sample, _, weighted_actual_names_eval_sample = \\\n",
    "    train_test_split(input_names_eval, weighted_actual_names_eval, test_size=sample_size)\n",
    "candidate_names_eval_sample = candidate_names_eval\n",
    "\n",
    "input_names_freq_eval_sample, weighted_actual_names_freq_eval_sample, candidate_names_freq_eval_sample = \\\n",
    "    select_frequent_k(input_names_eval, weighted_actual_names_eval, candidate_names_eval, \\\n",
    "                      k=sample_size)\n",
    "\n",
    "_, input_names_test_sample, _, weighted_actual_names_test_sample = \\\n",
    "    train_test_split(input_names_test, weighted_actual_names_test, test_size=sample_size)\n",
    "candidate_names_test_sample = candidate_names_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bb22f7d",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "print(\"input_names_train_sample\", len(input_names_train_sample))\n",
    "print(\"weighted_actual_names_train_sample\", len(weighted_actual_names_train_sample))\n",
    "print(\"candidate_names_train_sample\", len(candidate_names_train_sample))\n",
    "\n",
    "print(\"input_names_eval_sample\", len(input_names_eval_sample))\n",
    "print(\"weighted_actual_names_eval_sample\", len(weighted_actual_names_eval_sample))\n",
    "print(\"candidate_names_eval_sample\", len(candidate_names_eval_sample))\n",
    "\n",
    "print(\"input_names_freq_eval_sample\", len(input_names_freq_eval_sample))\n",
    "print(\"weighted_actual_names_freq_eval_sample\", len(weighted_actual_names_freq_eval_sample))\n",
    "print(\"candidate_names_freq_eval_sample\", len(candidate_names_freq_eval_sample))\n",
    "\n",
    "print(\"input_names_test_sample\", len(input_names_test_sample))\n",
    "print(\"weighted_actual_names_test_sample\", len(weighted_actual_names_test_sample))\n",
    "print(\"candidate_names_test_sample\", len(candidate_names_test_sample))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60ca74b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# free memory\n",
    "del input_names_train\n",
    "del weighted_actual_names_train\n",
    "del input_names_eval\n",
    "del weighted_actual_names_eval\n",
    "del input_names_test\n",
    "del weighted_actual_names_test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3292a668",
   "metadata": {},
   "source": [
    "### Create tfidf samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9bb5f2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_X_train_sample = tfidf_vectorizer.fit_transform(candidate_names_train_sample)\n",
    "tfidf_X_eval_sample = tfidf_vectorizer.transform(candidate_names_eval_sample)\n",
    "tfidf_X_freq_eval_sample = tfidf_vectorizer.transform(candidate_names_freq_eval_sample)\n",
    "tfidf_X_test_sample = tfidf_vectorizer.transform(candidate_names_test_sample)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a537fdf5",
   "metadata": {},
   "source": [
    "### Set up other algorithms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d73426c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_similarity_to(name, algo=\"levenshtein\"):\n",
    "    name = remove_padding(name)\n",
    "\n",
    "    def calc_similarity(row):\n",
    "        cand_name = remove_padding(row[0])\n",
    "        similarity = 0.0\n",
    "        if algo == \"levenshtein\":\n",
    "            dist = jellyfish.levenshtein_distance(name, cand_name)\n",
    "#             dist = levenshtein(name, cand_name)\n",
    "            similarity = 1 - (dist / max(len(name), len(cand_name)))\n",
    "        elif algo == \"damerau_levenshtein\":\n",
    "            dist = jellyfish.damerau_levenshtein_distance(name, cand_name)\n",
    "            similarity = 1 - (dist / max(len(name), len(cand_name)))\n",
    "        elif algo == \"jaro_winkler\":\n",
    "            similarity = jellyfish.jaro_winkler_similarity(name, cand_name)\n",
    "\n",
    "        return similarity\n",
    "\n",
    "    return calc_similarity"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adb71de7",
   "metadata": {},
   "source": [
    "#### Similarity Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fafabff1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_similars(shared, names, _=None):\n",
    "    candidate_names_test, k, algo, tfidf_vectorizer, tfidf_X_test = shared\n",
    "    \n",
    "    def get_similars_for_name(name):\n",
    "        if algo == \"tfidf\":\n",
    "            x = tfidf_vectorizer.transform([name]).toarray()\n",
    "            scores = safe_sparse_dot(tfidf_X_test, x.T).flatten()\n",
    "        else:\n",
    "            scores = np.apply_along_axis(calc_similarity_to(name, algo), 1, candidate_names_test[:, None])\n",
    "\n",
    "        # sorted_scores_idx = np.argsort(scores)[::-1][:k]\n",
    "        partitioned_idx = np.argpartition(scores, -k)[-k:]\n",
    "        sorted_partitioned_idx = np.argsort(scores[partitioned_idx])[::-1]\n",
    "        sorted_scores_idx = partitioned_idx[sorted_partitioned_idx]\n",
    "\n",
    "        candidate_names = candidate_names_test[sorted_scores_idx]\n",
    "        candidate_scores = scores[sorted_scores_idx]\n",
    "\n",
    "        return list(zip(candidate_names, candidate_scores))\n",
    "    \n",
    "    result = []\n",
    "    for name in names:\n",
    "        result.append(get_similars_for_name(name))\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "005f105b",
   "metadata": {},
   "source": [
    "#### Create batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c380dc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_batches(names, batch_size):\n",
    "    batches = []\n",
    "    for ix in range(0, len(names), batch_size):\n",
    "        # batches are tuples to keep mpire from expanding the batch \n",
    "        batches.append((names[ix:ix + batch_size], ix))\n",
    "    return batches"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c6cf259",
   "metadata": {},
   "source": [
    "#### Demo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3a3833d",
   "metadata": {},
   "outputs": [],
   "source": [
    "probe_name = \"<bostelman>\" if given_surname == \"surname\" else \"<richard>\"\n",
    "get_similars((candidate_names_test_sample, 10, \"levenshtein\", None, None), [probe_name])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2af839a6",
   "metadata": {},
   "source": [
    "# Evaluate each algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97f1ce29",
   "metadata": {},
   "outputs": [],
   "source": [
    "SimilarityAlgo = namedtuple(\"SimilarityAlgo\", \"name min_threshold max_threshold distances\")\n",
    "similarity_algos = [\n",
    "#     SimilarityAlgo(\"tfidf\", 0.0, 1.01, False),\n",
    "    SimilarityAlgo(\"swivel\", 0.0, 1.01, False),\n",
    "    SimilarityAlgo(\"ensemble_100\", 0.0, 1.01, False),\n",
    "    SimilarityAlgo(\"levenshtein\", 0.0, 1.01, False),\n",
    "#     SimilarityAlgo(\"damerau_levenshtein\", 0.0, 1.01, False),\n",
    "#     SimilarityAlgo(\"jaro_winkler\", 0.0, 1.01, False),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c94f343",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def evaluate_algos(similarity_algos, \n",
    "                   swivel_vocab, \n",
    "                   swivel_model,\n",
    "                   tfidf_vectorizer,\n",
    "                   ensemble_model_100,\n",
    "                   name_freq,\n",
    "                   input_names, \n",
    "                   weighted_actual_names, \n",
    "                   candidate_names, \n",
    "                   tfidf_X,\n",
    "                   num_matches):\n",
    "    n_jobs = 1\n",
    "    lev_jobs = 6\n",
    "    metrics_jobs = 4\n",
    "\n",
    "    figure, ax = plt.subplots(1, 1, figsize=(20, 15))\n",
    "    ax.set_title(\"PR at threshold\")\n",
    "    colors = cm.rainbow(np.linspace(0, 1, len(similarity_algos)))\n",
    "\n",
    "    for algo, color in zip(similarity_algos, colors):\n",
    "        print(algo.name)\n",
    "        if algo.name == \"swivel\":\n",
    "            similar_names_scores = get_best_swivel_matches(model=swivel_model, \n",
    "                                                           vocab=swivel_vocab, \n",
    "                                                           input_names=input_names,\n",
    "                                                           candidate_names=candidate_names, \n",
    "                                                           k=num_matches, \n",
    "                                                           batch_size=batch_size,\n",
    "                                                           add_context=True,\n",
    "                                                           n_jobs=n_jobs)\n",
    "        elif algo.name == \"ensemble_100\":\n",
    "            similar_names_scores = get_best_ensemble_matches(\n",
    "                model=swivel_model,\n",
    "                vocab=swivel_vocab,\n",
    "                name_freq=name_freq,\n",
    "                input_names=input_names,\n",
    "                candidate_names=candidate_names,\n",
    "                tfidf_vectorizer=tfidf_vectorizer,\n",
    "                ensemble_model=ensemble_model_100,\n",
    "                k=num_matches,\n",
    "                batch_size=batch_size,\n",
    "                add_context=True,\n",
    "                n_jobs=n_jobs,\n",
    "            )\n",
    "        else:\n",
    "            input_names_batches = create_batches(input_names, batch_size=batch_size)\n",
    "            with WorkerPool(\n",
    "                shared_objects=(candidate_names, num_matches, algo.name, tfidf_vectorizer, tfidf_X),\n",
    "                n_jobs=lev_jobs,\n",
    "            ) as pool:\n",
    "                similar_names_scores = pool.map(get_similars, input_names_batches, progress_bar=True)\n",
    "            input_names_batches = None\n",
    "            # flatten\n",
    "            similar_names_scores = [name_score for batch in similar_names_scores for name_score in batch]\n",
    "            # convert to ndarray\n",
    "            similar_names_scores = similars_to_ndarray(similar_names_scores)\n",
    "        print(\"calculating precision and recall\")\n",
    "        precisions, recalls = metrics.precision_weighted_recall_at_threshold(\n",
    "            weighted_actual_names,\n",
    "            similar_names_scores,\n",
    "            min_threshold=algo.min_threshold,\n",
    "            max_threshold=algo.max_threshold,\n",
    "            step=0.02,\n",
    "            distances=algo.distances,\n",
    "            n_jobs=metrics_jobs,\n",
    "            progress_bar=True,\n",
    "        )\n",
    "        similar_names_scores = None\n",
    "        print(\"auc\", metrics.get_auc_from_precisions_recalls(\n",
    "            precisions, \n",
    "            recalls, \n",
    "            distances=algo.distances\n",
    "        ))\n",
    "        ax.plot(recalls, precisions, \"o--\", color=color, label=algo.name)\n",
    "\n",
    "    ax.legend()\n",
    "    plt.xlim([0, 1.0])\n",
    "    plt.ylim([0, 1.0])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b547ebdd",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## on augmented in-vocabulary names (training data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2a204c2",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# evaluate_algos(similarity_algos, \n",
    "#                swivel_vocab, \n",
    "#                swivel_model,\n",
    "#                tfidf_vectorizer,\n",
    "#                ensemble_model_100,\n",
    "#                name_freq,\n",
    "#                input_names_train_sample, \n",
    "#                weighted_actual_names_train_sample, \n",
    "#                candidate_names_train_sample, \n",
    "#                tfidf_X_train_sample, \n",
    "#                num_matches)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67e35e45",
   "metadata": {},
   "source": [
    "## on original in-vocabulary names (eval data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "deee0eb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate_algos(similarity_algos, \n",
    "               swivel_vocab, \n",
    "               swivel_model, \n",
    "               tfidf_vectorizer,\n",
    "               ensemble_model_100,\n",
    "               name_freq,\n",
    "               input_names_eval_sample, \n",
    "               weighted_actual_names_eval_sample, \n",
    "               candidate_names_eval_sample, \n",
    "               tfidf_X_eval_sample,\n",
    "               num_matches)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e4f0f35",
   "metadata": {},
   "source": [
    "## on frequent in-vocabulary names (frequent eval data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "471e0a1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate_algos(similarity_algos, \n",
    "               swivel_vocab, \n",
    "               swivel_model, \n",
    "               tfidf_vectorizer,\n",
    "               ensemble_model_100,\n",
    "               name_freq,\n",
    "               input_names_freq_eval_sample, \n",
    "               weighted_actual_names_freq_eval_sample, \n",
    "               candidate_names_freq_eval_sample, \n",
    "               tfidf_X_freq_eval_sample,\n",
    "               num_matches)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71a8129c",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## on out-of-vocabulary names (test data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17deb6ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# make sure that test data doesn't include pairs where both are in the vocab\n",
    "n_zero = n_one = n_two = 0\n",
    "for input_name, wans in zip(input_names_test_sample, weighted_actual_names_test_sample):\n",
    "    for actual_name, _, _ in wans:\n",
    "        if input_name in swivel_vocab and actual_name in swivel_vocab and input_name != actual_name:\n",
    "            n_two += 1\n",
    "        elif input_name in swivel_vocab or actual_name in swivel_vocab:\n",
    "            n_one += 1\n",
    "        else:\n",
    "            n_zero += 1\n",
    "print(\"two names in vocab (should not be possible)\", n_two)\n",
    "print(\"one name in vocab\", n_one)\n",
    "print(\"zero names in vocab\", n_zero)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4f1d77d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# make sure that test data doesn't include pairs where both are in the vocab\n",
    "n_candidates_in_vocab = 0\n",
    "for candidate_name in candidate_names_test_sample:\n",
    "    if candidate_name in swivel_vocab:\n",
    "        n_candidates_in_vocab += 1\n",
    "n_inputs_in_vocab = 0\n",
    "for input_name in input_names_test_sample:\n",
    "    if input_name in swivel_vocab:\n",
    "        n_inputs_in_vocab += 1\n",
    "print(\"candidates total and in-vocab\", len(candidate_names_test_sample), n_candidates_in_vocab)\n",
    "print(\"inputs total and in-vocab\", len(input_names_test_sample), n_inputs_in_vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41560b20",
   "metadata": {},
   "outputs": [],
   "source": [
    "similarity_algos = [\n",
    "#     SimilarityAlgo(\"tfidf\", 0.0, 1.01, False),\n",
    "#     SimilarityAlgo(\"swivel\", 0.0, 1.01, False),\n",
    "    SimilarityAlgo(\"ensemble_100\", 0.0, 1.01, False),\n",
    "    SimilarityAlgo(\"levenshtein\", 0.0, 1.01, False),\n",
    "#     SimilarityAlgo(\"damerau_levenshtein\", 0.0, 1.01, False),\n",
    "#     SimilarityAlgo(\"jaro_winkler\", 0.0, 1.01, False),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf095c64",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "evaluate_algos(similarity_algos, \n",
    "               swivel_vocab, \n",
    "               swivel_model, \n",
    "               tfidf_vectorizer,\n",
    "               ensemble_model_100,\n",
    "               name_freq,\n",
    "               input_names_test_sample, \n",
    "               weighted_actual_names_test_sample, \n",
    "               candidate_names_test_sample, \n",
    "               tfidf_X_test_sample,\n",
    "               num_matches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55c8722a",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7955460f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nama",
   "language": "python",
   "name": "nama"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

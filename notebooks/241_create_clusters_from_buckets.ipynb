{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2882991e",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d671df72",
   "metadata": {},
   "source": [
    "# Split buckets into clusters and super-clusters using bi-encoder\n",
    "\n",
    "Load the parser and trained model, and use a hierarchal agglomerative clustering algorithm to split existing FamilySearch buckets into clusters and super-clusters based upon similarity computed using bi-encoder model. Each cluster contains the names in the bucket that the model determines are similar to each other, and each super-cluster contains all of the clusters in the bucket.\n",
    "\n",
    "Each cluster contains:\n",
    "\n",
    "1. a list of names, \n",
    "2. the most-common name as the cluster label (preceded by an underscore), and \n",
    "3. a cluster centroid: a vector depicting the center of the cluster. \n",
    "\n",
    "Each super-cluster contains:\n",
    "\n",
    "1. a list of cluster labels\n",
    "2. the most-common name in the cluster as the super-cluster label\n",
    "\n",
    "If a bucket has only one cluster, we don't create a super-cluster for the bucket.\n",
    "\n",
    "When determine which cluster a rare name belongs to, we will choose the closest centroid.\n",
    "\n",
    "The questions to answer are:\n",
    "\n",
    "1. Should we weight more-common names more than less-common names when computing the clusters?: log_10(freq)?\n",
    "2. Should we use average or complete linkage?\n",
    "3. What should the threshold be?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ab5d9f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "import json\n",
    "import math\n",
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.cluster import AgglomerativeClustering\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import torch\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "from src.models.biencoder import BiEncoder\n",
    "from src.models.tokenizer import get_tokenize_function_and_vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ff83f53",
   "metadata": {},
   "outputs": [],
   "source": [
    "# configure\n",
    "given_surname = \"given\"\n",
    "\n",
    "linkage = \"average\"  # average, complete\n",
    "similarity_threshold = 0.3  # 0.25-0.35 for average; 0.05 for complete\n",
    "cluster_freq_normalizer = \"none\"  # log, log10, none\n",
    "\n",
    "experiment_name = f\"{linkage}-{similarity_threshold}-{cluster_freq_normalizer}\"\n",
    "\n",
    "max_tokens = 10\n",
    "subwords_path=f\"../data/models/fs-{given_surname}-subword-tokenizer-2000f.json\"\n",
    "std_path = f\"../data/processed/std_{given_surname}-augmented.txt\"\n",
    "model_type = 'cecommon+0+aug-0-1'\n",
    "model_path = f\"../data/models/bi_encoder-{given_surname}-{model_type}.pth\"\n",
    "pref_path = f\"s3://familysearch-names/processed/tree-preferred-{given_surname}-aggr.csv.gz\"\n",
    "\n",
    "experiment_dir = f\"../reports/\"\n",
    "clusters_path = f\"../data/processed/clusters_{given_surname}-{linkage}-{similarity_threshold}-{cluster_freq_normalizer}.json\"\n",
    "super_clusters_path = f\"../data/processed/super_clusters_{given_surname}-{linkage}-{similarity_threshold}-{cluster_freq_normalizer}.json\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad87f02c",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56affce8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_cluster_freq(name):\n",
    "    freq = name_freq.get(name, 0)\n",
    "    if cluster_freq_normalizer == \"log\":\n",
    "        return max(1, math.floor(math.log(max(1,freq))))\n",
    "    elif cluster_freq_normalizer == \"log10\":\n",
    "        return max(1, math.floor(math.log10(max(1,freq))))\n",
    "    else:\n",
    "        return 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "deaa1fe1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load buckets\n",
    "bucket_names = defaultdict(set)\n",
    "name_buckets = defaultdict(set)\n",
    "with open(std_path, 'rt') as f:\n",
    "    for line in f.readlines():\n",
    "        names = line.strip().replace(':', '').split(' ')\n",
    "        bucket_name = names[0]\n",
    "        for name in names:\n",
    "            name = name.strip()\n",
    "            if len(name) == 0:\n",
    "                continue\n",
    "            bucket_names[bucket_name].add(name)\n",
    "            name_buckets[name].add(bucket_name)\n",
    "print(len(bucket_names), len(name_buckets))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf12581a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load pref names\n",
    "pref_df = pd.read_csv(pref_path, na_filter=False)\n",
    "name_freq = {name: freq for name, freq in zip(pref_df['name'], pref_df['frequency'])}\n",
    "pref_df = None\n",
    "print(len(name_freq))\n",
    "print('john', name_freq['john'], get_cluster_freq('john'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec03d8e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "cnt = 0\n",
    "for name in name_buckets:\n",
    "    if name not in name_freq:\n",
    "        cnt += 1\n",
    "        print(name)\n",
    "print(cnt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "356cb540",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_most_freq_name(names):\n",
    "    most_freq_name = None\n",
    "    most_freq_freq = None\n",
    "    for name in names:\n",
    "        freq = name_freq.get(name, 0)\n",
    "        if most_freq_name is None or freq > most_freq_freq:\n",
    "            most_freq_name = name\n",
    "            most_freq_freq = freq\n",
    "    return most_freq_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d701cfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load tokenize function\n",
    "tokenize, tokenizer_vocab = get_tokenize_function_and_vocab(\n",
    "    max_tokens=max_tokens,\n",
    "    subwords_path=subwords_path,\n",
    ")\n",
    "len(tokenizer_vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8768fe48",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load model\n",
    "model = torch.load(model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bf39b3f",
   "metadata": {},
   "source": [
    "## Cluster names"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df760a52",
   "metadata": {},
   "source": [
    "### compute embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b19a505a",
   "metadata": {},
   "outputs": [],
   "source": [
    "name_embedding = {}\n",
    "for names in tqdm(bucket_names.values()):\n",
    "    for name in names:\n",
    "        embedding = model.get_embedding(tokenize(name))\n",
    "        if linkage == \"ward\":\n",
    "            embedding /= np.linalg.norm(embedding)            \n",
    "        name_embedding[name] = embedding"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3367ceb",
   "metadata": {},
   "source": [
    "### create clusterer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63d8c5e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "clusterer = AgglomerativeClustering(\n",
    "    n_clusters=None,\n",
    "    metric=\"euclidean\" if linkage == \"ward\" else \"cosine\",\n",
    "    linkage=linkage,\n",
    "    distance_threshold=(1-similarity_threshold),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7375094e",
   "metadata": {},
   "source": [
    "### test clusterer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb1f29ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_names = ['abraham','abe','aabraham','ab','abaham','abaraham','abarham','abb','abelarde','abera','aberaham']\n",
    "X = []\n",
    "names = []\n",
    "for name in test_names:\n",
    "    embedding = name_embedding[name]\n",
    "    for _ in range(get_cluster_freq(name)):\n",
    "        names.append(name)\n",
    "        X.append(embedding)\n",
    "print(len(X))\n",
    "clustering = clusterer.fit(X)\n",
    "sub_clusters = [set() for _ in range(clustering.n_clusters_)]\n",
    "print('n_clusters', clustering.n_clusters_)\n",
    "print('labels', clustering.labels_)\n",
    "print('names', names)\n",
    "for name, sub_cluster in zip(names, clustering.labels_):\n",
    "    sub_clusters[sub_cluster].add(name)\n",
    "for sub_cluster in sub_clusters:\n",
    "    print(sub_cluster)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30331a86",
   "metadata": {},
   "source": [
    "### run clusterer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55325152",
   "metadata": {},
   "outputs": [],
   "source": [
    "bucket_clusters = {}\n",
    "for bucket_name, names in tqdm(bucket_names.items()):\n",
    "    if len(names) == 1:\n",
    "        clusters = [names]\n",
    "    else:\n",
    "        X = []\n",
    "        clustered_names = []\n",
    "        for name in names:\n",
    "            embedding = name_embedding[name]\n",
    "            for _ in range(get_cluster_freq(name)):\n",
    "                clustered_names.append(name)\n",
    "                X.append(embedding)\n",
    "        clustering = clusterer.fit(X)\n",
    "        clusters = [set() for _ in range(clustering.n_clusters_)]\n",
    "        for name, cluster in zip(clustered_names, clustering.labels_):\n",
    "            clusters[cluster].add(name)\n",
    "    bucket_clusters[bucket_name] = clusters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36337a99",
   "metadata": {},
   "source": [
    "## Evaluate results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dadc595",
   "metadata": {},
   "outputs": [],
   "source": [
    "bucket_cluster_total = sum(len(clusters) for clusters in bucket_clusters.values())\n",
    "print(len(bucket_clusters), bucket_cluster_total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86360730",
   "metadata": {},
   "outputs": [],
   "source": [
    "# what about the top 100, 1000 names?\n",
    "total_clusters = 0\n",
    "total_names = 0\n",
    "for ix, name in enumerate(name_freq.keys()):\n",
    "    if ix % 100 == 0 and ix > 0:\n",
    "        print(total_names, total_clusters / total_names)\n",
    "    if ix == 2000:\n",
    "        break\n",
    "    if name not in name_buckets:\n",
    "        continue\n",
    "    bucket_name = next(iter(name_buckets[name]))\n",
    "    total_clusters += len(bucket_clusters[bucket_name])\n",
    "    total_names += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a05c438",
   "metadata": {},
   "outputs": [],
   "source": [
    "for name in list(name_freq.keys())[:10]:\n",
    "    if name not in name_buckets:\n",
    "        continue\n",
    "    bucket_name = next(iter(name_buckets[name]))\n",
    "    print('***', name, bucket_name)\n",
    "    for ix, cluster in enumerate(bucket_clusters[bucket_name]):\n",
    "        print(' ', ix, get_most_freq_name(cluster), ':', ' '.join(cluster))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7efe7a89",
   "metadata": {},
   "source": [
    "### Write experiment report\n",
    "\n",
    "deprecated"
   ]
  },
  {
   "cell_type": "raw",
   "id": "87a1a1b7",
   "metadata": {},
   "source": [
    "# gather every 25'th name into an experiment\n",
    "experiment = {}\n",
    "for ix, (bucket_name, clusters) in enumerate(bucket_clusters.items()):\n",
    "    if ix % 25 != 0:\n",
    "        continue\n",
    "    experiment[bucket_name] = clusters"
   ]
  },
  {
   "cell_type": "raw",
   "id": "0d653f96",
   "metadata": {},
   "source": [
    "def name_sort_key(name):\n",
    "    freq = name_freq.get(name, 0)\n",
    "    return f\"{freq:12d}:{name}\""
   ]
  },
  {
   "cell_type": "raw",
   "id": "7fbade36",
   "metadata": {},
   "source": [
    "lines = []\n",
    "lines.append(f\"Experiment: {experiment_name}\")\n",
    "lines.append(f\"sub-buckets={bucket_cluster_total}\")\n",
    "for bucket_name, clusters in experiment.items():\n",
    "    lines.append(bucket_name)\n",
    "    clusters.sort(key=lambda cluster: name_sort_key(get_most_freq_name(cluster)), reverse=True)\n",
    "    for cluster in clusters:\n",
    "        cluster.sort(key=name_sort_key, reverse=True)\n",
    "        lines.append(f\"- {get_most_freq_name(cluster)}: {' '.join(cluster)}\")"
   ]
  },
  {
   "cell_type": "raw",
   "id": "07b04218",
   "metadata": {},
   "source": [
    "for line in lines:\n",
    "    print(line)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "cc1752f9",
   "metadata": {},
   "source": [
    "experiment_name"
   ]
  },
  {
   "cell_type": "raw",
   "id": "fd11adf9",
   "metadata": {},
   "source": [
    "experiment_filename = f\"{experiment_name}.txt\"\n",
    "with open(os.path.join(experiment_dir, experiment_filename), 'wt') as f:\n",
    "    f.write(\"\\n\".join(lines))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cbfb4ce",
   "metadata": {},
   "source": [
    "## Save Clusters and Super-Clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "582d08b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_cluster_centroid(cluster):\n",
    "    centroid = None\n",
    "    for name in cluster:\n",
    "        embedding = name_embedding[name]\n",
    "        for _ in range(get_cluster_freq(name)):\n",
    "            if centroid is None:\n",
    "                centroid = embedding.copy()\n",
    "            else:\n",
    "                centroid += embedding\n",
    "    return centroid / np.linalg.norm(centroid)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dcbde4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "get_cluster_freq('richard')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2d5daa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "emb1 = name_embedding['richard']\n",
    "emb2 = name_embedding['dallan']\n",
    "print(cosine_similarity([emb1], [emb2]))\n",
    "print(cosine_similarity([emb1], [emb1]))\n",
    "print(cosine_similarity([emb1], [emb1+emb2]))\n",
    "print(cosine_similarity([emb1], [get_cluster_centroid(['richard', 'dallan'])]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7173cf88",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_clusters = {}\n",
    "super_clusters = {}\n",
    "for bucket_name, clusters in bucket_clusters.items():\n",
    "    cluster_names = []\n",
    "    for cluster in clusters:\n",
    "        centroid = get_cluster_centroid(cluster)\n",
    "        cluster_name = f\"{bucket_name}/{get_most_freq_name(cluster)}\"\n",
    "        cluster_names.append(cluster_name)\n",
    "        all_clusters[cluster_name] = {\n",
    "            \"names\": list(cluster),\n",
    "            \"centroid\": centroid.tolist(),\n",
    "        }\n",
    "    if len(cluster_names) > 1:\n",
    "        super_clusters[bucket_name] = cluster_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5ae9082",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(all_clusters), len(super_clusters))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8acd092",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(clusters_path, super_clusters_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "373f49ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(clusters_path, 'wt') as f:\n",
    "    json.dump(all_clusters, f, indent=2)\n",
    "with open(super_clusters_path, 'wt') as f:\n",
    "    json.dump(super_clusters, f, indent=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67ae3e23",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nama",
   "language": "python",
   "name": "nama"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

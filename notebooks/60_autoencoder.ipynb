{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "medieval-dream",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "annoying-throat",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from src.data import constants\n",
    "from src.data.ancestry import load_train_test\n",
    "from src.metrics import metrics\n",
    "from src.models import utils\n",
    "from src.models.autoencoder import AutoEncoder, train_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "metric-approval",
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_NAME_LENGTH = 30"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "liberal-longitude",
   "metadata": {},
   "source": [
    "### Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "operational-heater",
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = load_train_test(f'../data/raw/records25k_data_train.csv',\n",
    "                              f'../data/raw/records25k_data_test.csv')\n",
    "_, _, candidate_names_train = train\n",
    "input_names_test, weighted_actual_names_test, candidate_names_test = test\n",
    "\n",
    "actual_names_test = [[name for name, _, _ in name_weights] for name_weights in weighted_actual_names_test]\n",
    "\n",
    "candidate_names_all = np.concatenate((candidate_names_train, candidate_names_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "official-fountain",
   "metadata": {},
   "source": [
    "### Build token index mappings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "potential-swift",
   "metadata": {},
   "outputs": [],
   "source": [
    "char_to_idx_map, idx_to_char_map = utils.build_token_idx_maps()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "median-prototype",
   "metadata": {},
   "source": [
    "### Convert names to ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "included-terminology",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare data for training\n",
    "# inputs and targets have the same data just in different representations 1-hot vs normal sequences\n",
    "candidate_names_train_X, candidate_names_train_y = utils.convert_names_to_model_inputs(candidate_names_train,\n",
    "                                                                                    char_to_idx_map,\n",
    "                                                                                    MAX_NAME_LENGTH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "incorporated-kingdom",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(candidate_names_train_X.shape, candidate_names_train_y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "patent-milton",
   "metadata": {},
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "referenced-inside",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "second-builder",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = AutoEncoder(input_size=constants.VOCAB_SIZE + 1,\n",
    "                    hidden_size=100,\n",
    "                    num_layers=1,\n",
    "                    seq_len=MAX_NAME_LENGTH,\n",
    "                    device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "architectural-addition",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_model(model, candidate_names_train_X, candidate_names_train_y, 100, 512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "mobile-donna",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model, '../models/anc-encoder-bilstm-100-512.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "essential-webmaster",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = torch.load('../models/anc-encoder-bilstm-100-512.pth')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "supposed-perry",
   "metadata": {},
   "source": [
    "### Understand AutoEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "regulated-county",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = torch.nn.CrossEntropyLoss()\n",
    "dataset_train = torch.utils.data.TensorDataset(candidate_names_train_X, candidate_names_train_y)\n",
    "data_loader = torch.utils.data.DataLoader(dataset_train, batch_size=512, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "conventional-england",
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = next(iter(data_loader))\n",
    "print(X.shape, y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "attempted-diversity",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.zero_grad()\n",
    "# Encode(input,hidden) -> (batch,seq,dirs*hidden), ((dirs*layers,batch,hidden),(dirs*layers,batch,hidden)) - x_encoded is the last hidden state\n",
    "_, (x_encoded, _) = model.lstm_encoder(X.to(device))\n",
    "print(x_encoded.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "amended-messaging",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concatenate left-right hidden vectors\n",
    "x_encoded = torch.cat([x_encoded[0], x_encoded[1]], dim=1)\n",
    "print(x_encoded.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "civil-possible",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reshape data to have seq_len time steps\n",
    "# TODO why do we copy x_encoded to every time step?\n",
    "x_encoded = x_encoded.unsqueeze(1).repeat(1, MAX_NAME_LENGTH, 1)\n",
    "print(x_encoded.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "tropical-option",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Decode(hidden*dirs,hidden) -> (batch,seq,dirs*hidden), ((dirs*layers,batch,hidden),(dirs*layers,batch,hidden)) - x_decoded is the output\n",
    "x_decoded, (_, _) = model.lstm_decoder(x_encoded)\n",
    "print(x_decoded.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "little-antique",
   "metadata": {},
   "outputs": [],
   "source": [
    "# linear layer(hidden,input) predicts characters\n",
    "x_prime = model.linear(x_decoded)\n",
    "print(x_prime.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "tender-intermediate",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reshape output to match CrossEntropyLoss input\n",
    "x_prime = x_prime.transpose(1, -1)\n",
    "print(x_prime.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "smaller-attitude",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute loss (batch,classes,seq), (batch,seq)\n",
    "loss = loss_fn(x_prime, y.to(device))\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "affecting-recovery",
   "metadata": {},
   "source": [
    "### Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "attended-lemon",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.to(\"cpu\")\n",
    "model.device=\"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fitting-width",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get Embeddings for the names from the encoder\n",
    "candidate_names_train_encoded = model(candidate_names_train_X, just_encoder=True).detach().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "humanitarian-canadian",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(candidate_names_train_X.shape)\n",
    "print(candidate_names_train_encoded.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "single-edwards",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert test name inputs to correct format\n",
    "input_names_test_X, input_names_test_y = utils.convert_names_to_model_inputs(input_names_test,\n",
    "                                                                          char_to_idx_map,\n",
    "                                                                          MAX_NAME_LENGTH)\n",
    "# Get Embeddings for the names from the encoder\n",
    "input_names_test_encoded = model(input_names_test_X, just_encoder=True).detach().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sweet-eagle",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(input_names_test_X.shape, input_names_test_y.shape)\n",
    "print(input_names_test_encoded.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "literary-future",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get embeddings for all candidate names (train + test)\n",
    "candidate_names_test_X, _ = utils.convert_names_to_model_inputs(candidate_names_test,\n",
    "                                                             char_to_idx_map,\n",
    "                                                             MAX_NAME_LENGTH)\n",
    "candidate_names_test_encoded = model(candidate_names_test_X, just_encoder=True).detach().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "supreme-polyester",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(candidate_names_test_X.shape)\n",
    "print(candidate_names_test_encoded.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "worse-secretary",
   "metadata": {},
   "outputs": [],
   "source": [
    "candidate_names_all_encoded = np.vstack((candidate_names_train_encoded, candidate_names_test_encoded))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bizarre-afternoon",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(candidate_names_all_encoded.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "occasional-boating",
   "metadata": {},
   "outputs": [],
   "source": [
    "k = 100\n",
    "candidate_names_scores = utils.get_best_matches(input_names_test_encoded,\n",
    "                                                candidate_names_all_encoded,\n",
    "                                                candidate_names_all,\n",
    "                                                num_candidates=k)\n",
    "print(candidate_names_scores.shape)\n",
    "print(candidate_names_scores[0, 0, 0])\n",
    "print(candidate_names_scores[0, 0, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "stock-archives",
   "metadata": {},
   "outputs": [],
   "source": [
    "candidate_names = candidate_names_scores[:, :, 0]\n",
    "print(candidate_names.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "passing-champagne",
   "metadata": {},
   "source": [
    "### Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "worldwide-active",
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics.precision_recall_curve_at_k(actual_names_test, candidate_names, k)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "valuable-generic",
   "metadata": {},
   "source": [
    "### mAP @ 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "coral-norwegian",
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics.mean_avg_precision_k(actual_names_test, candidate_names, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "moral-vertex",
   "metadata": {},
   "source": [
    "### mAP @ 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "framed-original",
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics.mean_avg_precision_k(actual_names_test, candidate_names, 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "corresponding-transportation",
   "metadata": {},
   "source": [
    "### Demo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "iraqi-dietary",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_name_X = ['<schumacher>']\n",
    "test_name_X, _ = utils.convert_names_to_model_inputs(test_name_X, char_to_idx_map, MAX_NAME_LENGTH)\n",
    "test_name_embedding = model(test_name_X, just_encoder=True).detach().numpy()\n",
    "\n",
    "print(utils.get_best_matches(test_name_embedding,\n",
    "                             candidate_names_all_encoded,\n",
    "                             candidate_names_all,\n",
    "                             num_candidates=10))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "streaming-ontario",
   "metadata": {},
   "source": [
    "## Evaluate using weighted relevant names and score thresholds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "retired-basketball",
   "metadata": {},
   "source": [
    "### Average precision at 0.97"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "distinguished-female",
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics.avg_precision_at_threshold(weighted_actual_names_test, candidate_names_scores, 0.97)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "brazilian-birthday",
   "metadata": {},
   "source": [
    "### Average recall at 0.97"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "passing-kingdom",
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics.avg_weighted_recall_at_threshold(weighted_actual_names_test, candidate_names_scores, 0.97)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "featured-traffic",
   "metadata": {},
   "source": [
    "### PR Curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "premier-shopping",
   "metadata": {},
   "outputs": [],
   "source": [
    "# minimum score threshold to test\n",
    "min_threshold = 0.5\n",
    "metrics.precision_weighted_recall_curve_at_threshold(weighted_actual_names_test, candidate_names_scores, min_threshold)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "certain-hampshire",
   "metadata": {},
   "source": [
    "### AUC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "southwest-merchant",
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics.get_auc(weighted_actual_names_test, candidate_names_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "executed-noise",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nama",
   "language": "python",
   "name": "nama"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

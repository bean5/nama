{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Clean preferred names and split into separate given and surname datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from os.path import join\n",
    "\n",
    "import csv\n",
    "from mpire import WorkerPool\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "from src.data.filesystem import glob\n",
    "from src.data.normalize import normalize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "in_path = \"s3://familysearch-names/raw/tree-preferred/\"\n",
    "given_out_path = \"s3://familysearch-names/interim/tree-preferred-given/\"\n",
    "surname_out_path = \"s3://familysearch-names/interim/tree-preferred-surname/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def normalize_given_and_join(name):\n",
    "    return \" \".join(normalize(name, False))\n",
    "\n",
    "def normalize_surname_and_join(name):\n",
    "    return \" \".join(normalize(name, True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def process_file(shared, filename):\n",
    "    given_out_path, surname_out_path = shared\n",
    "    basename = Path(filename).stem\n",
    "\n",
    "    df = pd.read_csv(\n",
    "        filename,\n",
    "        sep=\"|\",\n",
    "        compression=\"gzip\",\n",
    "        names=[\"name\"],\n",
    "        dtype={\"name\": str},\n",
    "        na_filter=False,\n",
    "        encoding=\"utf-8\",\n",
    "        encoding_errors=\"replace\",\n",
    "        on_bad_lines=\"warn\",\n",
    "        quoting=csv.QUOTE_NONE,    )\n",
    "\n",
    "    # create separate given and surname dataframes\n",
    "    given_df = df[[\"name\"]].copy()\n",
    "    surname_df = df[[\"name\"]].copy()\n",
    "    del df\n",
    "\n",
    "    # split names into given and surname\n",
    "    given_df[\"name\"] = given_df[\"name\"].str.replace(\"\\^.*$\", \"\", regex=True)\n",
    "    surname_df[\"name\"] = surname_df[\"name\"].str.replace(\"^.*\\^\", \"\", regex=True)\n",
    "\n",
    "    # filter out non-latin names\n",
    "    given_df = given_df[\n",
    "        given_df[\"name\"].str.endswith(\"~Latn\")\n",
    "    ]\n",
    "    surname_df = surname_df[\n",
    "        surname_df[\"name\"].str.endswith(\"~Latn\")\n",
    "    ]\n",
    "\n",
    "    # remove ~Latn suffix and lowercase\n",
    "    given_df[\"name\"] = given_df[\"name\"].str.replace(\n",
    "        \"~Latn$\", \"\", regex=True\n",
    "    ).str.lower()\n",
    "    surname_df[\"name\"] = surname_df[\"name\"].str.replace(\n",
    "        \"~Latn$\", \"\", regex=True\n",
    "    ).str.lower()\n",
    "\n",
    "    # normalize names and join the pieces back into a single space-separated string\n",
    "    given_df[\"name\"] = given_df[\"name\"].map(normalize_given_and_join)\n",
    "    surname_df[\"name\"] = surname_df[\"name\"].map(normalize_surname_and_join)\n",
    "\n",
    "    # write files\n",
    "    given_df.to_parquet(\n",
    "        join(given_out_path, basename) + \".parquet\", engine=\"pyarrow\", compression=\"snappy\"\n",
    "    )\n",
    "    surname_df.to_parquet(\n",
    "        join(surname_out_path, basename) + \".parquet\", engine=\"pyarrow\", compression=\"snappy\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# process files\n",
    "filenames = glob(join(in_path,\"*.gz\"))\n",
    "with WorkerPool(shared_objects=(given_out_path, surname_out_path)) as pool:\n",
    "    pool.map(process_file, filenames, progress_bar=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "7a8115de58066eb2ca8cfe29f0da77ee43c62745e34e8f6d96cac148b862780f"
  },
  "jupytext": {
   "encoding": "# -*- coding: utf-8 -*-",
   "main_language": "python"
  },
  "kernelspec": {
   "display_name": "nama",
   "language": "python",
   "name": "nama"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

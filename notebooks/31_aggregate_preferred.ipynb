{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Aggregate preferred names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from mpire import WorkerPool\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "from src.data.filesystem import glob\n",
    "from src.data.prepare import merge_surname_prefixes, remove_noise_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "in_path = \"s3://familysearch-names/interim/tree-preferred-surname/\"\n",
    "out_path = \"s3://familysearch-names/interim/tree-preferred-surname-aggr.csv.gz\"\n",
    "is_surname = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tqdm.pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read input files into dataframe array\n",
    "with WorkerPool() as pool:\n",
    "    dfs = pool.map(pd.read_parquet, glob(in_path + \"part-*\"), progress_bar=True)\n",
    "print(len(dfs))\n",
    "print(dfs[0].shape)\n",
    "print(dfs[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# process and pre-aggregate each dataframe\n",
    "def parameterize(dfs):\n",
    "    # a second element in the tuple is needed to keep mpire from trying to also iterate over the df\n",
    "    return [(df, ix) for ix, df in enumerate(dfs)]\n",
    "\n",
    "def process(df, ix):\n",
    "    # split into individual name pieces\n",
    "    df[\"name\"] = df[\"name\"].str.split()\n",
    "\n",
    "    # explode names\n",
    "    df = pd.DataFrame(\n",
    "        df.explode(\"name\", ignore_index=True).dropna()[\"name\"].tolist(),\n",
    "        columns=[\"name\"],\n",
    "    )\n",
    "\n",
    "    # group\n",
    "    df[\"frequency\"] = 1\n",
    "    return df.groupby([\"name\"]).sum().reset_index()\n",
    "\n",
    "with WorkerPool() as pool:\n",
    "    dfs = pool.map(process, parameterize(dfs), progress_bar=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "print(len(dfs))\n",
    "print(dfs[0].shape)\n",
    "print(dfs[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "# combine all dataframes into a single dataframe\n",
    "df = pd.concat(dfs)\n",
    "del dfs\n",
    "print(df.shape)\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "# group by name and sum frequency\n",
    "grouped = df.groupby([\"name\"]).sum().reset_index()\n",
    "del df\n",
    "print(grouped.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "# remove the empty name and single-occurrence names, and sort by descending frequency\n",
    "grouped = grouped[(grouped[\"name\"] != \"\") & (grouped[\"frequency\"] > 1)]\n",
    "grouped = grouped.sort_values(by='frequency', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(grouped.memory_usage(deep=True))\n",
    "print(grouped)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# write to csv\n",
    "grouped.to_csv(out_path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "0715013af127e2dc4bb03749d8253e928c185e319349e2573055324de1fe4a80"
  },
  "jupytext": {
   "main_language": "python"
  },
  "kernelspec": {
   "display_name": "nama",
   "language": "python",
   "name": "nama"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a9c0cca",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ccdd2bd",
   "metadata": {},
   "source": [
    "# Analyze sub-clusters to see if they are closer to other clusters\n",
    "\n",
    "The questions to answer are:\n",
    "\n",
    "1. Which sub-clusters are closer to sub-clusters in another cluster than to the sub-clusters in their own cluster?\n",
    "2. Which sub-clusters are really close to sub-clusters in other clusters, and how close are they?\n",
    "3. **How many bad mistakes is the name-to-vec making?**\n",
    "\n",
    "Steps:\n",
    "\n",
    "1. Compute sub-cluster centroids\n",
    "2. For each sub-cluster, calculate the similarity between that sub-cluster and all other sub-clusters\n",
    "3. Report any sub-clusters that are either \n",
    "   - very close to a sub-cluster in another cluster, or \n",
    "   - are closer to a sub-cluster in another cluster than to the nearest sub-cluster in their own cluster, or\n",
    "   - two out of the three closest sub-clusters are in another cluster, or\n",
    "   - are closer to the centroid of another cluster than the centroid of their own cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eebae341",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "import json\n",
    "import os\n",
    "import random\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import torch\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "from src.models.biencoder import BiEncoder\n",
    "from src.models.tokenizer import get_tokenize_function_and_vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0479328",
   "metadata": {},
   "outputs": [],
   "source": [
    "# configure\n",
    "given_surname = \"given\"\n",
    "\n",
    "other_cluster_similarity_threshold = 0.9\n",
    "\n",
    "distance_threshold = 0.65\n",
    "sub_clusters_path = f\"../data/models/sub_clusters_{given_surname}-{distance_threshold}.json\"\n",
    "nama_bucket = 'nama-data'\n",
    "vocab_type = 'f'\n",
    "subword_vocab_size = 2000\n",
    "subwords_path=f\"data/models/fs-{given_surname}-subword-tokenizer-{subword_vocab_size}{vocab_type}.json\"\n",
    "pref_path = f\"s3://familysearch-names/processed/tree-preferred-{given_surname}-aggr.csv.gz\"\n",
    "model_path = f\"../data/models/bi_encoder-{given_surname}.pth\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7472cde1",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "144fef97",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load sub-clusters\n",
    "with open(sub_clusters_path, 'rt') as f:\n",
    "    clusters = json.load(f)\n",
    "print(len(clusters))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0457dab6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load model\n",
    "model = torch.load(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dca9da7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load tokenize function\n",
    "tokenize, tokenizer_vocab = get_tokenize_function_and_vocab(\n",
    "    subwords_path=subwords_path,\n",
    "    nama_bucket=nama_bucket,\n",
    ")\n",
    "len(tokenizer_vocab)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "297bdbe1",
   "metadata": {},
   "source": [
    "## Compute cluster and sub-cluster centroids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07d224d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sub_cluster_key(cluster_name, sub_cluster_name):\n",
    "    return f\"{cluster_name}/{sub_cluster_name}\"\n",
    "\n",
    "def get_cluster_from_key(key):\n",
    "    return key.split('/')[0]\n",
    "\n",
    "def get_sub_cluster_from_key(key):\n",
    "    return key.split('/')[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "264db928",
   "metadata": {},
   "outputs": [],
   "source": [
    "name_embeddings = {}\n",
    "cluster_centroids = {}\n",
    "sub_cluster_centroids = {}\n",
    "\n",
    "for cluster_name, cluster in tqdm(clusters.items()):\n",
    "    cluster_embeddings = []\n",
    "    for sub_cluster_name, sub_cluster in cluster.items():\n",
    "        sub_cluster_embeddings = []\n",
    "        for name in sub_cluster:\n",
    "            embedding = model.get_embedding(tokenize(name))\n",
    "            # normalize embedding\n",
    "            embedding /= np.linalg.norm(embedding)\n",
    "            name_embeddings[name] = embedding\n",
    "            sub_cluster_embeddings.append(embedding)\n",
    "            cluster_embeddings.append(embedding)\n",
    "        centroid = np.array(sub_cluster_embeddings).sum(axis=0) / len(sub_cluster_embeddings)\n",
    "        # normalize centroid\n",
    "        centroid /= np.linalg.norm(centroid)\n",
    "        sub_cluster_centroids[get_sub_cluster_key(cluster_name, sub_cluster_name)] = centroid\n",
    "    centroid = np.array(cluster_embeddings).sum(axis=0) / len(cluster_embeddings)\n",
    "    cluster_centroids[cluster_name] = centroid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f94b7d67",
   "metadata": {},
   "outputs": [],
   "source": [
    "# turn sub-cluster centroids into a numpy array\n",
    "all_sub_cluster_centroids = []\n",
    "sub_cluster_keys = []     # map index to key\n",
    "sub_cluster_indices = {}  # max key to index\n",
    "\n",
    "for ix, (key, centroid) in enumerate(sub_cluster_centroids.items()):\n",
    "    all_sub_cluster_centroids.append(centroid)\n",
    "    sub_cluster_keys.append(key)\n",
    "    sub_cluster_indices[key] = ix\n",
    "    \n",
    "all_sub_cluster_centroids = np.array(all_sub_cluster_centroids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a464bce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# turn cluster centroids into a numpy array\n",
    "all_cluster_centroids = []\n",
    "cluster_keys = []     # map index to key\n",
    "cluster_indices = {}  # max key to index\n",
    "\n",
    "for ix, (key, centroid) in enumerate(cluster_centroids.items()):\n",
    "    all_cluster_centroids.append(centroid)\n",
    "    cluster_keys.append(key)\n",
    "    cluster_indices[key] = ix\n",
    "    \n",
    "all_cluster_centroids = np.array(all_cluster_centroids)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74046a51",
   "metadata": {},
   "source": [
    "## Check similarities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43bcd3bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_most_similar_centroids(centroid, all_centroids, k):\n",
    "    # Calculate the dot product\n",
    "    similarities = np.dot(all_centroids, centroid)\n",
    "    # Find the indices of the top k most similar vectors\n",
    "    top_indices = np.argpartition(similarities, -k)[-k:]\n",
    "    # Sort the top_indices by similarity (descending order)\n",
    "    top_indices = top_indices[np.argsort(similarities[top_indices])[::-1]]\n",
    "    # Get the similarities of the top k vectors\n",
    "    top_similarities = similarities[top_indices]    \n",
    "    return top_indices, top_similarities\n",
    "\n",
    "def calc_similarity_to_sub_cluster(sub_cluster_key1, sub_cluster_key2):\n",
    "    centroid1 = np.array(sub_cluster_centroids[sub_cluster_key1])\n",
    "    centroid2 = np.array(sub_cluster_centroids[sub_cluster_key2])\n",
    "    return  np.dot(centroid1, centroid2)\n",
    "\n",
    "def calc_similarity_to_cluster(sub_cluster_key, cluster_key):\n",
    "    centroid1 = np.array(sub_cluster_centroids[sub_cluster_key])\n",
    "    centroid2 = np.array(cluster_centroids[cluster_key])\n",
    "    return  np.dot(centroid1, centroid2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "208923cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check possible mistakes\n",
    "def check_mistake(key, other_key):\n",
    "    sub_cluster = get_sub_cluster_from_key(key)\n",
    "    cluster = get_cluster_from_key(key)\n",
    "    cluster_similarity = calc_similarity_to_cluster(key, cluster)\n",
    "    print('THIS', key, clusters[cluster][sub_cluster], cluster_similarity)\n",
    "    for other_sub_cluster in clusters[cluster]:\n",
    "        similarity = calc_similarity_to_sub_cluster(key, get_sub_cluster_key(cluster, other_sub_cluster))\n",
    "        print(other_sub_cluster, similarity, clusters[cluster][other_sub_cluster])\n",
    "    other_sub_cluster = get_sub_cluster_from_key(other_key)\n",
    "    other_cluster = get_cluster_from_key(other_key)\n",
    "    similarity = calc_similarity_to_sub_cluster(key, other_key)\n",
    "    print('OTHER', other_key, similarity, clusters[other_cluster][other_sub_cluster])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "860d77c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# how often do these mistakes happen?\n",
    "#   where a sub-cluster is far away from the cluster centroid and it isn't a nickname/cognate\n",
    "#   where a sub-cluster is close to another sub-cluster that has nothing to do with it\n",
    "#   we want to minimize these occurrences\n",
    "# why is this sub-cluster centroid so far from the aaron cluster centroid?\n",
    "# we need to try to improve name-to-vec\n",
    "#   train a cross-encoder from the triplets\n",
    "#   use the cross-encoder to score WANs, name-variants, common-non-negatives, high-freq name pairs\n",
    "#      with in-batch negatives to generate new triplets\n",
    "#   train a bi-encoder with the new triplets\n",
    "#   fine-tune the bi-encoder using the original triplets\n",
    "\n",
    "check_mistake('aaron/ehren', 'severino/sovren')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b065410",
   "metadata": {},
   "outputs": [],
   "source": [
    "check_mistake('asta/austie', 'austacia/austacia')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00300ef8",
   "metadata": {},
   "outputs": [],
   "source": [
    "check_mistake('aaron/erin', 'er/er')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b582c112",
   "metadata": {},
   "source": [
    "## Report sub-clusters that need to be reviewed\n",
    "\n",
    "Sub-clusters that are more similar to sub-clusters in another cluster than sub-clusters in their own cluster should be reviewed for possibly moving to the other cluster, or merging the two clusters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "606a34a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "k = 3\n",
    "for cnt, (cluster_name, cluster) in tqdm(enumerate(clusters.items())):\n",
    "    if cnt > 20:\n",
    "        break\n",
    "    for sub_cluster_name, sub_cluster in cluster.items():\n",
    "        # get the key for this sub-cluster\n",
    "        key = get_sub_cluster_key(cluster_name, sub_cluster_name)\n",
    "#         print(key)\n",
    "        # get the centroid for this key\n",
    "        sub_cluster_centroid = np.array(sub_cluster_centroids[key])\n",
    "        \n",
    "        # get closest k+1 sub-clusters\n",
    "        top_indices, top_similarities = find_most_similar_centroids(\n",
    "            sub_cluster_centroid, \n",
    "            all_sub_cluster_centroids, \n",
    "            k=k+1\n",
    "        )\n",
    "        top_indices = top_indices.tolist()\n",
    "        top_similarities = top_similarities.tolist()\n",
    "#         print(top_indices, top_similarities)\n",
    "        # remove this sub-cluster from the top results\n",
    "        sub_cluster_ix = sub_cluster_indices[key]\n",
    "        if sub_cluster_ix in top_indices:\n",
    "            ix = top_indices.index(sub_cluster_ix)\n",
    "            del top_indices[ix]\n",
    "            del top_similarities[ix]\n",
    "        else:\n",
    "            print(f\"WARNING {sub_cluster_ix} not found in {top_indices} with similarities {top_similarities}\")\n",
    "            top_indices = top_indices[:k]\n",
    "            top_similarities = top_similarities[:k]\n",
    "\n",
    "#         print(top_indices, top_similarities)\n",
    "#         for top_index in top_indices:\n",
    "#             print(top_index, sub_cluster_keys[top_index])\n",
    "\n",
    "        # check if this sub-cluster\n",
    "\n",
    "        # is very close to a sub-cluster in another cluster\n",
    "        for ix, similarity in zip(top_indices, top_similarities):\n",
    "            other_key = sub_cluster_keys[ix]\n",
    "            other_cluster = get_cluster_from_key(other_key)\n",
    "            if similarity > other_cluster_similarity_threshold and other_cluster != cluster_name:\n",
    "                print(f\"1. Sub-cluster {key} is very similar to {other_key} with similarity {similarity}\")\n",
    "\n",
    "        # is closer to a sub-cluster in another cluster than to the nearest sub-cluster in its own cluster\n",
    "        other_key = sub_cluster_keys[top_indices[0]]\n",
    "        other_cluster = get_cluster_from_key(other_key)\n",
    "        if len(cluster) > 1 and other_cluster != cluster_name:\n",
    "            print(f\"2. Sub-cluster {key} is closer to {other_key} with similarity {similarity} than to a sub-cluster in its own cluster: {list(cluster.keys())}\")\n",
    "\n",
    "        # has more than half of the closest sub-clusters in another cluster\n",
    "        top_clusters = [get_cluster_from_key(sub_cluster_keys[ix]) for ix in top_indices]\n",
    "        for top_cluster in set(top_clusters):\n",
    "            if top_clusters.count(top_cluster) > k / 2:\n",
    "                print(f\"3. Sub-cluster {key} has more than half of its closest sub-clusters in cluster {top_cluster}\")\n",
    "\n",
    "        # is closer to the centroid of another cluster than the centroid of its own cluster        \n",
    "        top_indices, top_similarities = find_most_similar_centroids(sub_cluster_centroid, all_cluster_centroids, k=1)\n",
    "#         print(\"cluster\", top_indices, top_similarities, cluster_keys[top_indices[0]])\n",
    "        other_cluster = cluster_keys[top_indices[0]]\n",
    "        if other_cluster != cluster_name:\n",
    "            print(f\"4. Sub-cluster {key} is closer to cluster {other_cluster} with similarity {top_similarities[0]} than its own cluster\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95e0160b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23033d7c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0b5c3d4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06ad1ecd",
   "metadata": {},
   "outputs": [],
   "source": [
    "len([sim for sim in similarities if sim < 0.5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e94f0d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 6))\n",
    "plt.hist(random.sample(similarities, 10000), bins=40, label=\"Name similarity to centroid\")\n",
    "plt.title('Centroid similarities')\n",
    "plt.xlabel('similarity')\n",
    "plt.ylabel('Frequency')\n",
    "\n",
    "# Show the plot\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b88d13c5",
   "metadata": {},
   "source": [
    "### Plot number of sub-clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bd261fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_sub_clusters = []\n",
    "for cluster in clusters.values():\n",
    "    n_sub_clusters.append(len(cluster))\n",
    "len(n_sub_clusters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41626cad",
   "metadata": {},
   "outputs": [],
   "source": [
    "len([n for n in n_sub_clusters if n > 10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "403caa7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(clusters['elizabeth'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d48c6024",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 6))\n",
    "plt.hist(n_sub_clusters, bins=40, label=\"Number of Sub-clusters\")\n",
    "plt.title('Number of Sub-clusters')\n",
    "plt.xlabel('Number of Sub-clusters')\n",
    "plt.ylabel('Frequency')\n",
    "\n",
    "# Show the plot\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62cb0231",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nama",
   "language": "python",
   "name": "nama"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

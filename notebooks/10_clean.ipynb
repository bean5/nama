{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clean raw names and split into separate given and surname datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from os.path import join\n",
    "from pathlib import Path\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "\n",
    "from src.data.prepare import normalize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "in_path = \"../data-raw/tree-hr/\"\n",
    "given_out_path = \"../data-raw/tree-hr-given/\"\n",
    "surname_out_path = \"../data-raw/tree-hr-surname/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def normalize_given_and_join(name):\n",
    "    return \" \".join(normalize(name, False))\n",
    "\n",
    "def normalize_surname_and_join(name):\n",
    "    return \" \".join(normalize(name, True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# process files\n",
    "# TODO switch this over to mpire\n",
    "filenames = list(Path(in_path).glob(\"*.gz\"))\n",
    "for f in tqdm(filenames):\n",
    "    basename = f.stem\n",
    "\n",
    "    df = pd.read_csv(\n",
    "        f,\n",
    "        sep=\"|\",\n",
    "        compression=\"gzip\",\n",
    "        names=[\"name\", \"alt_name\"],\n",
    "        dtype={\"name\": str, \"alt_name\": str},\n",
    "        na_filter=False,\n",
    "        encoding=\"utf-8\",\n",
    "    )\n",
    "\n",
    "    # create separate given and surname dataframes\n",
    "    given_df = df[[\"name\", \"alt_name\"]].copy()\n",
    "    surname_df = df[[\"name\", \"alt_name\"]].copy()\n",
    "    del df\n",
    "\n",
    "    # split names into given and surname\n",
    "    given_df[\"name\"] = given_df[\"name\"].str.replace(\"\\^.*$\", \"\", regex=True)\n",
    "    given_df[\"alt_name\"] = given_df[\"alt_name\"].str.replace(\"\\^.*$\", \"\", regex=True)\n",
    "    surname_df[\"name\"] = surname_df[\"name\"].str.replace(\"^.*\\^\", \"\", regex=True)\n",
    "    surname_df[\"alt_name\"] = surname_df[\"alt_name\"].str.replace(\"^.*\\^\", \"\", regex=True)\n",
    "\n",
    "    # filter out non-latin names\n",
    "    given_df = given_df[\n",
    "        given_df[\"name\"].str.endswith(\"~Latn\")\n",
    "        & given_df[\"alt_name\"].str.endswith(\"~Latn\")\n",
    "    ]\n",
    "    surname_df = surname_df[\n",
    "        surname_df[\"name\"].str.endswith(\"~Latn\")\n",
    "        & surname_df[\"alt_name\"].str.endswith(\"~Latn\")\n",
    "    ]\n",
    "\n",
    "    # remove ~Latn suffix\n",
    "    given_df[\"name\"] = given_df[\"name\"].str.replace(\n",
    "        \"~Latn$\", \"\", regex=True\n",
    "    )\n",
    "    given_df[\"alt_name\"] = given_df[\"alt_name\"].str.replace(\n",
    "        \"~Latn$\", \"\", regex=True\n",
    "    )\n",
    "    surname_df[\"name\"] = surname_df[\"name\"].str.replace(\n",
    "        \"~Latn$\", \"\", regex=True\n",
    "    )\n",
    "    surname_df[\"alt_name\"] = surname_df[\"alt_name\"].str.replace(\n",
    "        \"~Latn$\", \"\", regex=True\n",
    "    )\n",
    "\n",
    "    # normalize names and join the pieces back into a single space-separated string\n",
    "    given_df[\"name\"] = given_df[\"name\"].map(normalize_given_and_join)\n",
    "    given_df[\"alt_name\"] = given_df[\"alt_name\"].map(normalize_given_and_join)\n",
    "    surname_df[\"name\"] = surname_df[\"name\"].map(normalize_surname_and_join)\n",
    "    surname_df[\"alt_name\"] = surname_df[\"alt_name\"].map(normalize_surname_and_join)\n",
    "\n",
    "    # remove exact matches\n",
    "    given_df = given_df[given_df[\"name\"] != given_df[\"alt_name\"]]\n",
    "    surname_df = surname_df[surname_df[\"name\"] != surname_df[\"alt_name\"]]\n",
    "\n",
    "    # write files\n",
    "    given_df.to_parquet(\n",
    "        join(given_out_path, basename) + \".parquet\", engine=\"pyarrow\", compression=\"snappy\"\n",
    "    )\n",
    "    surname_df.to_parquet(\n",
    "        join(surname_out_path, basename) + \".parquet\", engine=\"pyarrow\", compression=\"snappy\"\n",
    "    )"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "7a8115de58066eb2ca8cfe29f0da77ee43c62745e34e8f6d96cac148b862780f"
  },
  "jupytext": {
   "encoding": "# -*- coding: utf-8 -*-",
   "main_language": "python"
  },
  "kernelspec": {
   "display_name": "Python 3.8.11 64-bit ('cookiecutter': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Generate a glove model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from collections import namedtuple\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "import torch\n",
    "import wandb\n",
    "\n",
    "from src.data.filesystem import fopen\n",
    "from src.data.utils import load_train_test\n",
    "from src.eval import metrics\n",
    "from src.models.glove import GloveDataset, GloveModel, train_glove, get_best_glove_matches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Config\n",
    "\n",
    "given_surname = \"given\"\n",
    "size = \"freq\"\n",
    "vocab_size = 500000\n",
    "embed_dim = 200\n",
    "Config = namedtuple(\"Config\", \"train_path vocab_size embed_dim glove_vocab_path glove_model_path\")\n",
    "config = Config(\n",
    "    train_path=f\"s3://familysearch-names/processed/tree-hr-{given_surname}-similar-train-{size}.csv.gz\",\n",
    "    vocab_size=vocab_size,\n",
    "    embed_dim=embed_dim,\n",
    "    glove_vocab_path=f\"s3://nama-data/data/models/fs-{given_surname}-{size}-glove-{vocab_size}-vocab-tfidf.csv\",\n",
    "    glove_model_path=f\"s3://nama-data/data/models/fs-{given_surname}-{size}-glove-{vocab_size}-{embed_dim}-tfidf.pt\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "wandb.init(\n",
    "    project=\"nama\",\n",
    "    entity=\"nama\",\n",
    "    name=\"52_glove\",\n",
    "    group=given_surname,\n",
    "    notes=\"\",\n",
    "    config=config._asdict()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "[train] = load_train_test([config.train_path])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "input_names_train, weighted_actual_names_train, candidate_names_train = train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "print(\"input_names_train\", len(input_names_train))\n",
    "print(\"weighted_actual_names_train\", sum(len(wan) for wan in weighted_actual_names_train))\n",
    "print(\"candidate_names_train\", len(candidate_names_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "symmetric=True\n",
    "dataset = GloveDataset(input_names_train, weighted_actual_names_train, config.vocab_size, device=device, symmetric=symmetric)\n",
    "vocab = dataset.get_vocab()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get vocab names in order by id\n",
    "vocab_names = list(name_id[0] for name_id in sorted(vocab.items(), key=lambda x: x[1]))\n",
    "print(len(vocab_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create vectors with tfidf values\n",
    "max_ngram = 4\n",
    "min_df = 10\n",
    "max_df = 0.5\n",
    "tfidf_vectorizer = TfidfVectorizer(ngram_range=(1, max_ngram), analyzer=\"char_wb\", min_df=min_df, max_df=max_df)\n",
    "tfidf_X_train = tfidf_vectorizer.fit_transform(vocab_names)\n",
    "print(tfidf_X_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reduce tfidf values to embed_dim\n",
    "svd = TruncatedSVD(n_components=config.embed_dim)\n",
    "tfidf_X_train = svd.fit_transform(tfidf_X_train)\n",
    "print(tfidf_X_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = GloveModel(len(vocab), config.embed_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# init weights to tfidf values\n",
    "model.wi.weight.data = torch.from_numpy(tfidf_X_train)\n",
    "model.wj.weight.data = torch.from_numpy(tfidf_X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "model.to(device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "n_epochs = 50  # 100\n",
    "batch_size = 64\n",
    "learning_rate = 0.05\n",
    "x_max = 100\n",
    "alpha = 0.75\n",
    "loss_values = train_glove(model, dataset, n_epochs=n_epochs, batch_size=batch_size, x_max=x_max, alpha=alpha, lr=learning_rate, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "ax = plt.gca()\n",
    "ax.set_ylim([0, 0.01])\n",
    "plt.plot(loss_values[::1000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_df = pd.DataFrame(vocab.items(), columns=[\"name\", \"index\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_df.to_csv(fopen(config.glove_vocab_path, \"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "torch.save(model.state_dict(), fopen(config.glove_model_path, \"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "model.load_state_dict(torch.load(fopen(config.glove_model_path, \"rb\")))\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# make sure all the names are in the model\n",
    "for name in input_names_train:\n",
    "    if name not in vocab.keys():\n",
    "        print(\"name missing\", name)\n",
    "        break\n",
    "for name in candidate_names_train:\n",
    "    if name not in vocab.keys():\n",
    "        print(\"name missing\", name)\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# get best matches\n",
    "# NOTE: only considers as potential matches names in candidate_names_train, not names in input_names_train\n",
    "k = 100\n",
    "batch_size = 256\n",
    "add_context = True\n",
    "best_matches = get_best_glove_matches(model, vocab, input_names_train, candidate_names_train, k, batch_size, add_context=add_context)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PR Curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "metrics.precision_weighted_recall_curve_at_threshold(\n",
    "    weighted_actual_names_train, best_matches, min_threshold=0.01, max_threshold=1.0, step=0.05, distances=False\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from src.models.glove import get_glove_embeddings\n",
    "from sklearn.metrics.pairwise import cosine_similarity, euclidean_distances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# demo names\n",
    "input_names_train = [\"<john>\", \"<mary>\"]\n",
    "weighted_actual_names_train = [\n",
    "    [(\"<johnny>\", 0.2, 20), (\"<jonathan>\", 0.5, 50), (\"<jon>\", 0.3, 30)],\n",
    "    [(\"<marie>\", 0.7, 70), (\"<maria>\", 0.3, 30)],\n",
    "    # [(\"<johnny>\", 0.2, 20), (\"<jonathan>\", 0.5, 50), (\"<jon>\", 0.3, 30), (\"<mary>\", 0.0, 0.5)],\n",
    "    # [(\"<marie>\", 0.7, 70), (\"<maria>\", 0.3, 30), (\"<john>\", 0.0, 0.5)],\n",
    "    # [(\"<johnny>\", 0.2, 20), (\"<jonathan>\", 0.5, 50), (\"<jon>\", 0.3, 30), (\"<mary>\", 0.0, 1), (\"<maria>\", 0.0, 1), (\"<marie>\", 0.0, 1)],\n",
    "    # [(\"<marie>\", 0.7, 70), (\"<maria>\", 0.3, 30), (\"<john>\", 0.0, 1), (\"<johnny>\", 0.0, 1), (\"<jonathan>\", 0.0, 1), (\"<jon>\", 0.0, 1)],\n",
    "]\n",
    "candidate_names_train = np.array([\"<johnny>\", \"<jonathan>\", \"<marie>\", \"<maria>\", \"<jon>\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "symmetric = True\n",
    "dataset = GloveDataset(input_names_train, weighted_actual_names_train, config.vocab_size, device=device,\n",
    "                       symmetric=symmetric)\n",
    "vocab = dataset.get_vocab()\n",
    "print(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "for ix in range(len(dataset._xij)):\n",
    "    name = dataset._id2word[int(dataset._i_idx[ix])]\n",
    "    context = dataset._id2word[int(dataset._j_idx[ix])]\n",
    "    freq = int(dataset._xij[ix])\n",
    "    print(f\"{name}/{context} {freq}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get vocab names in order by id\n",
    "vocab_names = list(name_id[0] for name_id in sorted(vocab.items(), key=lambda x: x[1]))\n",
    "print(vocab_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create vectors with tfidf values\n",
    "max_ngram = 5  # 3\n",
    "min_df = 1  # 10\n",
    "max_df = 1.0  # 0.5\n",
    "tfidf_vectorizer = TfidfVectorizer(ngram_range=(1, max_ngram), analyzer=\"char_wb\", min_df=min_df, max_df=max_df)\n",
    "tfidf_X_train = tfidf_vectorizer.fit_transform(vocab_names)\n",
    "print(tfidf_X_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embed_dim = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reduce tfidf values to embed_dim\n",
    "svd = TruncatedSVD(n_components=embed_dim)\n",
    "tfidf_X_train = svd.fit_transform(tfidf_X_train)\n",
    "tfidf_X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# create glove model\n",
    "model = GloveModel(len(vocab), embed_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# init weights to tfidf values\n",
    "model.wi.weight.data = torch.from_numpy(tfidf_X_train)\n",
    "model.wj.weight.data = torch.from_numpy(tfidf_X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.to(device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "n_epochs = 1000\n",
    "batch_size = 64\n",
    "learning_rate = 0.05\n",
    "x_max = 100\n",
    "alpha = 0.75\n",
    "loss_values = train_glove(model, dataset, n_epochs=n_epochs, batch_size=batch_size, x_max=x_max, alpha=alpha, lr=learning_rate, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "ax = plt.gca()\n",
    "ax.set_ylim([0, 0.1])\n",
    "plt.plot(loss_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "k = 10\n",
    "add_context = True\n",
    "\n",
    "all_names = np.array(input_names_train + candidate_names_train.tolist())\n",
    "all_embeddings = get_glove_embeddings(model, vocab, all_names, add_context=add_context)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "print(all_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "demo_name = '<john>'\n",
    "demo_name_pos = 0\n",
    "demo_embeddings = get_glove_embeddings(model, vocab, [demo_name], add_context=add_context)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# try cosine similarity\n",
    "# totals = all_embeddings.sum(axis=0)\n",
    "# all_embeddings_norm = all_embeddings / totals\n",
    "# demo_embeddings_norm = all_embeddings_norm[[demo_name_pos]]\n",
    "# scores = cosine_similarity(demo_embeddings_norm, all_embeddings_norm)\n",
    "# ixs = np.argsort(-scores)[:, :k]\n",
    "# sorted_scores = scores[:, ixs[0]]\n",
    "# sorted_names = all_names[ixs[0]]\n",
    "# best_matches = np.dstack((sorted_names, sorted_scores))\n",
    "# print(\"cosine_norm_0\", best_matches)\n",
    "\n",
    "# totals = demo_embeddings.sum(axis=1)\n",
    "# demo_embeddings_norm = demo_embeddings / totals[:, np.newaxis]\n",
    "# totals = all_embeddings.sum(axis=1)\n",
    "# all_embeddings_norm = all_embeddings / totals[:, np.newaxis]\n",
    "# scores = cosine_similarity(demo_embeddings_norm, all_embeddings_norm)\n",
    "# ixs = np.argsort(-scores)[:, :k]\n",
    "# sorted_scores = scores[:, ixs[0]]\n",
    "# sorted_names = all_names[ixs[0]]\n",
    "# best_matches = np.dstack((sorted_names, sorted_scores))\n",
    "# print(\"cosine_norm_1\", best_matches)\n",
    "\n",
    "scores = cosine_similarity(demo_embeddings, all_embeddings)\n",
    "ixs = np.argsort(-scores)[:, :k]\n",
    "sorted_scores = scores[:, ixs[0]]\n",
    "sorted_names = all_names[ixs[0]]\n",
    "best_matches = np.dstack((sorted_names, sorted_scores))\n",
    "print(\"cosine\", best_matches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# try euclidean similarity\n",
    "totals = all_embeddings.sum(axis=0)\n",
    "all_embeddings_norm = all_embeddings / totals\n",
    "demo_embeddings_norm = all_embeddings_norm[[demo_name_pos]]\n",
    "scores = euclidean_distances(demo_embeddings_norm, all_embeddings_norm)\n",
    "ixs = np.argsort(scores)[:, :k]\n",
    "sorted_scores = scores[:, ixs[0]]\n",
    "sorted_names = all_names[ixs[0]]\n",
    "best_matches = np.dstack((sorted_names, sorted_scores))\n",
    "print(\"euclidean_norm_0\", best_matches)\n",
    "\n",
    "# totals = demo_embeddings.sum(axis=1)\n",
    "# demo_embeddings_norm = demo_embeddings / totals[:, np.newaxis]\n",
    "# totals = all_embeddings.sum(axis=1)\n",
    "# all_embeddings_norm = all_embeddings / totals[:, np.newaxis]\n",
    "# scores = euclidean_distances(demo_embeddings_norm, all_embeddings_norm)\n",
    "# ixs = np.argsort(scores)[:, :k]\n",
    "# sorted_scores = scores[:, ixs[0]]\n",
    "# sorted_names = all_names[ixs[0]]\n",
    "# best_matches = np.dstack((sorted_names, sorted_scores))\n",
    "# print(\"euclidean_norm_1\", best_matches)\n",
    "\n",
    "scores = euclidean_distances(demo_embeddings, all_embeddings)\n",
    "ixs = np.argsort(scores)[:, :k]\n",
    "sorted_scores = scores[:, ixs[0]]\n",
    "sorted_names = all_names[ixs[0]]\n",
    "best_matches = np.dstack((sorted_names, sorted_scores))\n",
    "print(\"euclidean\", best_matches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# plot embeddings\n",
    "xs = list(x for x, _ in all_embeddings)\n",
    "ys = list(y for _, y in all_embeddings)\n",
    "plt.scatter(xs, ys)\n",
    "for ix, name in enumerate(all_names):\n",
    "    plt.annotate(name, xy=(xs[ix], ys[ix]), xytext=(5, 2),\n",
    "                 textcoords='offset points', ha='right', va='bottom')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nama",
   "language": "python",
   "name": "nama"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}

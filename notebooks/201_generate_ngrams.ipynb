{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31d54041",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05d44609",
   "metadata": {},
   "source": [
    "# Generate n-grams \n",
    "Find a reasonable number of n-grams using recursive feature elimination over n-grams generated using TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de08c50d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import random\n",
    "\n",
    "import joblib\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_selection import RFECV\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "from src.data.filesystem import fopen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a4feee7",
   "metadata": {},
   "outputs": [],
   "source": [
    "given_surname = \"given\"\n",
    "min_df = 2000\n",
    "ngram_range=(1,3)\n",
    "\n",
    "sample_frac = 0.05\n",
    "\n",
    "train_path = f\"s3://familysearch-names/processed/tree-hr-{given_surname}-train-v2.csv.gz\"\n",
    "triplets_path=f\"s3://familysearch-names/processed/tree-hr-{given_surname}-triplets.csv.gz\"\n",
    "tfidf_path=f\"s3://nama-data/data/models/fs-{given_surname}-tfidf-v2.joblib\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd22876a",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4490128",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(train_path, keep_default_na=False)\n",
    "print(df.shape)\n",
    "df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c553152",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_names = set(df['tree_name']) | set(df['record_name'])\n",
    "print(len(all_names))\n",
    "next(iter(all_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "908704d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read triplets\n",
    "triplets_df = pd.read_csv(triplets_path)\n",
    "print(len(triplets_df))\n",
    "triplets_df.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f08567b1",
   "metadata": {},
   "source": [
    "## Generate n-grams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43720989",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_df = 0.5\n",
    "tfidf_vectorizer = TfidfVectorizer(ngram_range=ngram_range, analyzer=\"char_wb\", min_df=min_df, max_df=max_df)\n",
    "tfidf_vectorizer.fit(all_names)\n",
    "vocab = tfidf_vectorizer.vocabulary_\n",
    "len(vocab)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6139d89f",
   "metadata": {},
   "source": [
    "## Generate training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6939559",
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_df = triplets_df[['anchor', 'positive', 'positive_score']].drop_duplicates()\n",
    "pos_df.rename(columns={'positive': 'name', 'positive_score': 'score'}, inplace=True)\n",
    "print('pos', len(pos_df))\n",
    "neg_df = triplets_df[['anchor', 'negative', 'negative_score']].drop_duplicates()\n",
    "print('raw neg', len(neg_df))\n",
    "# drop the really-easy negatives\n",
    "neg_df = neg_df[neg_df['negative_score'] > 0.03]\n",
    "print('not too easy neg', len(neg_df))\n",
    "# sample the remaining negatives so we have 50% more negatives than positives\n",
    "neg_df = neg_df.sample(int(len(pos_df) * 1.5))\n",
    "print('sampled neg', len(neg_df))\n",
    "neg_df.rename(columns={'negative': 'name', 'negative_score': 'score'}, inplace=True)\n",
    "pairs_df = pd.concat([pos_df, neg_df], ignore_index=True)\n",
    "# randomize pairs\n",
    "pairs_df = pairs_df.sample(frac=sample_frac).reset_index(drop=True)\n",
    "print('total', len(pairs_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6615e612",
   "metadata": {},
   "outputs": [],
   "source": [
    "A = []\n",
    "B = []\n",
    "y = []\n",
    "for anchor, name, score in tqdm(zip(pairs_df['anchor'], pairs_df['name'], pairs_df['score'])):\n",
    "    anchor = anchor[1:-1]\n",
    "    name = name[1:-1]\n",
    "    Xs = tfidf_vectorizer.transform([anchor, name]).todense()\n",
    "    anchor_X = Xs[0]\n",
    "    name_X = Xs[1]\n",
    "    A.append(np.squeeze(np.asarray(anchor_X)))\n",
    "    B.append(np.squeeze(np.asarray(name_X)))\n",
    "    y.append(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "188df7ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "A = np.stack(A, axis=0)\n",
    "B = np.stack(B, axis=0)\n",
    "print(A.shape)\n",
    "print(B.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1eec7cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "norm = np.sqrt(np.multiply(np.sum(A*A, axis=1), np.sum(B*B, axis=1)))\n",
    "X = np.multiply(A, B) / norm[..., np.newaxis]\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d54a845",
   "metadata": {},
   "source": [
    "## Test linear regression on all ngrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28ab81db",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = LinearRegression().fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f44e27a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.intercept_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e9bd048",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d59077b",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.score(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83cfb668",
   "metadata": {},
   "source": [
    "### Predict a single pair"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b6e2f11",
   "metadata": {},
   "outputs": [],
   "source": [
    "pairs_df.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78ff2407",
   "metadata": {},
   "outputs": [],
   "source": [
    "anchor = 'aage'\n",
    "name = 'age'\n",
    "Xs = tfidf_vectorizer.transform([anchor, name]).todense()\n",
    "anchor_X = Xs[0]\n",
    "name_X = Xs[1]\n",
    "norm = max(0.00001, math.sqrt(np.square(anchor_X).sum() * np.square(name_X).sum()))\n",
    "x = np.multiply(anchor_X, name_X) / norm\n",
    "clf.predict(np.asarray(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5d928c4",
   "metadata": {},
   "source": [
    "### Cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b11aff46",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = LinearRegression()\n",
    "scores = cross_val_score(clf, X, y, scoring='r2', cv=5)\n",
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aaa0d139",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"%0.2f accuracy with a standard deviation of %0.2f\" % (scores.mean(), scores.std()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcc836f7",
   "metadata": {},
   "source": [
    "#### Given names\n",
    "min doc freq 1000, (1,3) => mean -1e20, std dev 2e20\n",
    "\n",
    "min doc freq 1200, (1,3) => mean -5e19, std dev 1e20\n",
    "\n",
    "min doc freq 1500, (1,3) => mean -2e18, std dev 1e19\n",
    "\n",
    "min doc freq 2000, (1,3) => mean 0.25, std dev 0.01\n",
    "\n",
    "min doc freq 3000, (1,3) => mean 0.24, std dev 0.01\n",
    "\n",
    "min doc freq 1200, (1,2) => mean 1e-20, std dev 1e20\n",
    "\n",
    "min doc freq 1500, (1,2) => mean 0.20, std dev 0.01\n",
    "\n",
    "min doc freq 2000, (1,2) => mean 0.21, std dev 0.01\n",
    "\n",
    "min doc freq 3000, (1,2) => mean 0.21, std dev 0.01"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0321d1f8",
   "metadata": {},
   "source": [
    "## Recursive Feature Elimination"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7eadf59f",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_features = A.shape[1]\n",
    "support = [True] * n_features\n",
    "ranking = [1] * n_features\n",
    "all_scores = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e32616a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove features a few at a time so we can re-normalize after removing features\n",
    "min_features = 1\n",
    "step_size = -10\n",
    "for nf in tqdm(range(n_features+step_size, min_features, step_size)):\n",
    "    # filter A and B to have only selected features\n",
    "    A_filtered = A[:, support]\n",
    "    B_filtered = B[:, support]\n",
    "    # compute X = (A * B) / sqrt(sum(A^2)*sum(B^2))\n",
    "    norm = np.sqrt(np.multiply(np.sum(A_filtered*A_filtered, axis=1), \\\n",
    "                               np.sum(B_filtered*B_filtered, axis=1)))\n",
    "    X = np.multiply(A_filtered, B_filtered) / norm[..., np.newaxis]\n",
    "    \n",
    "    # remove one feature\n",
    "    clf = LinearRegression()\n",
    "    selector = RFECV(clf, min_features_to_select=nf, scoring='r2', cv=5)\n",
    "    selector = selector.fit(X, y)\n",
    "    # which feature did you remove in the original feature space?\n",
    "    new_support = list(selector.support_)\n",
    "    new_support_ix = 0\n",
    "    found = False\n",
    "    for support_ix in range(n_features):\n",
    "        if not support[support_ix]:\n",
    "            continue\n",
    "        if not new_support[new_support_ix]:\n",
    "            ranking[support_ix] = A_filtered.shape[1]\n",
    "            support[support_ix] = False\n",
    "            found = True\n",
    "        new_support_ix += 1\n",
    "    # stop early?\n",
    "    if not found:\n",
    "        break\n",
    "    # calculate CV scores\n",
    "    clf = LinearRegression()\n",
    "    scores = cross_val_score(clf, X[:, selector.support_], y, scoring='r2', cv=5)\n",
    "    print(f\"mean={scores.mean()}, std dev={scores.std()}\")\n",
    "    for score in scores:\n",
    "        all_scores.append((nf, score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f411484",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(*zip(*all_scores))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1a42783",
   "metadata": {},
   "source": [
    "### Cross-validate results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc642928",
   "metadata": {},
   "outputs": [],
   "source": [
    "A_filtered = A[:, support]\n",
    "B_filtered = B[:, support]\n",
    "# compute X = (A * B) / sqrt(sum(A^2)*sum(B^2))\n",
    "norm = np.sqrt(np.multiply(np.sum(A_filtered*A_filtered, axis=1), \\\n",
    "                           np.sum(B_filtered*B_filtered, axis=1)))\n",
    "X = np.multiply(A_filtered, B_filtered) / norm[..., np.newaxis]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6262b215",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = LinearRegression()\n",
    "scores = cross_val_score(clf, X, y, scoring='r2', cv=5)\n",
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aab02803",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"%0.2f accuracy with a standard deviation of %0.2f\" % (scores.mean(), scores.std()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "342e37c2",
   "metadata": {},
   "source": [
    "## Review results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65efe6b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "norm = np.sqrt(np.multiply(np.sum(A*A, axis=1), \\\n",
    "                           np.sum(B*B, axis=1)))\n",
    "X = np.multiply(A, B) / norm[..., np.newaxis]\n",
    "\n",
    "norm_filtered = np.sqrt(np.multiply(np.sum(A_filtered*A_filtered, axis=1), \\\n",
    "                                    np.sum(B_filtered*B_filtered, axis=1)))\n",
    "X_filtered = np.multiply(A_filtered, B_filtered) / norm_filtered[..., np.newaxis]\n",
    "\n",
    "clf = LinearRegression().fit(X, y)\n",
    "clf_filtered = LinearRegression().fit(X_filtered, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49a95165",
   "metadata": {},
   "outputs": [],
   "source": [
    "for ix, (anchor, name, score) in enumerate(zip(pairs_df['anchor'], pairs_df['name'], pairs_df['score'])):\n",
    "    if ix > 100:\n",
    "        break\n",
    "    anchor = anchor[1:-1]\n",
    "    name = name[1:-1]\n",
    "    Xs = tfidf_vectorizer.transform([anchor, name]).todense()\n",
    "    anchor_X = Xs[0]\n",
    "    name_X = Xs[1]\n",
    "    norm = math.sqrt(np.square(anchor_X).sum() * np.square(name_X).sum())\n",
    "    x = np.multiply(anchor_X, name_X) / norm\n",
    "    predict = clf.predict(np.asarray(x))[0]\n",
    "\n",
    "    Xs_filtered = Xs[:, support]\n",
    "    anchor_X_filtered = Xs_filtered[0]\n",
    "    name_X_filtered = Xs_filtered[1]\n",
    "    norm_filtered = math.sqrt(np.square(anchor_X_filtered).sum() * np.square(name_X_filtered).sum())\n",
    "    x_filtered = np.multiply(anchor_X_filtered, name_X_filtered) / norm_filtered\n",
    "    predict_filtered = clf_filtered.predict(np.asarray(x_filtered))[0]\n",
    "    \n",
    "    print(f\"{anchor} {name} {score} {predict} {predict_filtered}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d206cfe7",
   "metadata": {},
   "source": [
    "## Save TfidfVectorizer\n",
    "don't filter n-grams - there's no benefit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7302f01f",
   "metadata": {},
   "outputs": [],
   "source": [
    "joblib.dump(tfidf_vectorizer, fopen(tfidf_path, mode='wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0fc979b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nama",
   "language": "python",
   "name": "nama"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

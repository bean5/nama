{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6b1d8c64",
   "metadata": {},
   "source": [
    "# Train a TfidfVectorizer to filter names sent to levenshtein\n",
    "Levenshtein is slow, so we want to use TfidfVectorizer to filter the number of candidates we pass into levenshtein. Try different hyperparameters to see which yields the best results.\n",
    "\n",
    "Save the best TfidfVectorizer model so we can re-use it later\n",
    "\n",
    "In addition, implement our own TfidfVectorizer (transform only) so we can port it to other languages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c63679db",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29a1d9ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import namedtuple\n",
    "import math\n",
    "\n",
    "import jellyfish\n",
    "import joblib\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.pyplot import cm\n",
    "from mpire import WorkerPool\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils.extmath import safe_sparse_dot\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "import wandb\n",
    "\n",
    "from src.data.filesystem import fopen\n",
    "from src.data.utils import load_dataset, select_frequent_k, frequent_k_names\n",
    "from src.eval import metrics\n",
    "from src.eval.utils import similars_to_ndarray\n",
    "from src.models.ensemble import get_best_ensemble_matches\n",
    "from src.models.swivel import SwivelModel, get_best_swivel_matches\n",
    "from src.models.swivel_encoder import SwivelEncoderModel\n",
    "from src.models.utils import remove_padding, add_padding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e770235",
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "# config\n",
    "\n",
    "given_surname = \"surname\"\n",
    "vocab_size = 610000 if given_surname == \"given\" else 2100000\n",
    "sample_size = 1000\n",
    "num_matches = 5000\n",
    "batch_size = 32 # 256\n",
    "\n",
    "Config = namedtuple(\"Config\", [\n",
    "    \"train_path\",\n",
    "    \"test_path\",\n",
    "    \"tfidf_path\",\n",
    "])\n",
    "config = Config(\n",
    "    train_path=f\"s3://familysearch-names/processed/tree-hr-{given_surname}-train-augmented.csv.gz\",\n",
    "    test_path=f\"s3://familysearch-names/processed/tree-hr-{given_surname}-test.csv.gz\",\n",
    "    tfidf_path=f\"s3://nama-data/data/models/fs-{given_surname}-tfidf.joblib\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b482fe7e",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "wandb.init(\n",
    "    project=\"nama\",\n",
    "    entity=\"nama\",\n",
    "    name=\"65_tfidf\",\n",
    "    group=given_surname,\n",
    "    notes=\"\",\n",
    "    config=config._asdict(),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c2da8b6",
   "metadata": {},
   "source": [
    "### Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75c95ea6",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)\n",
    "print(\"cuda total\", torch.cuda.get_device_properties(0).total_memory)\n",
    "print(\"cuda reserved\", torch.cuda.memory_reserved(0))\n",
    "print(\"cuda allocated\", torch.cuda.memory_allocated(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d80efe1",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_names_train, weighted_actual_names_train, candidate_names_train = load_dataset(config.train_path, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73bd600c",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_names_test, weighted_actual_names_test, candidate_names_test = load_dataset(config.test_path, is_eval=True, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03a03eec",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# sample names (train, eval, and freq_eval for in-vocab and test for out-of-vocab)\n",
    "_, input_names_train_sample, _, weighted_actual_names_train_sample = \\\n",
    "    train_test_split(input_names_train, weighted_actual_names_train, test_size=sample_size)\n",
    "candidate_names_train_sample = candidate_names_train\n",
    "\n",
    "_, input_names_test_sample, _, weighted_actual_names_test_sample = \\\n",
    "    train_test_split(input_names_test, weighted_actual_names_test, test_size=sample_size)\n",
    "candidate_names_test_sample = candidate_names_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bb22f7d",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "print(\"input_names_train_sample\", len(input_names_train_sample))\n",
    "print(\"weighted_actual_names_train_sample\", len(weighted_actual_names_train_sample))\n",
    "print(\"candidate_names_train_sample\", len(candidate_names_train_sample))\n",
    "\n",
    "print(\"input_names_test_sample\", len(input_names_test_sample))\n",
    "print(\"weighted_actual_names_test_sample\", len(weighted_actual_names_test_sample))\n",
    "print(\"candidate_names_test_sample\", len(candidate_names_test_sample))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60ca74b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# free memory\n",
    "del input_names_train\n",
    "del weighted_actual_names_train\n",
    "del input_names_test\n",
    "del weighted_actual_names_test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a537fdf5",
   "metadata": {},
   "source": [
    "### Set up tfidf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "397ed0be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tfidf\n",
    "tfidf_vectorizer = TfidfVectorizer(ngram_range=(1, 2), analyzer=\"char_wb\", min_df=40000, max_df=0.5)\n",
    "tfidf_X_train_sample = tfidf_vectorizer.fit_transform(candidate_names_train_sample)\n",
    "tfidf_X_test_sample = tfidf_vectorizer.transform(candidate_names_test_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "600bbc8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_X_test_sample.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4adfaef4",
   "metadata": {},
   "outputs": [],
   "source": [
    "candidate_names_test_sample[0:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d40a37df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# (1,3), 10, 0.5 => 8936\n",
    "# (1,3), 100, 0.5 => 4744\n",
    "# (1,3), 1000, 0.5 => 1428\n",
    "# (1,3), 10000, 0.5 => 221\n",
    "# (1,3), 15000, 0.5 => 160 not as good as bigrams\n",
    "# (1,2), 10, 0.5 => 700\n",
    "# (1,2), 100, 0.5 => 592\n",
    "# (1,2), 1000, 0.5 => 406\n",
    "# (1,2), 5000, 0.5 => 233 @ threshold=0.4: 30sec, .4193auc\n",
    "# (1,2), 10000, 0.5 => 160 @ threshold=0.45 28sec .4188auc\n",
    "# (1,2), 20000, 0.5 => 97 @ threshold=0.55 21sec  .4167auc threshold=0.5 29sec  .4180auc\n",
    "# (1,2), 40000, 0.5 => 46 @ threshold=0.65 20sec  .411auc  threshold=0.6 30sec  .415auc\n",
    "# ^^^ winner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c8e1270",
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_vectorizer.vocabulary_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "090c7586",
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_vectorizer.idf_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90f396d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "test = [\"<a<c<a\"]\n",
    "tfidf_vectorizer.transform(test).todense()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca25755d",
   "metadata": {},
   "source": [
    "### Simple (but slow) Tfidf transformer implementation that is portable to other languages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67e06224",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyTfidfVectorizer:\n",
    "    def __init__(self, vocab, idf, ngram_range=None):\n",
    "        self.vocab = vocab\n",
    "        self.idf = idf\n",
    "        self.ngram_range = (1,2) if ngram_range is None else ngram_range\n",
    "        \n",
    "    def transform(self, word):\n",
    "        # get counts\n",
    "        result = np.zeros(len(self.vocab))\n",
    "        for ngram_len in self.ngram_range:\n",
    "            for pos in range(len(word)-ngram_len+1):\n",
    "                tok = word[pos:pos+ngram_len]\n",
    "                ix = self.vocab.get(tok, -1)\n",
    "                if ix >= 0:\n",
    "                    result[ix] += 1\n",
    "        # multiply counts by idf\n",
    "        sum_squares = 0.0\n",
    "        for ix in range(len(self.vocab)):\n",
    "            tf_idf = result[ix] * self.idf[ix]\n",
    "            result[ix] = tf_idf\n",
    "            sum_squares += tf_idf * tf_idf\n",
    "        # divide by l2 norm\n",
    "        norm = math.sqrt(sum_squares)\n",
    "        if norm > 0.0:\n",
    "            for ix in range(len(self.vocab)):\n",
    "                result[ix] /= norm\n",
    "            \n",
    "        return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae55199c",
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf = MyTfidfVectorizer(tfidf_vectorizer.vocabulary_, tfidf_vectorizer.idf_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11bd1525",
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf.transform(\"<a<c<a\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df7dc78d",
   "metadata": {},
   "source": [
    "### Levenshtein similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d73426c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_lev_similarity_to(name):\n",
    "    name = remove_padding(name)\n",
    "\n",
    "    def calc_similarity(row):\n",
    "        cand_name = remove_padding(row[0])\n",
    "        dist = jellyfish.levenshtein_distance(name, cand_name)\n",
    "        return 1 - (dist / max(len(name), len(cand_name)))\n",
    "\n",
    "    return calc_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fafabff1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_similars(shared, names, _=None):\n",
    "    candidate_names_test, k, algo, tfidf_vectorizer, tfidf_X_test = shared\n",
    "    \n",
    "    def get_similars_for_name(name):\n",
    "        if algo == \"tfidf\":\n",
    "            x = tfidf_vectorizer.transform([name]).toarray()\n",
    "            scores = safe_sparse_dot(tfidf_X_test, x.T).flatten()\n",
    "        elif algo.startswith(\"tfidf+lev\"):\n",
    "            scores = np.zeros(len(candidate_names_test))\n",
    "            threshold = float(algo.split(\"_\")[1])\n",
    "            x = tfidf_vectorizer.transform([name]).toarray()\n",
    "            tfidf_scores = safe_sparse_dot(tfidf_X_test, x.T).flatten()\n",
    "            ixs = (tfidf_scores > threshold).nonzero()[0]\n",
    "            if len(ixs) > 0:\n",
    "                lev_scores = np.apply_along_axis(calc_lev_similarity_to(name),\n",
    "                                                1, candidate_names_test[ixs, None])\n",
    "                scores[ixs] = lev_scores\n",
    "        else:\n",
    "            scores = np.apply_along_axis(calc_lev_similarity_to(name), \n",
    "                                         1, candidate_names_test[:, None])\n",
    "\n",
    "        # sorted_scores_idx = np.argsort(scores)[::-1][:k]\n",
    "        partitioned_idx = np.argpartition(scores, -k)[-k:]\n",
    "        sorted_partitioned_idx = np.argsort(scores[partitioned_idx])[::-1]\n",
    "        sorted_scores_idx = partitioned_idx[sorted_partitioned_idx]\n",
    "\n",
    "        candidate_names = candidate_names_test[sorted_scores_idx]\n",
    "        candidate_scores = scores[sorted_scores_idx]\n",
    "\n",
    "        return list(zip(candidate_names, candidate_scores))\n",
    "    \n",
    "    result = []\n",
    "    for name in names:\n",
    "        result.append(get_similars_for_name(name))\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "005f105b",
   "metadata": {},
   "source": [
    "#### Create batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c380dc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_batches(names, batch_size):\n",
    "    batches = []\n",
    "    for ix in range(0, len(names), batch_size):\n",
    "        # batches are tuples to keep mpire from expanding the batch \n",
    "        batches.append((names[ix:ix + batch_size], ix))\n",
    "    return batches"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c6cf259",
   "metadata": {},
   "source": [
    "### Test levenshtein"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3a3833d",
   "metadata": {},
   "outputs": [],
   "source": [
    "probe_name = \"<bostelman>\" if given_surname == \"surname\" else \"<richard>\"\n",
    "get_similars((candidate_names_test_sample, 10, \"levenshtein\", None, None), [probe_name])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "906aa37f",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Test tfidf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa1454d8",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "probe_name = \"<bostelman>\" if given_surname == \"surname\" else \"<richard>\"\n",
    "get_similars((candidate_names_test_sample, 10, \"tfidf\", tfidf_vectorizer, tfidf_X_test_sample), [probe_name])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26ac69e3",
   "metadata": {},
   "source": [
    "### Test tfidf+lev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b6d92c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "probe_name = \"<bostelman>\" if given_surname == \"surname\" else \"<richard>\"\n",
    "get_similars((candidate_names_test_sample, 10, \"tfidf+lev_0.76\", tfidf_vectorizer, tfidf_X_test_sample), [probe_name])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2af839a6",
   "metadata": {},
   "source": [
    "# Evaluate at various thresholds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97f1ce29",
   "metadata": {},
   "outputs": [],
   "source": [
    "SimilarityAlgo = namedtuple(\"SimilarityAlgo\", \"name min_threshold max_threshold distances\")\n",
    "similarity_algos = [\n",
    "    SimilarityAlgo(\"tfidf+lev_0.7\", 0.0, 1.01, False),\n",
    "    SimilarityAlgo(\"tfidf+lev_0.65\", 0.0, 1.01, False),\n",
    "    SimilarityAlgo(\"tfidf+lev_0.6\", 0.0, 1.01, False),\n",
    "#     SimilarityAlgo(\"levenshtein\", 0.0, 1.01, False),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c94f343",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def evaluate_algos(similarity_algos, \n",
    "                   input_names, \n",
    "                   weighted_actual_names, \n",
    "                   candidate_names, \n",
    "                   tfidf_X):\n",
    "    n_jobs = 1\n",
    "\n",
    "    figure, ax = plt.subplots(1, 1, figsize=(20, 15))\n",
    "    ax.set_title(\"PR at threshold\")\n",
    "    colors = cm.rainbow(np.linspace(0, 1, len(similarity_algos)))\n",
    "\n",
    "    for algo, color in zip(similarity_algos, colors):\n",
    "        print(algo.name)\n",
    "        input_names_batches = create_batches(input_names, batch_size=batch_size)\n",
    "        if n_jobs == 1:\n",
    "            similar_names_scores = []\n",
    "            for input_names_batch, _ in tqdm(input_names_batches):\n",
    "                similar_names_scores.append(\n",
    "                    get_similars((candidate_names, num_matches, algo.name, tfidf_vectorizer, tfidf_X),\n",
    "                                 input_names_batch))\n",
    "        else:\n",
    "            with WorkerPool(\n",
    "                shared_objects=(candidate_names, num_matches, algo.name, tfidf_vectorizer, tfidf_X),\n",
    "                n_jobs=n_jobs,\n",
    "            ) as pool:\n",
    "                similar_names_scores = pool.map(get_similars, input_names_batches, progress_bar=True)\n",
    "        input_names_batches = None\n",
    "        # flatten\n",
    "        similar_names_scores = [name_score for batch in similar_names_scores for name_score in batch]\n",
    "        # convert to ndarray\n",
    "        similar_names_scores = similars_to_ndarray(similar_names_scores)\n",
    "        print(\"calculating precision and recall\")\n",
    "        precisions, recalls = metrics.precision_weighted_recall_at_threshold(\n",
    "            weighted_actual_names,\n",
    "            similar_names_scores,\n",
    "            min_threshold=algo.min_threshold,\n",
    "            max_threshold=algo.max_threshold,\n",
    "            step=0.01,\n",
    "            distances=algo.distances,\n",
    "            n_jobs=1,\n",
    "            progress_bar=True,\n",
    "        )\n",
    "        similar_names_scores = None\n",
    "        print(\"auc\", metrics.get_auc_from_precisions_recalls(\n",
    "            precisions, \n",
    "            recalls, \n",
    "            distances=algo.distances\n",
    "        ))\n",
    "        ax.plot(recalls, precisions, \"o--\", color=color, label=algo.name)\n",
    "\n",
    "    ax.legend()\n",
    "    plt.xlim([0, 1.0])\n",
    "    plt.ylim([0, 1.0])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71a8129c",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## on out-of-vocabulary names (test data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf095c64",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "evaluate_algos(similarity_algos, \n",
    "               input_names_test_sample, \n",
    "               weighted_actual_names_test_sample, \n",
    "               candidate_names_test_sample, \n",
    "               tfidf_X_test_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "296d1484",
   "metadata": {},
   "outputs": [],
   "source": [
    "joblib.dump(tfidf_vectorizer, fopen(config.tfidf_path, mode='wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55c8722a",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43cdb30d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nama",
   "language": "python",
   "name": "nama"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

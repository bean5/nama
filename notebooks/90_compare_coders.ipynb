{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8262d44",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2c205f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import namedtuple\n",
    "import cologne_phonetics\n",
    "import jellyfish\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.pyplot import cm\n",
    "from metaphone import doublemetaphone\n",
    "from mpire import WorkerPool\n",
    "import numpy as np\n",
    "from pyphonetics import RefinedSoundex\n",
    "from spellwise import CaverphoneOne, CaverphoneTwo\n",
    "from tqdm import tqdm\n",
    "import wandb\n",
    "\n",
    "from src.data.utils import load_train_test\n",
    "from src.eval import metrics\n",
    "from src.models.utils import remove_padding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56a0fe18",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# config\n",
    "\n",
    "# from src.data.ancestry import load_train_test\n",
    "# train_path = \"../data/raw/records25k_data_train.csv\"\n",
    "# test_path = \"../data/raw/records25k_data_test.csv\"\n",
    "# sample_all_names = True\n",
    "\n",
    "given_surname = \"given\"\n",
    "Config = namedtuple(\"Config\", \"train_path test_path triplet_model_path sample_all_names\")\n",
    "config = Config(\n",
    "    train_path=f\"s3://familysearch-names/processed/tree-hr-{given_surname}-similar-train.csv.gz\",\n",
    "    test_path=f\"s3://familysearch-names/processed/tree-hr-{given_surname}-similar-train-freq.csv.gz\",\n",
    "    # test_path=f\"s3://familysearch-names/processed/tree-hr-{given_surname}-similar-test-freq.csv.gz\",\n",
    "    triplet_model_path=f\"s3://nama-data/data/models/anc-triplet-bilstm-100-512-40-05.pth\",\n",
    "    sample_all_names=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa465334",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.set_printoptions(suppress=True)\n",
    "tqdm.pandas()\n",
    "wandb.init(\n",
    "    project=\"nama\",\n",
    "    entity=\"nama\",\n",
    "    name=\"90_compare_coders\",\n",
    "    group=given_surname,\n",
    "    notes=\"fs in-vocab\",\n",
    "    config=config._asdict(),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7498122",
   "metadata": {},
   "source": [
    "### Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36556f13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read data\n",
    "\n",
    "train, test = load_train_test([config.train_path, config.test_path])\n",
    "\n",
    "input_names_train, weighted_actual_names_train, candidate_names_train = train\n",
    "input_names_test, weighted_actual_names_test, candidate_names_test = test\n",
    "\n",
    "candidate_names_all = np.concatenate((candidate_names_train, candidate_names_test))\n",
    "input_names_all = input_names_train + input_names_test\n",
    "weighted_actual_names_all = weighted_actual_names_train + weighted_actual_names_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0bd1bd2",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# sample\n",
    "\n",
    "input_names_sample = input_names_all if config.sample_all_names else input_names_test\n",
    "weighted_actual_names_sample = weighted_actual_names_all if config.sample_all_names else weighted_actual_names_test\n",
    "candidate_names_sample = candidate_names_all if config.sample_all_names else candidate_names_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d18d88c",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "print(\"input_names_train\", len(input_names_train))\n",
    "print(\"input_names_test\", len(input_names_test))\n",
    "print(\"input_names_all\", len(input_names_all))\n",
    "print(\"input_names_sample\", len(input_names_sample))\n",
    "print(\"weighted_actual_names_train\", len(weighted_actual_names_train))\n",
    "print(\"weighted_actual_names_test\", len(weighted_actual_names_test))\n",
    "print(\"weighted_actual_names_all\", len(weighted_actual_names_all))\n",
    "print(\"weighted_actual_names_sample\", len(weighted_actual_names_sample))\n",
    "print(\"candidate_names_train\", len(candidate_names_train))\n",
    "print(\"candidate_names_test\", len(candidate_names_test))\n",
    "print(\"candidate_names_all\", len(candidate_names_all))\n",
    "print(\"candidate_names_sample\", len(candidate_names_sample))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f648503",
   "metadata": {},
   "source": [
    "### Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e75073f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# various coders\n",
    "caverphone_one = CaverphoneOne()\n",
    "caverphone_two = CaverphoneTwo()\n",
    "refined_soundex = RefinedSoundex()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cebaa126",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "coding_algos = [\n",
    "    \"soundex\",\n",
    "    \"nysiis\",\n",
    "    \"metaphone\",\n",
    "    \"caverphone1\",\n",
    "    \"caverphone2\",\n",
    "    \"refined_soundex\",\n",
    "    #     \"double_metaphone\",  # bad implementation?\n",
    "    \"cologne_phonetics\",\n",
    "    \"match_rating\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a37d97b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_similarity_to(name, algo=\"levenshtein\"):\n",
    "    name = remove_padding(name)\n",
    "\n",
    "    def calc_similarity(row):\n",
    "        cand_name = remove_padding(row[0])\n",
    "        similarity = 0.0\n",
    "        if algo == \"caverphone1\":\n",
    "            similarity = 1.0 if caverphone_one._pre_process(name) == caverphone_one._pre_process(cand_name) else 0.0\n",
    "        elif algo == \"caverphone2\":\n",
    "            similarity = 1.0 if caverphone_two._pre_process(name) == caverphone_two._pre_process(cand_name) else 0.0\n",
    "        elif algo == \"refined_soundex\":\n",
    "            similarity = 1.0 if refined_soundex.phonetics(name) == refined_soundex.phonetics(cand_name) else 0.0\n",
    "        elif algo == \"double_metaphone\":\n",
    "            dm1 = doublemetaphone(name)\n",
    "            dm2 = doublemetaphone(cand_name)\n",
    "            similarity = 1.0 if any(code in dm2 for code in dm1) else 0.0\n",
    "        elif algo == \"cologne_phonetics\":\n",
    "            similarity = (\n",
    "                1.0 if cologne_phonetics.encode(name)[0][1] == cologne_phonetics.encode(cand_name)[0][1] else 0.0\n",
    "            )\n",
    "        elif algo == \"match_rating\":\n",
    "            similarity = 1.0 if jellyfish.match_rating_comparison(name, cand_name) else 0.0\n",
    "        elif algo == \"soundex\":\n",
    "            similarity = 1.0 if jellyfish.soundex(name) == jellyfish.soundex(cand_name) else 0.0\n",
    "        elif algo == \"nysiis\":\n",
    "            similarity = 1.0 if jellyfish.nysiis(name) == jellyfish.nysiis(cand_name) else 0.0\n",
    "        elif algo == \"metaphone\":\n",
    "            similarity = 1.0 if jellyfish.metaphone(name) == jellyfish.metaphone(cand_name) else 0.0\n",
    "        return similarity\n",
    "\n",
    "    return calc_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b979895",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test double metaphone\n",
    "name = \"smith\"\n",
    "cand_name = \"schmidt\"\n",
    "dm1 = doublemetaphone(name)\n",
    "dm2 = doublemetaphone(cand_name)\n",
    "similarity = 1.0 if any(code in dm2 for code in dm1) else 0.0\n",
    "print(\"dm1\", dm1)\n",
    "print(\"dm2\", dm2)\n",
    "print(\"similarity\", similarity)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfb90820",
   "metadata": {},
   "source": [
    "#### Similarity Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fb8560e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_similars(shared, name=\"\"):\n",
    "    candidate_names_sample, k, algo = shared\n",
    "    scores = np.apply_along_axis(calc_similarity_to(name, algo), 1, candidate_names_sample[:, None])\n",
    "    sorted_scores_idx = np.argsort(scores)[::-1][:k]\n",
    "    candidate_names = candidate_names_sample[sorted_scores_idx]\n",
    "    candidate_scores = scores[sorted_scores_idx]\n",
    "\n",
    "    return list(zip(candidate_names, candidate_scores))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c4a88fe",
   "metadata": {},
   "source": [
    "#### Demo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "273a1732",
   "metadata": {},
   "source": [
    "## Test Soundex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "588ac7a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "k = 1000  # Number of candidates to consider\n",
    "\n",
    "ix = 251\n",
    "probe_name = input_names_test[ix]\n",
    "print(probe_name)\n",
    "similar_names_scores = [get_similars((candidate_names_sample, k, \"soundex\"), probe_name)]\n",
    "similar_names_scores[0][:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55434f0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ugh - how can I create a 3D array with (str, float) as the third axis without taking apart and re-assembling the array?\n",
    "# names is a 2D array [names, name of k similar-names]\n",
    "names = np.array(list(list(cell[0] for cell in row) for row in similar_names_scores), dtype=\"O\")\n",
    "# scores is a 2D array [names, score of k similar-names]\n",
    "scores = np.array(list(list(cell[1] for cell in row) for row in similar_names_scores), dtype=\"f8\")\n",
    "# similar_names_scores is now a 3D array [names, k similar-names, name or score]\n",
    "similar_names_scores = np.dstack((names, scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa234173",
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics.weighted_recall_at_threshold(weighted_actual_names_test[ix], similar_names_scores[0], 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "504ce44e",
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics.precision_at_threshold(weighted_actual_names_test[ix], similar_names_scores[0], 0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37e1f414",
   "metadata": {},
   "source": [
    "# Evaluate each algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69b25ead",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "k = 5000  # Number of candidates to consider\n",
    "extra_algos = 0\n",
    "actual_names_sample = [[name for name, _, _ in name_weights] for name_weights in weighted_actual_names_sample]\n",
    "figure, ax = plt.subplots(1, 1, figsize=(20, 15))\n",
    "ax.set_title(\"PR at threshold\")\n",
    "colors = cm.rainbow(np.linspace(0, 1, len(coding_algos) + extra_algos))\n",
    "\n",
    "# plot anc-triplet-bilstm-100-512-40-05 model\n",
    "# ax.plot([.809], [.664], \"o--\", color=colors[0], label=\"triplet-cluster\")\n",
    "# ax.plot([.594], [.543], \"o--\", color=colors[1], label=\"dam-lev-cluster\")\n",
    "\n",
    "for algo, color in zip(coding_algos, colors[extra_algos:]):\n",
    "    print(algo)\n",
    "    with WorkerPool(shared_objects=(candidate_names_sample, k, algo)) as pool:\n",
    "        similar_names_scores = pool.map(get_similars, input_names_sample, progress_bar=True)\n",
    "    similar_names = [[name for name, _ in name_similarities] for name_similarities in similar_names_scores]\n",
    "    names = np.array(list(list(cell[0] for cell in row) for row in similar_names_scores), dtype=\"O\")\n",
    "    scores = np.array(list(list(cell[1] for cell in row) for row in similar_names_scores), dtype=\"f8\")\n",
    "    total = max(scores.sum(axis=1))\n",
    "    print(\"max sum of scores\", total)\n",
    "    if total == k:\n",
    "        print(\"WARNING!!! need to increase k!!!\")\n",
    "    similar_names_scores = np.dstack((names, scores))\n",
    "    precision = metrics.avg_precision_at_threshold(weighted_actual_names_sample, similar_names_scores, 0.5)\n",
    "    recall = metrics.avg_weighted_recall_at_threshold(weighted_actual_names_sample, similar_names_scores, 0.5)\n",
    "    print(f\"precision={precision} recall={recall}\")\n",
    "    precisions = [precision]\n",
    "    recalls = [recall]\n",
    "    ax.plot(recalls, precisions, \"o--\", color=color, label=algo)\n",
    "\n",
    "ax.legend()\n",
    "plt.xlim([0, 1.0])\n",
    "plt.ylim([0, 1.0])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed367dde",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "wandb.finish()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nama",
   "language": "python",
   "name": "nama"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

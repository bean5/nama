{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from collections import namedtuple\n",
    "from datetime import datetime\n",
    "\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "import wandb\n",
    "\n",
    "from src.data.filesystem import fopen\n",
    "from src.data.utils import load_datasets, select_frequent_k\n",
    "from src.eval import metrics\n",
    "from src.models.swivel import SwivelDataset, SwivelModel, train_swivel, get_best_swivel_matches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Config\n",
    "\n",
    "given_surname = \"given\"\n",
    "vocab_size = 600000 if given_surname == \"given\" else 2100000\n",
    "vocab_size = 200000   # partial\n",
    "embed_dim = 200\n",
    "n_epochs = 50\n",
    "Config = namedtuple(\"Config\", \"train_path vocab_size embed_dim confidence_base confidence_scale confidence_exponent n_epochs submatrix_size lr vocab_path model_path\")\n",
    "config = Config(\n",
    "    train_path=f\"s3://familysearch-names/processed/tree-hr-{given_surname}-train.csv.gz\",\n",
    "    vocab_size=vocab_size,\n",
    "    embed_dim=embed_dim,\n",
    "    confidence_base=0.18,    # 0.14 for surnames\n",
    "    confidence_scale=0.5,    # 0.45 for surnames\n",
    "    confidence_exponent=0.3, # 0.3 for surnames\n",
    "    lr = 0.14,               # 0.24 for surnames\n",
    "    n_epochs = n_epochs,\n",
    "    submatrix_size = 4096,   # 4096 for surnames (to speed things up)\n",
    "    vocab_path=f\"s3://nama-data/data/models/fs-{given_surname}-swivel-vocab-{vocab_size}.csv\",\n",
    "    model_path=f\"s3://nama-data/data/models/fs-{given_surname}-swivel-model-{vocab_size}-{embed_dim}.pth\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()\n",
    "print(torch.cuda.is_available())\n",
    "print(\"cuda total\", torch.cuda.get_device_properties(0).total_memory)\n",
    "print(\"cuda reserved\", torch.cuda.memory_reserved(0))\n",
    "print(\"cuda allocated\", torch.cuda.memory_allocated(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "wandb.init(\n",
    "    project=\"nama\",\n",
    "    entity=\"nama\",\n",
    "    name=\"61_swivel\",\n",
    "    group=given_surname,\n",
    "    notes=\"\",\n",
    "    config=config._asdict()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "[train] = load_datasets([config.train_path])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "input_names_train, weighted_actual_names_train, candidate_names_train = train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# keep only the most-frequent vocab_size names\n",
    "input_names_train, weighted_actual_names_train, candidate_names_train = \\\n",
    "    select_frequent_k(input_names_train, \n",
    "                      weighted_actual_names_train, \n",
    "                      candidate_names_train,\n",
    "                      config.vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"input_names_train\", len(input_names_train))\n",
    "print(\"weighted_actual_names_train\", sum(len(wan) for wan in weighted_actual_names_train))\n",
    "print(\"candidate_names_train\", len(candidate_names_train))\n",
    "print(\"total names\", len(set(input_names_train).union(set(candidate_names_train))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "dataset = SwivelDataset(input_names_train, weighted_actual_names_train, config.vocab_size, symmetric=True)\n",
    "vocab = dataset.get_vocab()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get vocab names in order by id\n",
    "vocab_names = list(name_id[0] for name_id in sorted(vocab.items(), key=lambda x: x[1]))\n",
    "print(len(vocab_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SwivelModel(len(vocab), config.embed_dim, config.confidence_base, config.confidence_scale, config.confidence_exponent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# init weights\n",
    "model.init_params(dataset.get_row_sums(), dataset.get_col_sums())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Save vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_df = pd.DataFrame(vocab.items(), columns=[\"name\", \"index\"])\n",
    "vocab_df.to_csv(fopen(config.vocab_path, \"wb\"), index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "n_steps_per_epoch = 0\n",
    "\n",
    "model.to(device)\n",
    "optimizer = optim.Adagrad(model.parameters(), lr=config.lr)\n",
    "\n",
    "all_loss_values = []\n",
    "for e in tqdm(range(0, config.n_epochs)):\n",
    "    print(\"Epoch\", e, datetime.now())\n",
    "    loss_values = train_swivel(model, dataset, n_steps=n_steps_per_epoch, \n",
    "                     submatrix_size=config.submatrix_size, \n",
    "                     lr=config.lr, device=device, optimizer=optimizer)\n",
    "    all_loss_values.extend(loss_values)\n",
    "    torch.save(model.state_dict(), fopen(f\"{config.model_path}.{e}\", \"wb\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Save model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), fopen(config.model_path, \"wb\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Reload model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "vocab_df = pd.read_csv(fopen(config.vocab_path, \"rb\"))\n",
    "vocab = {name: _id for name, _id in zip(vocab_df[\"name\"], vocab_df[\"index\"])}\n",
    "model = SwivelModel(len(vocab), config.embed_dim)\n",
    "model.load_state_dict(torch.load(fopen(config.model_path, \"rb\")))\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "ax = plt.gca()\n",
    "ax.set_ylim([0, 1.0])\n",
    "plt.plot(all_loss_values[::1000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# make sure all the names are in the model\n",
    "for name in input_names_train:\n",
    "    if name not in vocab.keys():\n",
    "        print(\"name missing\", name)\n",
    "        break\n",
    "for name in candidate_names_train:\n",
    "    if name not in vocab.keys():\n",
    "        print(\"name missing\", name)\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# get best matches\n",
    "# NOTE: only considers as potential matches names in candidate_names_train, not names in input_names_train\n",
    "k = 100\n",
    "eval_batch_size = 1024\n",
    "add_context = True\n",
    "n_jobs=4\n",
    "best_matches = get_best_swivel_matches(model, vocab, input_names_train, \n",
    "                                       candidate_names_train, k, eval_batch_size, \n",
    "                                       add_context=add_context, n_jobs=n_jobs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PR Curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "metrics.precision_weighted_recall_curve_at_threshold(\n",
    "    weighted_actual_names_train, best_matches, min_threshold=0.01, max_threshold=2.0, step=0.05, distances=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics.get_auc(\n",
    "    weighted_actual_names_train, best_matches, min_threshold=0.01, max_threshold=2.0, step=0.05, distances=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from src.models.swivel import get_swivel_embeddings\n",
    "from sklearn.metrics.pairwise import cosine_similarity, euclidean_distances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# demo names\n",
    "input_names_train = [\"<john>\", \"<mary>\"]\n",
    "weighted_actual_names_train = [\n",
    "    [(\"<johnny>\", 0.2, 20), (\"<jonathan>\", 0.5, 50), (\"<jon>\", 0.3, 30)],\n",
    "    [(\"<marie>\", 0.7, 70), (\"<maria>\", 0.3, 30)],\n",
    "    # [(\"<johnny>\", 0.2, 20), (\"<jonathan>\", 0.5, 50), (\"<jon>\", 0.3, 30), (\"<mary>\", 0.0, 0.5)],\n",
    "    # [(\"<marie>\", 0.7, 70), (\"<maria>\", 0.3, 30), (\"<john>\", 0.0, 0.5)],\n",
    "    # [(\"<johnny>\", 0.2, 20), (\"<jonathan>\", 0.5, 50), (\"<jon>\", 0.3, 30), (\"<mary>\", 0.0, 1), (\"<maria>\", 0.0, 1), (\"<marie>\", 0.0, 1)],\n",
    "    # [(\"<marie>\", 0.7, 70), (\"<maria>\", 0.3, 30), (\"<john>\", 0.0, 1), (\"<johnny>\", 0.0, 1), (\"<jonathan>\", 0.0, 1), (\"<jon>\", 0.0, 1)],\n",
    "]\n",
    "candidate_names_train = np.array([\"<johnny>\", \"<jonathan>\", \"<marie>\", \"<maria>\", \"<jon>\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "symmetric = True\n",
    "dataset = SwivelDataset(input_names_train, weighted_actual_names_train, config.vocab_size, symmetric=symmetric)\n",
    "vocab = dataset.get_vocab()\n",
    "print(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "print(dataset._sparse_cooc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get vocab names in order by id\n",
    "vocab_names = list(name_id[0] for name_id in sorted(vocab.items(), key=lambda x: x[1]))\n",
    "print(vocab_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create vectors with tfidf values\n",
    "max_ngram = 5  # 3\n",
    "min_df = 1  # 10\n",
    "max_df = 1.0  # 0.5\n",
    "tfidf_vectorizer = TfidfVectorizer(ngram_range=(1, max_ngram), analyzer=\"char_wb\", min_df=min_df, max_df=max_df)\n",
    "tfidf_X_train = tfidf_vectorizer.fit_transform(vocab_names)\n",
    "print(tfidf_X_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embed_dim = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reduce tfidf values to embed_dim\n",
    "svd = TruncatedSVD(n_components=embed_dim)\n",
    "tfidf_X_train = svd.fit_transform(tfidf_X_train)\n",
    "tfidf_X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# create swivel model\n",
    "model = SwivelModel(len(vocab), embed_dim, config.confidence_base, config.confidence_scale, config.confidence_exponent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# init weights to tfidf values\n",
    "# model.init_params(dataset.get_row_sums(), dataset.get_col_sums(), tfidf_X_train)\n",
    "model.init_params(dataset.get_row_sums(), dataset.get_col_sums(), tfidf_X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# device=\"cpu\"\n",
    "n_steps = 10\n",
    "submatrix_size = 64\n",
    "learning_rate = 0.05\n",
    "loss_values = train_swivel(model, dataset, n_steps=n_steps, submatrix_size=submatrix_size, lr=learning_rate, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "ax = plt.gca()\n",
    "# ax.set_ylim([0, 0.1])\n",
    "plt.plot(loss_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "k = 10\n",
    "add_context = True\n",
    "\n",
    "all_names = np.array(input_names_train + candidate_names_train.tolist())\n",
    "all_embeddings = get_swivel_embeddings(model, vocab, all_names, add_context=add_context)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "print(all_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "demo_name = '<john>'\n",
    "demo_name_pos = 0\n",
    "demo_embeddings = get_swivel_embeddings(model, vocab, [demo_name], add_context=add_context)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# try cosine similarity\n",
    "# totals = all_embeddings.sum(axis=0)\n",
    "# all_embeddings_norm = all_embeddings / totals\n",
    "# demo_embeddings_norm = all_embeddings_norm[[demo_name_pos]]\n",
    "# scores = cosine_similarity(demo_embeddings_norm, all_embeddings_norm)\n",
    "# ixs = np.argsort(-scores)[:, :k]\n",
    "# sorted_scores = scores[:, ixs[0]]\n",
    "# sorted_names = all_names[ixs[0]]\n",
    "# best_matches = np.dstack((sorted_names, sorted_scores))\n",
    "# print(\"cosine_norm_0\", best_matches)\n",
    "\n",
    "# totals = demo_embeddings.sum(axis=1)\n",
    "# demo_embeddings_norm = demo_embeddings / totals[:, np.newaxis]\n",
    "# totals = all_embeddings.sum(axis=1)\n",
    "# all_embeddings_norm = all_embeddings / totals[:, np.newaxis]\n",
    "# scores = cosine_similarity(demo_embeddings_norm, all_embeddings_norm)\n",
    "# ixs = np.argsort(-scores)[:, :k]\n",
    "# sorted_scores = scores[:, ixs[0]]\n",
    "# sorted_names = all_names[ixs[0]]\n",
    "# best_matches = np.dstack((sorted_names, sorted_scores))\n",
    "# print(\"cosine_norm_1\", best_matches)\n",
    "\n",
    "scores = cosine_similarity(demo_embeddings, all_embeddings)\n",
    "ixs = np.argsort(-scores)[:, :k]\n",
    "sorted_scores = scores[:, ixs[0]]\n",
    "sorted_names = all_names[ixs[0]]\n",
    "best_matches = np.dstack((sorted_names, sorted_scores))\n",
    "print(\"cosine\", best_matches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# try euclidean similarity\n",
    "totals = all_embeddings.sum(axis=0)\n",
    "all_embeddings_norm = all_embeddings / totals\n",
    "demo_embeddings_norm = all_embeddings_norm[[demo_name_pos]]\n",
    "scores = euclidean_distances(demo_embeddings_norm, all_embeddings_norm)\n",
    "ixs = np.argsort(scores)[:, :k]\n",
    "sorted_scores = scores[:, ixs[0]]\n",
    "sorted_names = all_names[ixs[0]]\n",
    "best_matches = np.dstack((sorted_names, sorted_scores))\n",
    "print(\"euclidean_norm_0\", best_matches)\n",
    "\n",
    "# totals = demo_embeddings.sum(axis=1)\n",
    "# demo_embeddings_norm = demo_embeddings / totals[:, np.newaxis]\n",
    "# totals = all_embeddings.sum(axis=1)\n",
    "# all_embeddings_norm = all_embeddings / totals[:, np.newaxis]\n",
    "# scores = euclidean_distances(demo_embeddings_norm, all_embeddings_norm)\n",
    "# ixs = np.argsort(scores)[:, :k]\n",
    "# sorted_scores = scores[:, ixs[0]]\n",
    "# sorted_names = all_names[ixs[0]]\n",
    "# best_matches = np.dstack((sorted_names, sorted_scores))\n",
    "# print(\"euclidean_norm_1\", best_matches)\n",
    "\n",
    "scores = euclidean_distances(demo_embeddings, all_embeddings)\n",
    "ixs = np.argsort(scores)[:, :k]\n",
    "sorted_scores = scores[:, ixs[0]]\n",
    "sorted_names = all_names[ixs[0]]\n",
    "best_matches = np.dstack((sorted_names, sorted_scores))\n",
    "print(\"euclidean\", best_matches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# plot embeddings\n",
    "xs = list(x for x, _ in all_embeddings)\n",
    "ys = list(y for _, y in all_embeddings)\n",
    "plt.scatter(xs, ys)\n",
    "for ix, name in enumerate(all_names):\n",
    "    plt.annotate(name, xy=(xs[ix], ys[ix]), xytext=(5, 2),\n",
    "                 textcoords='offset points', ha='right', va='bottom')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nama",
   "language": "python",
   "name": "nama"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}

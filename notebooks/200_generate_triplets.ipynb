{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f03c5c95",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a85e8a5",
   "metadata": {},
   "source": [
    "# Generate tree anchor name, pos record name, neg record name triplets\n",
    "\n",
    "Use the training data generated in notebook 100 and generate (anchor, pos, pos_score, neg, neg_score) triplets.\n",
    "\n",
    "We decided to use tree_name_min_freq=1000 going forward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f1cc02e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter, defaultdict\n",
    "import random\n",
    "\n",
    "import pandas as pd\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "from src.data.utils import load_dataset_v2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd18a3ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Config\n",
    "\n",
    "given_surname = \"given\"\n",
    "\n",
    "tree_name_min_freq = 1000\n",
    "record_name_min_freq = 200\n",
    "pos_threshold = 0.5\n",
    "max_triplets_per_tree_name = 2000\n",
    "\n",
    "train_path=f\"s3://familysearch-names/processed/tree-hr-{given_surname}-train-v2.csv.gz\"\n",
    "\n",
    "triplets_path=f\"../data/processed/tree-hr-{given_surname}-triplets-v2-{tree_name_min_freq}.csv.gz\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "418249f4",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "297657ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "tree_names_train, attached_names_train, record_names_train = \\\n",
    "    load_dataset_v2(train_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbf566ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"tree_names_train\", len(tree_names_train))\n",
    "print(\"attached_names_train\", sum(len(attaches) for attaches in attached_names_train))\n",
    "print(\"total pairs\", sum(freq for attachments in attached_names_train for _, freq in attachments))\n",
    "print(\"record_names_train\", len(record_names_train))\n",
    "print(\"total names\", len(set(tree_names_train).union(set(record_names_train))))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15066e4e",
   "metadata": {},
   "source": [
    "## Generate triplets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e3819bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_tree_occurs = Counter()\n",
    "total_record_occurs = Counter()\n",
    "for tree_name, attachments in tqdm(zip(tree_names_train, attached_names_train)):\n",
    "    # attachments is a list of (record name, frequency)\n",
    "    for attachment in attachments:\n",
    "        # include frequency even if a name goes to itself, \n",
    "        # because if a name usually goes to itself, we want its vector\n",
    "        # to not be that close to another vector\n",
    "        total_tree_occurs[tree_name] += attachment[1]\n",
    "        total_record_occurs[attachment[0]] += attachment[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f24259c",
   "metadata": {},
   "outputs": [],
   "source": [
    "tree_names_train_ixs = {}\n",
    "for ix, tree_name in enumerate(tree_names_train):\n",
    "    tree_names_train_ixs[tree_name] = ix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3f3ec5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _score(tree_name, record_name):\n",
    "    tree_ix = tree_names_train_ixs[tree_name]\n",
    "    freq = 0\n",
    "    for name_freq in attached_names_train[tree_ix]:\n",
    "        if name_freq[0] == record_name:\n",
    "            freq = name_freq[1]\n",
    "            break\n",
    "    total_tree_occur = total_tree_occurs[tree_name]\n",
    "    tree_co_occur_ratio = freq / total_tree_occur\n",
    "    total_record_occur = total_record_occurs[record_name]\n",
    "    record_co_occur_ratio = freq / total_record_occur\n",
    "    return freq, tree_co_occur_ratio, record_co_occur_ratio\n",
    "\n",
    "def sample_scores(tree_name, pos, pos_score, neg, neg_score):\n",
    "    for name, score in [(pos, pos_score), (neg, neg_score)]:\n",
    "        bucket = int(score * 10)\n",
    "        if random.random() < 0.001 and len(score_buckets[bucket]) < 40:\n",
    "            freq, tree_co_occur_ratio, record_co_occur_ratio = _score(tree_name, name)\n",
    "            score_buckets[bucket].append({\n",
    "                'tree_name': tree_name, \n",
    "                'record_name': name, \n",
    "                'score': score, \n",
    "                'tree_co_occur_ratio': tree_co_occur_ratio,\n",
    "                'record_co_occur_ratio': record_co_occur_ratio,\n",
    "                'freq': freq,\n",
    "            })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "610e7711",
   "metadata": {},
   "outputs": [],
   "source": [
    "# smooth rare names, increase all scores by a multiplier\n",
    "# we want nearly every attachment to score at least 0.4\n",
    "def score(tree_name, record_name, smoothing=20, multiplier=0.38):\n",
    "    tree_ix = tree_names_train_ixs[tree_name]\n",
    "    freq = 0\n",
    "    for name_freq in attached_names_train[tree_ix]:\n",
    "        if name_freq[0] == record_name:\n",
    "            freq = name_freq[1]\n",
    "            break\n",
    "    total_tree_occur = total_tree_occurs[tree_name]\n",
    "    tree_co_occur_ratio = (freq + smoothing) / (total_tree_occur + smoothing)\n",
    "    total_record_occur = total_record_occurs[record_name]\n",
    "    record_co_occur_ratio = (freq + smoothing) / (total_record_occur + smoothing)\n",
    "    max_score = max(tree_co_occur_ratio, record_co_occur_ratio)\n",
    "    return max_score + multiplier * (1.0 - max_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6768dfe0",
   "metadata": {},
   "outputs": [],
   "source": [
    "score_buckets = defaultdict(list)\n",
    "\n",
    "total_record_candidates = 0\n",
    "total_tree_names = 0\n",
    "triplets = []\n",
    "for tree_name, attachments in tqdm(zip(tree_names_train, attached_names_train)):\n",
    "    if total_tree_occurs[tree_name] < tree_name_min_freq:\n",
    "        continue\n",
    "    record_candidates = [name_freq for name_freq in attachments \\\n",
    "                         if total_record_occurs[name_freq[0]] >= record_name_min_freq]\n",
    "    pairs = set()\n",
    "    for pos_candidate in record_candidates:\n",
    "        pos_name = pos_candidate[0]\n",
    "        if pos_name == tree_name:\n",
    "            continue\n",
    "        for neg_candidate in record_candidates:\n",
    "            neg_name = neg_candidate[0]\n",
    "            if neg_name == tree_name:\n",
    "                continue\n",
    "            if pos_name == neg_name:\n",
    "                continue\n",
    "            if f\"{pos_name},{neg_name}\" in pairs \\\n",
    "            or f\"{neg_name},{pos_name}\" in pairs:\n",
    "                continue\n",
    "            pos_score = score(tree_name, pos_name)\n",
    "            neg_score = score(tree_name, neg_name)\n",
    "            if max(pos_score, neg_score) < pos_threshold:\n",
    "                continue\n",
    "            if pos_score < neg_score:\n",
    "                pos_name, pos_score, neg_name, neg_score = neg_name, neg_score, pos_name, pos_score\n",
    "            pairs.add(f\"{pos_name},{neg_name}\")\n",
    "            triplets.append({\n",
    "                'anchor': tree_name, \n",
    "                'positive': pos_name, \n",
    "                'positive_score': pos_score, \n",
    "                'negative': neg_name, \n",
    "                'negative_score': neg_score\n",
    "            })\n",
    "            sample_scores(tree_name, pos_name, pos_score, neg_name, neg_score)\n",
    "            if len(pairs) == max_triplets_per_tree_name:\n",
    "                break\n",
    "        if len(pairs) == max_triplets_per_tree_name:\n",
    "            break\n",
    "    total_record_candidates += len(record_candidates)\n",
    "    total_tree_names += 1\n",
    "print('tree names', total_tree_names)\n",
    "print('total record candidates for all tree names', total_record_candidates)\n",
    "print('avg record candidates per tree name', total_record_candidates / total_tree_names)\n",
    "print('total triplets', len(triplets))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c844bf3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(triplets)\n",
    "df['positive_score'].hist(bins=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a5a97a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['negative_score'].hist(bins=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "782a7af9",
   "metadata": {},
   "outputs": [],
   "source": [
    "triplets[::10000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec594541",
   "metadata": {},
   "outputs": [],
   "source": [
    "bucket = 4\n",
    "pd.DataFrame(score_buckets[bucket])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c8e6cfd",
   "metadata": {},
   "source": [
    "## Save triplets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7264f212",
   "metadata": {},
   "outputs": [],
   "source": [
    "random.shuffle(triplets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b72dca35",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(triplets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1eb6caa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(triplets_path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "180c9f08",
   "metadata": {},
   "outputs": [],
   "source": [
    "anchor_pos_df = df[['anchor', 'positive']].drop_duplicates()\n",
    "len(anchor_pos_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03f0d7a1",
   "metadata": {},
   "source": [
    "## Review anchor-positive pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "633df84e",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_rows', 200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea23b0b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from phonemizer.separator import Separator\n",
    "from phonemizer.backend import EspeakBackend\n",
    "\n",
    "espeak = EspeakBackend('en-us')\n",
    "separator = Separator(phone=' ', syllable=None, word='|')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53fd7662",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(espeak.phonemize(\n",
    "    ['john'], \n",
    "    separator=separator,\n",
    "    strip=True\n",
    ")[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d7bb5a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "for anchor, positive, positive_score in \\\n",
    "        df[['anchor', 'positive', 'positive_score']].sample(100).values.tolist():\n",
    "    print(anchor, \n",
    "          positive, \n",
    "          positive_score,\n",
    "          espeak.phonemize([anchor], separator=separator, strip=True)[0],\n",
    "          espeak.phonemize([positive], separator=separator, strip=True)[0],\n",
    "         )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68a7272f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import Levenshtein"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "283659db",
   "metadata": {},
   "outputs": [],
   "source": [
    "name1 = '<abcdefxyij'\n",
    "name2 = '<abcfxyghik'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6cd1594",
   "metadata": {},
   "outputs": [],
   "source": [
    "opcodes = Levenshtein.opcodes(name1, name2)\n",
    "opcodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc22355e",
   "metadata": {},
   "outputs": [],
   "source": [
    "word_pieces = []\n",
    "for (opcode, src_start, src_end, tar_start, tar_end) in opcodes:\n",
    "    if opcode == 'equal':\n",
    "        word_pieces.append(name1[src_start:src_end])\n",
    "    elif opcode == 'delete':\n",
    "        word_pieces.append(name1[src_start:src_end])\n",
    "    elif opcode == 'insert':\n",
    "        word_pieces.append(name2[tar_start:tar_end])\n",
    "    elif opcode == 'replace':\n",
    "        word_pieces.append(name1[src_start:src_end])\n",
    "        word_pieces.append(name2[tar_start:tar_end])\n",
    "    else:\n",
    "        print('Unexpected opcode', opcode)\n",
    "word_pieces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cc90228",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Costs for the operations\n",
    "INS_COST = 1\n",
    "DEL_COST = 1\n",
    "SUB_COST = 2\n",
    "\n",
    "def find_minimum_edit_distance(source_string, target_string) :\n",
    "\n",
    "    # Create a dp matrix of dimension (source_string + 1) x (destination_matrix + 1)\n",
    "    dp = [[0] * (len(source_string) + 1) for i in range(len(target_string) + 1)]\n",
    "\n",
    "    # Initialize the required values of the matrix\n",
    "    for i in range(1, len(target_string) + 1) :\n",
    "        dp[i][0] = dp[i - 1][0] + INS_COST\n",
    "    for i in range(1, len(source_string) + 1) :\n",
    "        dp[0][i] = dp[0][i - 1] + DEL_COST\n",
    "\n",
    "    # Maintain the record of opertions done\n",
    "    # Record is one tuple. Eg : (INSERT, 'a') or (SUBSTITUTE, 'e', 'r') or (DELETE, 'j')\n",
    "    operations_performed = []\n",
    "\n",
    "    # Build the matrix following the algorithm\n",
    "    for i in range(1, len(target_string) + 1) :\n",
    "        for j in range(1, len(source_string) + 1) :\n",
    "            if source_string[j - 1] == target_string[i - 1] :\n",
    "                dp[i][j] = dp[i - 1][j - 1]\n",
    "            else :\n",
    "                dp[i][j] =  min(dp[i - 1][j] + INS_COST, \\\n",
    "                                dp[i - 1][j - 1] + SUB_COST, \\\n",
    "                                dp[i][j - 1] + DEL_COST)\n",
    "\n",
    "    # Initialization for backtracking\n",
    "    i = len(target_string)\n",
    "    j = len(source_string)\n",
    "\n",
    "    # Backtrack to record the operation performed\n",
    "    while (i != 0 and j != 0) :\n",
    "        # If the character of the source string is equal to the character of the destination string,\n",
    "        # no operation is performed\n",
    "        if target_string[i - 1] == source_string[j - 1] :\n",
    "            i -= 1\n",
    "            j -= 1\n",
    "        else :\n",
    "            # Check if the current element is derived from the upper-left diagonal element\n",
    "            if dp[i][j] == dp[i - 1][j - 1] + SUB_COST :\n",
    "                operations_performed.append(('SUBSTITUTE', source_string[j - 1], target_string[i - 1]))\n",
    "                i -= 1\n",
    "                j -= 1\n",
    "            # Check if the current element is derived from the upper element\n",
    "            elif dp[i][j] == dp[i - 1][j] + INS_COST :\n",
    "                operations_performed.append(('INSERT', target_string[i - 1]))\n",
    "                i -= 1\n",
    "            # Check if the current element is derived from the left element\n",
    "            else :\n",
    "                operations_performed.append(('DELETE', source_string[j - 1]))\n",
    "                j -= 1\n",
    "\n",
    "    # If we reach top-most row of the matrix\n",
    "    while (j != 0) :\n",
    "        operations_performed.append(('DELETE', source_string[j - 1]))\n",
    "        j -= 1\n",
    "\n",
    "    # If we reach left-most column of the matrix\n",
    "    while (i != 0) :\n",
    "        operations_performed.append(('INSERT', target_string[i - 1]))\n",
    "        i -= 1\n",
    "\n",
    "    # Reverse the list of operations performed as we have operations in reverse\n",
    "    # order because of backtracking\n",
    "    operations_performed.reverse()\n",
    "    return [dp[len(target_string)][len(source_string)], operations_performed]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f391fb1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "find_minimum_edit_distance(name1, name2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47c074fe",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nama",
   "language": "python",
   "name": "nama"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

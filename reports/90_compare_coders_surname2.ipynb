{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8262d44",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2c205f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import namedtuple\n",
    "\n",
    "import cologne_phonetics\n",
    "import jellyfish\n",
    "import joblib\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.pyplot import cm\n",
    "from metaphone import doublemetaphone\n",
    "from mpire import WorkerPool\n",
    "import numpy as np\n",
    "from pyphonetics import RefinedSoundex\n",
    "from sklearn.model_selection import train_test_split\n",
    "from spellwise import CaverphoneOne, CaverphoneTwo\n",
    "import pandas as pd\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "import wandb\n",
    "\n",
    "from src.data.filesystem import fopen\n",
    "from src.data.normalize import normalize_freq_names\n",
    "from src.data.utils import load_dataset, select_frequent_k\n",
    "from src.eval import metrics\n",
    "from src.models.utils import remove_padding\n",
    "from src.models.cluster import read_clusters, get_validation_results\n",
    "from src.models.swivel import SwivelModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56a0fe18",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# config\n",
    "\n",
    "given_surname = \"surname\"\n",
    "vocab_size = 610000 if given_surname == \"given\" else 2100000\n",
    "eval_size = 200000\n",
    "sample_size = 1000\n",
    "embed_dim = 100\n",
    "NAMA_MAX_CLUSTERS = 20\n",
    "n_jobs = 1\n",
    "verbose = True\n",
    "num_matches = 1000  # Number of candidates to consider\n",
    "\n",
    "Config = namedtuple(\"Config\", [\n",
    "    \"eval_path\",\n",
    "    \"test_path\",\n",
    "    \"freq_path\",\n",
    "    \"embed_dim\",\n",
    "    \"swivel_vocab_path\",\n",
    "    \"swivel_model_path\",\n",
    "    \"tfidf_path\",\n",
    "    \"ensemble_model_path\",\n",
    "    \"cluster_path\",\n",
    "    \"partition_path\",\n",
    "])\n",
    "config = Config(\n",
    "    eval_path=f\"s3://familysearch-names/processed/tree-hr-{given_surname}-train.csv.gz\",\n",
    "    test_path=f\"s3://familysearch-names/processed/tree-hr-{given_surname}-test.csv.gz\",\n",
    "    freq_path=f\"s3://familysearch-names/processed/tree-preferred-{given_surname}-aggr.csv.gz\",\n",
    "    embed_dim=embed_dim,\n",
    "    swivel_vocab_path=f\"s3://nama-data/data/models/fs-{given_surname}-swivel-vocab-{vocab_size}-augmented.csv\",\n",
    "    swivel_model_path=f\"s3://nama-data/data/models/fs-{given_surname}-swivel-model-{vocab_size}-{embed_dim}-augmented.pth\",\n",
    "    tfidf_path=f\"s3://nama-data/data/models/fs-{given_surname}-tfidf.joblib\",\n",
    "    ensemble_model_path=f\"s3://nama-data/data/models/fs-{given_surname}-ensemble-model-{vocab_size}-{embed_dim}-augmented-100.joblib\",    \n",
    "    cluster_path=f\"s3://nama-data/data/models/fs-{given_surname}-cluster-names.csv\",\n",
    "    partition_path=f\"s3://nama-data/data/models/fs-{given_surname}-cluster-partitions.csv\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa465334",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.set_printoptions(suppress=True)\n",
    "tqdm.pandas()\n",
    "\n",
    "wandb.init(\n",
    "    project=\"nama\",\n",
    "    entity=\"nama\",\n",
    "    name=\"90_compare_coders\",\n",
    "    group=given_surname,\n",
    "    notes=\"test\",\n",
    "    config=config._asdict(),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7498122",
   "metadata": {},
   "source": [
    "### Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fbf0a75",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36556f13",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_names_eval, weighted_actual_names_eval, candidate_names_eval = load_dataset(config.eval_path, is_eval=True)\n",
    "input_names_test, weighted_actual_names_test, candidate_names_test = load_dataset(config.test_path, is_eval=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b44b3b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# make all candidate_names_eval are in actual_names_eval\n",
    "actual_names_eval = set([name for wans in weighted_actual_names_eval for name, _, _ in wans])\n",
    "candidate_names_eval = np.array(list(actual_names_eval))\n",
    "del actual_names_eval\n",
    "print(len(candidate_names_eval))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1df9eed9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the most-frequent eval_size names\n",
    "input_names_eval, weighted_actual_names_eval, candidate_names_eval = \\\n",
    "    select_frequent_k(input_names_eval,\n",
    "                      weighted_actual_names_eval,\n",
    "                      candidate_names_eval,\n",
    "                      eval_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a04ad20d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"input_names_eval\", len(input_names_eval))\n",
    "print(\"candidate_names_eval\", len(candidate_names_eval))\n",
    "\n",
    "print(\"input_names_test\", len(input_names_test))\n",
    "print(\"candidate_names_test\", len(candidate_names_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c5ebe65",
   "metadata": {},
   "outputs": [],
   "source": [
    "freq_df = pd.read_csv(config.freq_path, na_filter=False)\n",
    "name_freq = normalize_freq_names(freq_df, is_surname=given_surname != \"given\", add_padding=True)\n",
    "freq_df = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0557b726",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "vocab_df = pd.read_csv(fopen(config.swivel_vocab_path, \"rb\"))\n",
    "swivel_vocab = {name: _id for name, _id in zip(vocab_df[\"name\"], vocab_df[\"index\"])}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "394d3428",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "swivel_model = SwivelModel(len(swivel_vocab), config.embed_dim)\n",
    "swivel_model.load_state_dict(torch.load(fopen(config.swivel_model_path, \"rb\"), map_location=torch.device(device)))\n",
    "swivel_model.to(device)\n",
    "swivel_model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79e28667",
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_vectorizer = joblib.load(fopen(config.tfidf_path, mode='rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "379be513",
   "metadata": {},
   "outputs": [],
   "source": [
    "ensemble_model = joblib.load(fopen(config.ensemble_model_path, mode='rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24fd88f7",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "name_cluster = read_clusters(config.cluster_path)\n",
    "print(\"name_cluster\", len(name_cluster))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "463dfb91",
   "metadata": {},
   "outputs": [],
   "source": [
    "for ix, (key, value) in enumerate(name_cluster.items()):\n",
    "    print(key, value)\n",
    "    if ix > 20:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5c4ed03",
   "metadata": {},
   "outputs": [],
   "source": [
    "if given_surname == \"given\":\n",
    "    cluster_partition = None\n",
    "else:\n",
    "    cluster_partition_df = pd.read_csv(config.partition_path)\n",
    "    cluster_partition = {cluster: (start_partition, n_partitions) \\\n",
    "                      for cluster, start_partition, n_partitions in \\\n",
    "                         zip(cluster_partition_df[\"cluster\"], \n",
    "                             cluster_partition_df[\"start_partition\"],\n",
    "                             cluster_partition_df[\"n_partitions\"])}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08faa79c",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_names_test, weighted_actual_names_test, candidate_names_test = load_dataset(config.test_path, is_eval=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc0e87c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove oov names from input_names_test and remove in-vocab names from candidate_names_test\n",
    "# so we only compare in-vocab against out-of-vocab\n",
    "input_names_test_iv = []\n",
    "weighted_actual_names_test_iv = []\n",
    "candidate_names_test_oov = set()\n",
    "for input_name, wans in zip(input_names_test, weighted_actual_names_test):\n",
    "    if input_name not in swivel_vocab:\n",
    "        continue\n",
    "    wans_oov = []\n",
    "    sum_freq = 0\n",
    "    for name, weight, freq in wans:\n",
    "        if name in swivel_vocab or freq == 0:\n",
    "            continue\n",
    "        wans_oov.append((name, freq))\n",
    "        sum_freq += freq\n",
    "    wans_oov = [(name, freq / sum_freq, freq) for name, freq in wans_oov]\n",
    "    if len(wans_oov) == 0:\n",
    "        continue\n",
    "    input_names_test_iv.append(input_name)\n",
    "    weighted_actual_names_test_iv.append(wans_oov)\n",
    "    for name, _, _ in wans_oov:\n",
    "        candidate_names_test_oov.add(name)\n",
    "candidate_names_test_oov = list(candidate_names_test_oov)\n",
    "# for candidate_name in candidate_names_test:\n",
    "#     if candidate_name in swivel_vocab:\n",
    "#         continue\n",
    "#     candidate_names_test_oov.append(candidate_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48f3a156",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(input_names_test))\n",
    "print(len(input_names_test_iv))\n",
    "print(len(candidate_names_test))\n",
    "print(len(candidate_names_test_oov))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6d009e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(input_names_test_iv[0:5])\n",
    "print(weighted_actual_names_test_iv[0:5])\n",
    "print(candidate_names_test_oov[0:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2fb96c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_names_test = input_names_test_iv\n",
    "weighted_actual_names_test = weighted_actual_names_test_iv\n",
    "candidate_names_test = np.array(candidate_names_test_oov)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c6736d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(num_matches)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f648503",
   "metadata": {},
   "source": [
    "### Other Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e75073f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# various coders\n",
    "caverphone_one = CaverphoneOne()\n",
    "caverphone_two = CaverphoneTwo()\n",
    "refined_soundex = RefinedSoundex()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cebaa126",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "coding_algos = [\n",
    "    \"nama\",\n",
    "    \"nama-05\",\n",
    "    \"nama-50\",\n",
    "    \"nama-80\",\n",
    "    \"soundex\",\n",
    "    \"nysiis\",\n",
    "    \"metaphone\",\n",
    "    \"caverphone1\",\n",
    "    \"caverphone2\",\n",
    "    \"refined_soundex\",\n",
    "    #     \"double_metaphone\",  # bad implementation?\n",
    "    \"cologne_phonetics\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b735e736",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# test double metaphone\n",
    "name = \"smith\"\n",
    "cand_name = \"schmidt\"\n",
    "dm1 = doublemetaphone(name)\n",
    "dm2 = doublemetaphone(cand_name)\n",
    "similarity = 1.0 if any(code in dm2 for code in dm1) else 0.0\n",
    "print(\"dm1\", dm1)\n",
    "print(\"dm2\", dm2)\n",
    "print(\"similarity\", similarity)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e339779",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Similarity functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db1c41b0",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def get_codes(name, algo):\n",
    "    name = remove_padding(name)\n",
    "    if algo == \"caverphone1\":\n",
    "        return [caverphone_one._pre_process(name)]\n",
    "    elif algo == \"caverphone2\":\n",
    "        return [caverphone_two._pre_process(name)]\n",
    "    elif algo == \"refined_soundex\":\n",
    "        return [refined_soundex.phonetics(name)]\n",
    "    elif algo == \"double_metaphone\":\n",
    "        return doublemetaphone(name)\n",
    "    elif algo == \"cologne_phonetics\":\n",
    "        return [cologne_phonetics.encode(name)[0][1]]\n",
    "    elif algo == \"soundex\":\n",
    "        return [jellyfish.soundex(name)]\n",
    "    elif algo == \"nysiis\":\n",
    "        return [jellyfish.nysiis(name)]\n",
    "    elif algo == \"metaphone\":\n",
    "        return [jellyfish.metaphone(name)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a37d97b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_similarity_to(name, name2codes):\n",
    "    codes1 = set(name2codes[name])\n",
    "\n",
    "    def calc_similarity(row):\n",
    "        cand_name = row[0]\n",
    "        code2 = name2codes[cand_name][0]  # code2 is the code cand_name is indexed under\n",
    "        return 1.0 if code2 in codes1 else 0.0\n",
    "\n",
    "    return calc_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fb8560e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_similars(shared, name=\"\"):\n",
    "    candidate_names, k, name2codes = shared\n",
    "    scores = np.apply_along_axis(calc_similarity_to(name, name2codes), 1, candidate_names[:, None])\n",
    "    sorted_scores_idx = np.argsort(scores)[::-1][:k]\n",
    "    candidate_names = candidate_names[sorted_scores_idx]\n",
    "    candidate_scores = scores[sorted_scores_idx]\n",
    "\n",
    "    return list(zip(candidate_names, candidate_scores))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37e1f414",
   "metadata": {},
   "source": [
    "# Evaluate each algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dab98f85",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def evaluate_algos(coding_algos,\n",
    "                   swivel_vocab,\n",
    "                   swivel_model,\n",
    "                   name_freq,\n",
    "                   name_cluster,\n",
    "                   cluster_partition,\n",
    "                   tfidf_vectorizer,\n",
    "                   ensemble_model,\n",
    "                   input_names,\n",
    "                   weighted_actual_names,\n",
    "                   candidate_names):\n",
    "\n",
    "    figure, ax = plt.subplots(1, 1, figsize=(20, 15))\n",
    "    ax.set_title(\"PR at threshold\")\n",
    "    colors = cm.rainbow(np.linspace(0, 1, len(coding_algos)))\n",
    "    all_names = list(set(input_names).union(set(candidate_names)))\n",
    "\n",
    "    for algo, color in zip(coding_algos, colors):\n",
    "        print(algo)\n",
    "        if algo.startswith(\"nama\"):\n",
    "            if algo == \"nama\":\n",
    "                search_threshold = 0\n",
    "                max_clusters = 1  # return just one cluster\n",
    "            else:\n",
    "                _, search_threshold = algo.split('-')\n",
    "                search_threshold = int(search_threshold) / 100.0\n",
    "                max_clusters = NAMA_MAX_CLUSTERS\n",
    "            results = get_validation_results(\n",
    "                input_names_eval=input_names,\n",
    "                weighted_actual_names_eval=weighted_actual_names,\n",
    "                candidate_names_eval=candidate_names,\n",
    "                name_freq=name_freq,\n",
    "                name_cluster=name_cluster,\n",
    "                cluster_partition=cluster_partition,\n",
    "                swivel_model=swivel_model,\n",
    "                swivel_vocab=swivel_vocab,\n",
    "                tfidf_vectorizer=tfidf_vectorizer,\n",
    "                ensemble_model=ensemble_model,\n",
    "                search_threshold=search_threshold,\n",
    "                num_matches=num_matches,\n",
    "                max_clusters=max_clusters,\n",
    "                sample_size=sample_size,\n",
    "                validation_sizes=[0],\n",
    "                n_jobs=n_jobs,\n",
    "                verbose=verbose) \n",
    "            precision = results['precisions'][0][search_threshold]\n",
    "            recall = results['recalls'][0][search_threshold]\n",
    "            avg_partitions = results['avg_partitions'][0][search_threshold]\n",
    "        else:\n",
    "            name2codes = {name: get_codes(name, algo) for name in all_names}\n",
    "            with WorkerPool(shared_objects=(candidate_names, num_matches, name2codes)) as pool:\n",
    "                similar_names_scores = pool.map(get_similars, input_names, progress_bar=True)\n",
    "            similar_names = [[name for name, _ in name_similarities] for name_similarities in similar_names_scores]\n",
    "            names = np.array(list(list(cell[0] for cell in row) for row in similar_names_scores), dtype=\"O\")\n",
    "            scores = np.array(list(list(cell[1] for cell in row) for row in similar_names_scores), dtype=\"f8\")\n",
    "            total = max(scores.sum(axis=1))\n",
    "            print(\"max sum of scores\", total)\n",
    "            if total == num_matches:\n",
    "                print(\"WARNING: need to increase num_matches\")\n",
    "            similar_names_scores = np.dstack((names, scores))\n",
    "            precision = metrics.avg_precision_at_threshold(weighted_actual_names, similar_names_scores, 0.5)\n",
    "            recall = metrics.avg_weighted_recall_at_threshold(weighted_actual_names, similar_names_scores, 0.5)\n",
    "            avg_partitions = 1.0\n",
    "        print(f\"precision={precision} recall={recall} avg_partitions={avg_partitions}\")\n",
    "        precisions = [precision]\n",
    "        recalls = [recall]\n",
    "        ax.plot(recalls, precisions, \"o--\", color=color, label=algo)\n",
    "\n",
    "    ax.legend()\n",
    "    plt.xlim([0, 1.0])\n",
    "    plt.ylim([0, 1.0])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7925affd",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "#### on in-vocabulary names (training data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35594069",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "_, input_names_sample, _, weighted_actual_names_sample = \\\n",
    "    train_test_split(input_names_eval, weighted_actual_names_eval, test_size=sample_size)\n",
    "candidate_names_sample = candidate_names_eval\n",
    "\n",
    "print(\"input_names\", len(input_names_sample))\n",
    "print(\"weighted_actual_names\", len(weighted_actual_names_sample))\n",
    "print(\"candidate_names\", len(candidate_names_sample))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69b25ead",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "evaluate_algos(coding_algos,\n",
    "                   swivel_vocab,\n",
    "                   swivel_model,\n",
    "                   name_freq,\n",
    "                   name_cluster,\n",
    "                   cluster_partition,\n",
    "                   tfidf_vectorizer,\n",
    "                   ensemble_model,\n",
    "                   input_names_sample,\n",
    "                   weighted_actual_names_sample,\n",
    "                   candidate_names_sample)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1f25279",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "#### on out-of-vocabulary names (test data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58b364b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "_, input_names_sample, _, weighted_actual_names_sample = \\\n",
    "    train_test_split(input_names_test, weighted_actual_names_test, test_size=sample_size)\n",
    "candidate_names_sample = candidate_names_test\n",
    "\n",
    "print(\"input_names\", len(input_names_sample))\n",
    "print(\"weighted_actual_names\", len(weighted_actual_names_sample))\n",
    "print(\"candidate_names\", len(candidate_names_sample))\n",
    "print(\"all names\", len(set(input_names_sample).union(set(candidate_names_sample))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8e6832a",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_zero = n_one = n_two = 0\n",
    "for input_name, wans in zip(input_names_sample, weighted_actual_names_sample):\n",
    "    for actual_name, _, _ in wans:\n",
    "        if input_name in swivel_vocab and actual_name in swivel_vocab:\n",
    "            n_two += 1\n",
    "        elif input_name in swivel_vocab or actual_name in swivel_vocab:\n",
    "            n_one += 1\n",
    "        else:\n",
    "            n_zero += 1\n",
    "print(\"two names in vocab (should not be possible)\", n_two)\n",
    "print(\"one name in vocab\", n_one)\n",
    "print(\"zero names in vocab\", n_zero)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3277d44c",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "evaluate_algos(coding_algos,\n",
    "                   swivel_vocab,\n",
    "                   swivel_model,\n",
    "                   name_freq,\n",
    "                   name_cluster,\n",
    "                   cluster_partition,\n",
    "                   tfidf_vectorizer,\n",
    "                   ensemble_model,\n",
    "                   input_names_sample,\n",
    "                   weighted_actual_names_sample,\n",
    "                   candidate_names_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed367dde",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "254e2a07",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nama",
   "language": "python",
   "name": "nama"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

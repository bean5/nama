{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "403ab30a",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d6ea350",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import namedtuple\n",
    "import cologne_phonetics\n",
    "import jellyfish\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.pyplot import cm\n",
    "from metaphone import doublemetaphone\n",
    "from mpire import WorkerPool\n",
    "import numpy as np\n",
    "from pyphonetics import RefinedSoundex\n",
    "from scipy.sparse import vstack\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.utils.extmath import safe_sparse_dot\n",
    "from spellwise import CaverphoneOne, CaverphoneTwo\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "\n",
    "from src.data.ancestry import load_train_test\n",
    "from src.metrics import metrics\n",
    "from src.models.utils import remove_padding, get_best_matches, build_token_idx_maps, convert_names_to_model_inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "800f0ea7",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.set_printoptions(suppress=True)\n",
    "tqdm.pandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efc2171a",
   "metadata": {},
   "source": [
    "### Load and process data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e19b85e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read ancestry data\n",
    "\n",
    "train, test = load_train_test(f\"../data/raw/records25k_data_train.csv\", f\"../data/raw/records25k_data_test.csv\")\n",
    "\n",
    "input_names_train, weighted_actual_names_train, candidate_names_train = train\n",
    "input_names_test, weighted_actual_names_test, candidate_names_test = test\n",
    "\n",
    "candidate_names_all = np.concatenate((candidate_names_train, candidate_names_test))\n",
    "input_names_all = input_names_train + input_names_test\n",
    "weighted_actual_names_all = weighted_actual_names_train + weighted_actual_names_test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ead0a08",
   "metadata": {},
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c64b3d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# various coders\n",
    "caverphone_one = CaverphoneOne()\n",
    "caverphone_two = CaverphoneTwo()\n",
    "refined_soundex = RefinedSoundex()\n",
    "\n",
    "# tfidf\n",
    "tfidf_vectorizer = TfidfVectorizer(ngram_range=(1, 3), analyzer=\"char_wb\", min_df=10, max_df=0.5)\n",
    "tfidf_X_train = tfidf_vectorizer.fit_transform(candidate_names_train)\n",
    "tfidf_X_test = tfidf_vectorizer.transform(candidate_names_test)\n",
    "tfidf_X_all = vstack((tfidf_X_train, tfidf_X_test))\n",
    "\n",
    "# autoencoder with triplet loss\n",
    "triplet_model = torch.load(\"../data/models/anc-triplet-bilstm-100-512-40-05.pth\")\n",
    "# move to cpu for evaluation so we don't run out of GPU memory\n",
    "triplet_model.to(\"cpu\")\n",
    "triplet_model.device = \"cpu\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f670567",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "SimilarityAlgo = namedtuple(\"SimilarityAlgo\", \"name min_threshold max_threshold distances\")\n",
    "similarity_algos = [\n",
    "    SimilarityAlgo(\"tfidf\", 0.5, 1.0, False),\n",
    "    SimilarityAlgo(\"levenshtein\", 0.5, 1.0, False),\n",
    "    SimilarityAlgo(\"damerau_levenshtein\", 0.5, 1.0, False),\n",
    "    SimilarityAlgo(\"jaro_winkler\", 0.5, 1.0, False),\n",
    "    SimilarityAlgo(\"triplet\", 0.01, 1.0, True),\n",
    "]\n",
    "coding_algos = [\n",
    "    \"soundex\",\n",
    "    \"nysiis\",\n",
    "    \"metaphone\",\n",
    "    \"caverphone1\",\n",
    "    \"caverphone2\",\n",
    "    \"refined_soundex\",\n",
    "    \"double_metaphone\",\n",
    "    \"cologne_phonetics\",\n",
    "    \"match_rating\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9527b1ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_similarity_to(name, algo=\"levenshtein\"):\n",
    "    name = remove_padding(name)\n",
    "    \n",
    "    def calc_similarity(row):\n",
    "        cand_name = remove_padding(row[0])\n",
    "        similarity = 0.0\n",
    "        if algo == \"levenshtein\":\n",
    "            dist = jellyfish.levenshtein_distance(name, cand_name)\n",
    "            similarity = 1 - (dist / max(len(name), len(cand_name)))\n",
    "        elif algo == \"damerau_levenshtein\":\n",
    "            dist = jellyfish.damerau_levenshtein_distance(name, cand_name)\n",
    "            similarity = 1 - (dist / max(len(name), len(cand_name)))\n",
    "        elif algo == \"jaro_winkler\":\n",
    "            similarity = jellyfish.jaro_winkler_similarity(name, cand_name)\n",
    "\n",
    "        elif algo == \"caverphone1\":\n",
    "            similarity = 1.0 if caverphone_one._pre_process(name) == caverphone_one._pre_process(cand_name) else 0.0\n",
    "        elif algo == \"caverphone2\":\n",
    "            similarity = 1.0 if caverphone_two._pre_process(name) == caverphone_two._pre_process(cand_name) else 0.0\n",
    "        elif algo == \"refined_soundex\":\n",
    "            similarity = 1.0 if refined_soundex.phonetics(name) == refined_soundex.phonetics(cand_name) else 0.0\n",
    "        elif algo == \"double_metaphone\":\n",
    "            dm1 = doublemetaphone(name)\n",
    "            dm2 = doublemetaphone(cand_name)\n",
    "            similarity = 1.0 if any(code in dm2 for code in dm1) else 0.0\n",
    "        elif algo == \"cologne_phonetics\":\n",
    "            similarity = 1.0 if cologne_phonetics.encode(name)[0][1] == cologne_phonetics.encode(cand_name)[0][1] else 0.0\n",
    "        elif algo == \"match_rating\":\n",
    "            similarity = 1.0 if jellyfish.match_rating_comparison(name, cand_name) else 0.0\n",
    "        elif algo == \"soundex\":\n",
    "            similarity = 1.0 if jellyfish.soundex(name) == jellyfish.soundex(cand_name) else 0.0\n",
    "        elif algo == \"nysiis\":\n",
    "            similarity = 1.0 if jellyfish.nysiis(name) == jellyfish.nysiis(cand_name) else 0.0\n",
    "        elif algo == \"metaphone\":\n",
    "            similarity = 1.0 if jellyfish.metaphone(name) == jellyfish.metaphone(cand_name) else 0.0\n",
    "        return similarity\n",
    "\n",
    "    return calc_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17d19fcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test double metaphone\n",
    "name = \"smith\"\n",
    "cand_name = \"schmidt\"\n",
    "dm1 = doublemetaphone(name)\n",
    "dm2 = doublemetaphone(cand_name)\n",
    "similarity = 1.0 if any(code in dm2 for code in dm1) else 0.0\n",
    "print(\"dm1\", dm1)\n",
    "print(\"dm2\", dm2)\n",
    "print(\"similarity\", similarity)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b3c4728",
   "metadata": {},
   "source": [
    "#### Similarity Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34a1e9f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_similars(shared, name=''):\n",
    "    candidate_names_all, k, algo, tfidf_vectorizer, tfidf_X_all  = shared\n",
    "    if algo == \"tfidf\":\n",
    "        x = tfidf_vectorizer.transform([name]).toarray()\n",
    "        scores = safe_sparse_dot(tfidf_X_all, x.T).flatten()\n",
    "    else:\n",
    "        scores = np.apply_along_axis(calc_similarity_to(name, algo), 1, candidate_names_all[:, None])\n",
    "    sorted_scores_idx = np.argsort(scores)[::-1][:k]\n",
    "    candidate_names = candidate_names_all[sorted_scores_idx]\n",
    "    candidate_scores = scores[sorted_scores_idx]\n",
    "\n",
    "    return list(zip(candidate_names, candidate_scores))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd3455a0",
   "metadata": {},
   "source": [
    "#### Demo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d71a5e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get_similars('schumacher', 10, 'jaro_winkler', True)\n",
    "get_similars((candidate_names_all, 10, \"levenshtein\", None, None), \"<bostelman>\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45c84a99",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Test tfidf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04218a21",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "get_similars((candidate_names_all, 10, \"tfidf\", tfidf_vectorizer, tfidf_X_all), \"<schumacher>\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "168a5cf5",
   "metadata": {},
   "source": [
    "## Test levenshtein"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "706048ed",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "input_names_test[251]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df731e17",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "weighted_actual_names_test[251]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5add52a3",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "k = 100  # Number of candidates to consider\n",
    "similar_names_scores = [get_similars((candidate_names_all, k, \"levenshtein\", None, None), input_names_test[251])]\n",
    "similar_names_scores[0][:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "758606e2",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Ugh - how can I create a 3D array with (str, float) as the third axis without taking apart and re-assembling the array?\n",
    "# names is a 2D array axis 0 = names, axis 1 = name of k similar-names\n",
    "names = np.array(list(list(cell[0] for cell in row) for row in similar_names_scores), dtype=\"O\")\n",
    "# scores is a 2D array axis 0 = names, axis 1 = score of k similar-names\n",
    "scores = np.array(list(list(cell[1] for cell in row) for row in similar_names_scores), dtype=\"f8\")\n",
    "# similar_names is now a 3D array axis 0 = names, axis 1 = k similar-names, axis 2 = name or score\n",
    "similar_names_scores = np.dstack((names, scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5f2bf97",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "metrics.weighted_recall_at_threshold(weighted_actual_names_test[251], similar_names_scores[0], 0.85)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88eb5931",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "metrics.weighted_recall_at_threshold(weighted_actual_names_test[251], similar_names_scores[0], 0.75)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "318b12e1",
   "metadata": {},
   "source": [
    "## Test Soundex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd3bc695",
   "metadata": {},
   "outputs": [],
   "source": [
    "k = 1000  # Number of candidates to consider\n",
    "similar_names_scores = [get_similars((candidate_names_all, k, \"soundex\", None, None), input_names_test[251])]\n",
    "similar_names_scores[0][:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1eb5e52a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ugh - how can I create a 3D array with (str, float) as the third axis without taking apart and re-assembling the array?\n",
    "# names is a 2D array axis 0 = names, axis 1 = name of k similar-names\n",
    "names = np.array(list(list(cell[0] for cell in row) for row in similar_names_scores), dtype=\"O\")\n",
    "# scores is a 2D array axis 0 = names, axis 1 = score of k similar-names\n",
    "scores = np.array(list(list(cell[1] for cell in row) for row in similar_names_scores), dtype=\"f8\")\n",
    "# similar_names is now a 3D array axis 0 = names, axis 1 = k similar-names, axis 2 = name or score\n",
    "similar_names_scores = np.dstack((names, scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08331bbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics.weighted_recall_at_threshold(weighted_actual_names_test[251], similar_names_scores[0], 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68cf8fd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics.precision_at_threshold(weighted_actual_names_test[251], similar_names_scores[0], 0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cefb8e0c",
   "metadata": {},
   "source": [
    "# Evaluate each algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd3ec79f",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def triplet_eval(triplet_model, input_names, candidate_names_all, k):\n",
    "    MAX_NAME_LENGTH = 30\n",
    "    char_to_idx_map, idx_to_char_map = build_token_idx_maps()\n",
    "\n",
    "    # Get embeddings for input names\n",
    "    input_names_X, _ = convert_names_to_model_inputs(input_names, char_to_idx_map, MAX_NAME_LENGTH)\n",
    "    input_names_encoded = triplet_model(input_names_X, just_encoder=True).detach().numpy()\n",
    "\n",
    "    # Get embeddings for candidate names\n",
    "    candidate_names_all_X, _ = convert_names_to_model_inputs(\n",
    "        candidate_names_all, char_to_idx_map, MAX_NAME_LENGTH\n",
    "    )\n",
    "    candidate_names_all_encoded = triplet_model(candidate_names_all_X, just_encoder=True).detach().numpy()\n",
    "\n",
    "    return get_best_matches(\n",
    "        input_names_encoded, candidate_names_all_encoded, candidate_names_all, num_candidates=k, metric=\"euclidean\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f64ad01",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "k = 1000  # Number of candidates to consider\n",
    "actual_names_all = [[name for name, _, _ in name_weights] for name_weights in weighted_actual_names_all]\n",
    "figure, ax = plt.subplots(1, 1, figsize=(20, 15))\n",
    "ax.set_title(\"PR at threshold\")\n",
    "colors = cm.rainbow(np.linspace(0, 1, len(similarity_algos)))\n",
    "# TODO use input_names_test and weighted_Actual_names_test\n",
    "input_names_sample = input_names_all\n",
    "\n",
    "for algo, color in zip(similarity_algos, colors):\n",
    "    print(algo.name)\n",
    "    if algo.name == \"triplet\":\n",
    "        similar_names_scores = triplet_eval(triplet_model, input_names_sample, candidate_names_all, k)\n",
    "    else:\n",
    "        with WorkerPool(shared_objects=(candidate_names_all, k, algo.name, tfidf_vectorizer, tfidf_X_all)) as pool:\n",
    "            similar_names_scores = pool.map(get_similars, input_names_sample, progress_bar=True)\n",
    "        similar_names = [[name for name, _ in name_similarities] for name_similarities in similar_names_scores]\n",
    "        names = np.array(list(list(cell[0] for cell in row) for row in similar_names_scores), dtype=\"O\")\n",
    "        scores = np.array(list(list(cell[1] for cell in row) for row in similar_names_scores), dtype=\"f8\")\n",
    "        similar_names_scores = np.dstack((names, scores))\n",
    "    precisions, recalls = metrics.precision_weighted_recall_at_threshold(\n",
    "        weighted_actual_names_all, similar_names_scores,\n",
    "        min_threshold=algo.min_threshold, max_threshold=algo.max_threshold, distances=algo.distances\n",
    "    )\n",
    "    ax.plot(recalls, precisions, \"o--\", color=color, label=algo.name)\n",
    "\n",
    "ax.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d506ebb",
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "k = 1000  # Number of candidates to consider\n",
    "actual_names_all = [[name for name, _, _ in name_weights] for name_weights in weighted_actual_names_all]\n",
    "figure, ax = plt.subplots(1, 1, figsize=(20, 15))\n",
    "ax.set_title(\"PR at threshold\")\n",
    "colors = cm.rainbow(np.linspace(0, 1, len(coding_algos)+2))\n",
    "input_names_sample = input_names_all\n",
    "\n",
    "# plot anc-triplet-bilstm-100-512-40-05 model\n",
    "ax.plot([.809], [.664], \"o--\", color=colors[0], label=\"triplet-cluster\")\n",
    "ax.plot([.594], [.543], \"o--\", color=colors[1], label=\"dam-lev-cluster\")\n",
    "\n",
    "for algo, color in zip(coding_algos, colors[2:]):\n",
    "    print(algo)\n",
    "#     similar_names_scores = list(map(lambda x: get_similars(x, k=k, algo=algo), tqdm(input_names_all)))\n",
    "    with WorkerPool(shared_objects=(candidate_names_all, k, algo, tfidf_vectorizer, tfidf_X_all)) as pool:\n",
    "        similar_names_scores = pool.map(get_similars, input_names_sample, progress_bar=True)\n",
    "    similar_names = [[name for name, _ in name_similarities] for name_similarities in similar_names_scores]\n",
    "    names = np.array(list(list(cell[0] for cell in row) for row in similar_names_scores), dtype=\"O\")\n",
    "    scores = np.array(list(list(cell[1] for cell in row) for row in similar_names_scores), dtype=\"f8\")\n",
    "    similar_names_scores = np.dstack((names, scores))\n",
    "    precision = metrics.avg_precision_at_threshold(weighted_actual_names_all, similar_names_scores, 0.5)\n",
    "    recall = metrics.avg_weighted_recall_at_threshold(weighted_actual_names_all, similar_names_scores, 0.5)\n",
    "    print(f\"precision={precision} recall={recall}\")\n",
    "    precisions = [precision]\n",
    "    recalls = [recall]\n",
    "    ax.plot(recalls, precisions, \"o--\", color=color, label=algo)\n",
    "\n",
    "ax.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70ca8de9",
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "jupytext": {
   "text_representation": {
    "extension": ".py",
    "format_name": "percent",
    "format_version": "1.3",
    "jupytext_version": "1.13.0"
   }
  },
  "kernelspec": {
   "display_name": "nama",
   "language": "python",
   "name": "nama"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

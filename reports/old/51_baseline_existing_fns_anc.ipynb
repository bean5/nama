{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e32ddd3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5beb4979",
   "metadata": {},
   "outputs": [],
   "source": [
    "from abydos import distance\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.pyplot import cm\n",
    "import numpy as np\n",
    "import jellyfish\n",
    "from tqdm import tqdm\n",
    "\n",
    "from src.data.ancestry import load_train_test\n",
    "from src.metrics import metrics\n",
    "from src.models import utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "935a4f02",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.set_printoptions(suppress=True)\n",
    "tqdm.pandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "973b728f",
   "metadata": {},
   "source": [
    "### Load and process data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b338eac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Only need to run this once\n",
    "# It we split the data into train/test and will persist the data on disk\n",
    "# train_test_split(test_size=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60ab5343",
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = load_train_test(f\"../data/raw/records25k_data_train.csv\", f\"../data/raw/records25k_data_test.csv\")\n",
    "\n",
    "input_names_train, weighted_actual_names_train, candidate_names_train = train\n",
    "input_names_test, weighted_actual_names_test, candidate_names_test = test\n",
    "\n",
    "candidate_names_all = np.concatenate((candidate_names_train, candidate_names_test))\n",
    "input_names_all = input_names_train + input_names_test\n",
    "weighted_actual_names_all = weighted_actual_names_train + weighted_actual_names_test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f5c7aea",
   "metadata": {},
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "681c86f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "sc95 = distance.Strcmp95()\n",
    "nw = distance.NeedlemanWunsch()\n",
    "sw = distance.SmithWaterman()\n",
    "gotoh = distance.Gotoh()\n",
    "dice = distance.Dice()\n",
    "me = distance.MongeElkan(symmetric=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0c38b05",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "continuous_algos = [\"levenshtein\", \"damerau_levenshtein\", \"jaro_winkler\", \"strcmp95\", \"dice\"]\n",
    "boolean_algos = [\"match_rating\", \"soundex\", \"nysiis\", \"metaphone\"]\n",
    "# Elasticsearch has metaphone double_metaphone, soundex, refined_soundex, caverphone1, caverphone2, cologne, nysiis, koelnerphonetik, haasephonetik, beider_morse, daitch_mokotoff\n",
    "# algos = continuous_algos + boolean_algos\n",
    "algos = continuous_algos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "606f8aa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_similarity_to(name, algo=\"levenshtein\"):\n",
    "    name = utils.remove_padding(name)\n",
    "\n",
    "    def calc_similarity(row):\n",
    "        cand_name = utils.remove_padding(row[0])\n",
    "        similarity = 0\n",
    "        if algo == \"levenshtein\":\n",
    "            dist = jellyfish.levenshtein_distance(name, cand_name)\n",
    "            similarity = 1 - (dist / max(len(name), len(cand_name)))\n",
    "        elif algo == \"damerau_levenshtein\":\n",
    "            dist = jellyfish.damerau_levenshtein_distance(name, cand_name)\n",
    "            similarity = 1 - (dist / max(len(name), len(cand_name)))\n",
    "        elif algo == \"jaro_winkler\":\n",
    "            similarity = jellyfish.jaro_winkler_similarity(name, cand_name)\n",
    "        elif algo == \"strcmp95\":\n",
    "            similarity = sc95.sim(name, cand_name)\n",
    "        elif algo == \"dice\":\n",
    "            similarity = dice.sim(name, cand_name)\n",
    "        elif algo == \"needleman_wunsch\":\n",
    "            similarity = nw.sim(name, cand_name)\n",
    "        elif algo == \"smith_waterman\":\n",
    "            similarity = sw.sim(name, cand_name)\n",
    "        elif algo == \"gotoh\":\n",
    "            similarity = gotoh.sim(name, cand_name)\n",
    "        elif algo == \"monge_elkan\":\n",
    "            similarity = me.sim(name, cand_name)\n",
    "        elif algo == \"match_rating\":\n",
    "            similarity = 1 if jellyfish.match_rating_comparison(name, cand_name) else 0\n",
    "        elif algo == \"soundex\":\n",
    "            similarity = 1 if jellyfish.soundex(name) == jellyfish.soundex(cand_name) else 0\n",
    "        elif algo == \"nysiis\":\n",
    "            similarity = 1 if jellyfish.nysiis(name) == jellyfish.nysiis(cand_name) else 0\n",
    "        elif algo == \"metaphone\":\n",
    "            similarity = 1 if jellyfish.metaphone(name) == jellyfish.metaphone(cand_name) else 0\n",
    "        return similarity\n",
    "\n",
    "    return calc_similarity"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e0a1f9b",
   "metadata": {},
   "source": [
    "#### Similarity Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ead16813",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_similars(name, k=10, algo=\"levenshtein\", demo_mode=False):\n",
    "    if demo_mode:\n",
    "        name = utils.add_padding(name)\n",
    "    scores = np.apply_along_axis(calc_similarity_to(name, algo), 1, candidate_names_all[:, None])\n",
    "    sorted_scores_idx = np.argsort(scores)[::-1][:k]\n",
    "    candidate_names = candidate_names_all[sorted_scores_idx]\n",
    "    if demo_mode:\n",
    "        candidate_names = [utils.remove_padding(candidate) for candidate in candidate_names]\n",
    "    candidate_scores = scores[sorted_scores_idx]\n",
    "\n",
    "    return list(zip(candidate_names, candidate_scores))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efb750ef",
   "metadata": {},
   "source": [
    "#### Demo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af6babda",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get_similars('schumacher', 10, 'jaro_winkler', True)\n",
    "get_similars(\"bostelman\", 10, \"levenshtein\", True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50f9c8e3",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Test levenshtein"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd8ac7aa",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "input_names_test[251]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12706a31",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "weighted_actual_names_test[251]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "706631b1",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "k = 100  # Number of candidates to consider\n",
    "similar_names_scores = [get_similars(input_names_test[251], k=k, algo=\"levenshtein\")]\n",
    "similar_names_scores[0][:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e6ee211",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Ugh - how can I create a 3D array with (str, float) as the third axis without taking apart and re-assembling the array?\n",
    "# names is a 2D array axis 0 = names, axis 1 = name of k similar-names\n",
    "names = np.array(list(list(cell[0] for cell in row) for row in similar_names_scores), dtype=\"O\")\n",
    "# scores is a 2D array axis 0 = names, axis 1 = score of k similar-names\n",
    "scores = np.array(list(list(cell[1] for cell in row) for row in similar_names_scores), dtype=\"f8\")\n",
    "# similar_names is now a 3D array axis 0 = names, axis 1 = k similar-names, axis 2 = name or score\n",
    "similar_names_scores = np.dstack((names, scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8a9e6f7",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "metrics.weighted_recall_at_threshold(weighted_actual_names_test[251], similar_names_scores[0], 0.85)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be944156",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "metrics.weighted_recall_at_threshold(weighted_actual_names_test[251], similar_names_scores[0], 0.75)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7006dc46",
   "metadata": {},
   "source": [
    "# Evaluate each algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bc437d9",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "k = 100  # Number of candidates to consider\n",
    "min_threshold = 0.5\n",
    "actual_names_all = [[name for name, _, _ in name_weights] for name_weights in weighted_actual_names_all]\n",
    "figure, axis = plt.subplots(2, 1, figsize=(20, 30))\n",
    "axis[0].set_title(\"PR at k\")\n",
    "axis[1].set_title(\"PR at threshold\")\n",
    "colors = cm.rainbow(np.linspace(0, 1, len(algos)))\n",
    "\n",
    "for algo, color in zip(algos, colors):\n",
    "    print(algo)\n",
    "    similar_names_scores = list(map(lambda x: get_similars(x, k=k, algo=algo), tqdm(input_names_all)))\n",
    "    similar_names = [[name for name, _ in name_similarities] for name_similarities in similar_names_scores]\n",
    "    names = np.array(list(list(cell[0] for cell in row) for row in similar_names_scores), dtype=\"O\")\n",
    "    scores = np.array(list(list(cell[1] for cell in row) for row in similar_names_scores), dtype=\"f8\")\n",
    "    similar_names_scores = np.dstack((names, scores))\n",
    "    if algo in continuous_algos:\n",
    "        precisions, recalls = metrics.precision_recall_at_k(actual_names_all, similar_names, k)\n",
    "        axis[0].plot(recalls, precisions, \"o--\", color=color, label=algo)\n",
    "\n",
    "        precisions, recalls = metrics.precision_weighted_recall_at_threshold(\n",
    "            weighted_actual_names_all, similar_names_scores, min_threshold\n",
    "        )\n",
    "        # metrics.get_auc(all_weighted_actuals, similar_names, step=.01)\n",
    "    else:\n",
    "        precisions = [metrics.avg_precision_at_threshold(weighted_actual_names_all, similar_names_scores, 0.5)]\n",
    "        recalls = [metrics.avg_weighted_recall_at_threshold(weighted_actual_names_test, similar_names_scores, 0.5)]\n",
    "\n",
    "    axis[1].plot(recalls, precisions, \"o--\", color=color, label=algo)\n",
    "\n",
    "axis[0].legend()\n",
    "axis[1].legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d769ef7",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "016935d5",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nama",
   "language": "python",
   "name": "nama"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
